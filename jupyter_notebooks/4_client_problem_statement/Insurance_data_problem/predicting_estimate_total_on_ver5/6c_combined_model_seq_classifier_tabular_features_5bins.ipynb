{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ambuj/izenda_fullcycle/environment/env/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "cleaned = pd.read_csv('datasets/cleaned_Izends_Data_Thru201712_ver5.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_loss_des = pd.read_csv('hashed_cleaned_loss_desc_from_5_ipynb.csv',index_col=0)\n",
    "# changing dtype of hashed_loss_desc_padded column\n",
    "cleaned_loss_des['hashed_loss_desc_padded'] = cleaned_loss_des['hashed_loss_desc_padded'].apply(lambda x: np.fromstring(x[1:-1],dtype='int32',sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing no of bins from 10 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0009999999999716, 924.544]    153282\n",
       "(924.544, 2023.348]               153281\n",
       "(2023.348, 3864.61]               153283\n",
       "(3864.61, 8323.578]               153280\n",
       "(8323.578, 265738.05]             153282\n",
       "Name: EstimateTotal, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(cleaned_loss_des['EstimateTotal'],5).value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_loss_des['EstimateTotal_bins'] = pd.qcut(cleaned['EstimateTotal'],5,labels = [\"a\", \"b\", \"c\", \"d\",\"e\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_combined = pd.merge(cleaned,cleaned_loss_des[['EstimateTotal_bins','hashed_loss_desc_padded']],left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(766408, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DisplayName', 'DivisionName', 'City', 'Zip', 'State', 'LossYearMo',\n",
       "       'StartedFlag', 'CommOrRes', 'NoteCount', 'PhotoCount', 'JobCount',\n",
       "       'ClaimCount', 'EstimateTotal', 'PolicyHolderType', 'LossDescription',\n",
       "       'Estimate_NetClaim', 'Estimate_MaterialSaleTax', 'Estimate_OverHead',\n",
       "       'Estimate_Profit', 'Estimate_PctOverhead', 'Estimate_PctProfit',\n",
       "       'Estimate_Deductible', 'Estimate_BaseSvcCharge',\n",
       "       'CleanAddressFranchisorID', 'CleanAddressContactID', 'LossMo',\n",
       "       'EstimateTotal_bins', 'hashed_loss_desc_padded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_combined.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = cleaned_combined[['DisplayName', 'DivisionName','LossMo','CommOrRes','PolicyHolderType','NoteCount','PhotoCount','JobCount','ClaimCount','LossYearMo']]\n",
    "X2 = cleaned_combined['hashed_loss_desc_padded']\n",
    "y = cleaned_combined['EstimateTotal_bins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_dummies = pd.get_dummies(X1,sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(X1_dummies,pd.DataFrame(X2),left_index=True,right_index=True)\n",
    "all_data['EstimateTotal_bins'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017=all_data[all_data[\"LossYearMo\"].apply(lambda all_data:all_data>=201701)]\n",
    "learning=all_data[all_data[\"LossYearMo\"].apply(lambda all_data:all_data<201701)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_x = learning[learning.columns.difference(['LossYearMo','EstimateTotal_bins'])]\n",
    "learning_y = learning['EstimateTotal_bins']\n",
    "learning_y_dummies = pd.get_dummies(learning_y,sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_x1 = test2017[test2017.columns.difference(['LossYearMo','EstimateTotal_bins','hashed_loss_desc_padded'])]\n",
    "test2017_x2 = test2017['hashed_loss_desc_padded']\n",
    "test2017_y = test2017['EstimateTotal_bins']\n",
    "test2017_y_dummies = pd.get_dummies(test2017_y,sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(learning_x, learning_y_dummies, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X_train[X_train.columns.difference(['hashed_loss_desc_padded'])]\n",
    "X2_train = X_train['hashed_loss_desc_padded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_val = X_val[X_val.columns.difference(['hashed_loss_desc_padded'])]\n",
    "X2_val = X_val['hashed_loss_desc_padded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Custom Keras Combined Model using Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History \n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input\n",
    "input1 = Input(shape=(X1_train.shape[1],),name='input1')\n",
    "hidden1 = Dense(512, activation='relu')(input1)\n",
    "dropout1 = Dropout(0.25)(hidden1)\n",
    "hidden2 = Dense(512, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.25)(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second input\n",
    "input2 = Input(shape=(14,),name='input2')\n",
    "embedding = Embedding(11024,100,input_length=14)(input2)\n",
    "lstm = LSTM(15)(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge layers\n",
    "merge = concatenate([dropout2,lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "output = Dense(y_train.shape[1], activation='softmax',name='output')(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model(inputs=[input1,input2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             (None, 1064)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          545280      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 14, 100)      1102400     input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 15)           6960        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 527)          0           dropout_2[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 5)            2640        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,919,936\n",
      "Trainable params: 1,919,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,to_file='combined_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=50,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 335176 samples, validate on 165087 samples\n",
      "Epoch 1/500\n",
      "335176/335176 [==============================] - 81s 242us/step - loss: 1.4023 - acc: 0.3773 - val_loss: 1.3533 - val_acc: 0.4006\n",
      "Epoch 2/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 1.3395 - acc: 0.4092 - val_loss: 1.3466 - val_acc: 0.4053\n",
      "Epoch 3/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.3158 - acc: 0.4234 - val_loss: 1.3452 - val_acc: 0.4038\n",
      "Epoch 4/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 1.2948 - acc: 0.4368 - val_loss: 1.3475 - val_acc: 0.4058\n",
      "Epoch 5/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.2730 - acc: 0.4481 - val_loss: 1.3599 - val_acc: 0.4034\n",
      "Epoch 6/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.2512 - acc: 0.4605 - val_loss: 1.3751 - val_acc: 0.4001\n",
      "Epoch 7/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.2301 - acc: 0.4708 - val_loss: 1.3877 - val_acc: 0.4010\n",
      "Epoch 8/500\n",
      "335176/335176 [==============================] - 79s 237us/step - loss: 1.2096 - acc: 0.4811 - val_loss: 1.4050 - val_acc: 0.3996\n",
      "Epoch 9/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.1910 - acc: 0.4913 - val_loss: 1.4320 - val_acc: 0.3949\n",
      "Epoch 10/500\n",
      "335176/335176 [==============================] - 79s 237us/step - loss: 1.1738 - acc: 0.4994 - val_loss: 1.4463 - val_acc: 0.3942\n",
      "Epoch 11/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.1578 - acc: 0.5062 - val_loss: 1.4759 - val_acc: 0.3866\n",
      "Epoch 12/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.1427 - acc: 0.5138 - val_loss: 1.4890 - val_acc: 0.3921\n",
      "Epoch 13/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.1283 - acc: 0.5202 - val_loss: 1.5041 - val_acc: 0.3900\n",
      "Epoch 14/500\n",
      "335176/335176 [==============================] - 79s 237us/step - loss: 1.1159 - acc: 0.5271 - val_loss: 1.5285 - val_acc: 0.3878\n",
      "Epoch 15/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.1047 - acc: 0.5314 - val_loss: 1.5523 - val_acc: 0.3872\n",
      "Epoch 16/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0935 - acc: 0.5366 - val_loss: 1.5630 - val_acc: 0.3848\n",
      "Epoch 17/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0841 - acc: 0.5409 - val_loss: 1.5694 - val_acc: 0.3856\n",
      "Epoch 18/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0745 - acc: 0.5446 - val_loss: 1.6003 - val_acc: 0.3846\n",
      "Epoch 19/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0650 - acc: 0.5495 - val_loss: 1.6127 - val_acc: 0.3832\n",
      "Epoch 20/500\n",
      "335176/335176 [==============================] - 80s 237us/step - loss: 1.0572 - acc: 0.5529 - val_loss: 1.6372 - val_acc: 0.3840\n",
      "Epoch 21/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0490 - acc: 0.5573 - val_loss: 1.6441 - val_acc: 0.3812\n",
      "Epoch 22/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0423 - acc: 0.5597 - val_loss: 1.6660 - val_acc: 0.3829\n",
      "Epoch 23/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0355 - acc: 0.5623 - val_loss: 1.6845 - val_acc: 0.3802\n",
      "Epoch 24/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 1.0278 - acc: 0.5661 - val_loss: 1.6943 - val_acc: 0.3817\n",
      "Epoch 25/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 1.0231 - acc: 0.5696 - val_loss: 1.7003 - val_acc: 0.3795\n",
      "Epoch 26/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0159 - acc: 0.5715 - val_loss: 1.7183 - val_acc: 0.3810\n",
      "Epoch 27/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0105 - acc: 0.5743 - val_loss: 1.7400 - val_acc: 0.3780\n",
      "Epoch 28/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 1.0057 - acc: 0.5768 - val_loss: 1.7425 - val_acc: 0.3751\n",
      "Epoch 29/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9995 - acc: 0.5792 - val_loss: 1.7605 - val_acc: 0.3772\n",
      "Epoch 30/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9953 - acc: 0.5812 - val_loss: 1.7828 - val_acc: 0.3777\n",
      "Epoch 31/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9903 - acc: 0.5837 - val_loss: 1.7940 - val_acc: 0.3746\n",
      "Epoch 32/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9863 - acc: 0.5855 - val_loss: 1.8026 - val_acc: 0.3757\n",
      "Epoch 33/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9817 - acc: 0.5881 - val_loss: 1.8083 - val_acc: 0.3758\n",
      "Epoch 34/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9786 - acc: 0.5891 - val_loss: 1.8231 - val_acc: 0.3729\n",
      "Epoch 35/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9741 - acc: 0.5910 - val_loss: 1.8372 - val_acc: 0.3726\n",
      "Epoch 36/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9702 - acc: 0.5923 - val_loss: 1.8431 - val_acc: 0.3741\n",
      "Epoch 37/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9665 - acc: 0.5935 - val_loss: 1.8509 - val_acc: 0.3739\n",
      "Epoch 38/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9638 - acc: 0.5958 - val_loss: 1.8820 - val_acc: 0.3696\n",
      "Epoch 39/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9604 - acc: 0.5966 - val_loss: 1.8721 - val_acc: 0.3725\n",
      "Epoch 40/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9574 - acc: 0.5986 - val_loss: 1.8826 - val_acc: 0.3751\n",
      "Epoch 41/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9541 - acc: 0.5996 - val_loss: 1.8922 - val_acc: 0.3717\n",
      "Epoch 42/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9501 - acc: 0.6020 - val_loss: 1.9095 - val_acc: 0.3708\n",
      "Epoch 43/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9482 - acc: 0.6026 - val_loss: 1.9190 - val_acc: 0.3691\n",
      "Epoch 44/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9459 - acc: 0.6037 - val_loss: 1.9165 - val_acc: 0.3729\n",
      "Epoch 45/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9429 - acc: 0.6049 - val_loss: 1.9188 - val_acc: 0.3695\n",
      "Epoch 46/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9403 - acc: 0.6062 - val_loss: 1.9397 - val_acc: 0.3682\n",
      "Epoch 47/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9377 - acc: 0.6075 - val_loss: 1.9350 - val_acc: 0.3685\n",
      "Epoch 48/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9359 - acc: 0.6082 - val_loss: 1.9544 - val_acc: 0.3667\n",
      "Epoch 49/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9332 - acc: 0.6090 - val_loss: 1.9532 - val_acc: 0.3691\n",
      "Epoch 50/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9321 - acc: 0.6100 - val_loss: 1.9516 - val_acc: 0.3698\n",
      "Epoch 51/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9299 - acc: 0.6117 - val_loss: 1.9687 - val_acc: 0.3689\n",
      "Epoch 52/500\n",
      "335176/335176 [==============================] - 80s 238us/step - loss: 0.9271 - acc: 0.6124 - val_loss: 1.9657 - val_acc: 0.3700\n",
      "Epoch 53/500\n",
      "335176/335176 [==============================] - 80s 239us/step - loss: 0.9236 - acc: 0.6140 - val_loss: 1.9884 - val_acc: 0.3667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8baf34b70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'input1':X1_train,'input2':np.stack(X2_train, axis=0)},\n",
    "          {'output':y_train.values},\n",
    "          validation_data=({'input1':X1_val,'input2':np.stack(X2_val, axis=0)},{'output':y_val.values}),\n",
    "         callbacks=[early_stop],epochs=500, batch_size=128,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_preds_proba = model.predict({'input1':test2017_x1,'input2':np.stack(test2017_x2, axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_preds = np.argmax(test2017_preds_proba,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {0:'a',1:'b',2:'c',3:'d',4:'e'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_preds_names = pd.Series(test2017_preds).map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40343797553964944"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test2017_y,test2017_preds_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
