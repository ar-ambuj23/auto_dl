{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ambuj/izenda_fullcycle/environment/env/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "cleaned = pd.read_csv('datasets/cleaned_Izends_Data_Thru201712_ver5.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_loss_des = pd.read_csv('hashed_cleaned_loss_desc_from_5_ipynb.csv',index_col=0)\n",
    "# changing dtype of hashed_loss_desc_padded column\n",
    "cleaned_loss_des['hashed_loss_desc_padded'] = cleaned_loss_des['hashed_loss_desc_padded'].apply(lambda x: np.fromstring(x[1:-1],dtype='int32',sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing no of bins from 10 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0009999999999716, 2790.16]    383204\n",
       "(2790.16, 265738.05]              383204\n",
       "Name: EstimateTotal, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(cleaned_loss_des['EstimateTotal'],2).value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_loss_des['EstimateTotal_bins'] = pd.qcut(cleaned['EstimateTotal'],2,labels = [\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_combined = pd.merge(cleaned,cleaned_loss_des[['EstimateTotal_bins','hashed_loss_desc_padded']],left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(766408, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DisplayName', 'DivisionName', 'City', 'Zip', 'State', 'LossYearMo',\n",
       "       'StartedFlag', 'CommOrRes', 'NoteCount', 'PhotoCount', 'JobCount',\n",
       "       'ClaimCount', 'EstimateTotal', 'PolicyHolderType', 'LossDescription',\n",
       "       'Estimate_NetClaim', 'Estimate_MaterialSaleTax', 'Estimate_OverHead',\n",
       "       'Estimate_Profit', 'Estimate_PctOverhead', 'Estimate_PctProfit',\n",
       "       'Estimate_Deductible', 'Estimate_BaseSvcCharge',\n",
       "       'CleanAddressFranchisorID', 'CleanAddressContactID', 'LossMo',\n",
       "       'EstimateTotal_bins', 'hashed_loss_desc_padded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_combined.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = cleaned_combined[['DisplayName', 'DivisionName','LossMo','CommOrRes','PolicyHolderType','NoteCount','PhotoCount','JobCount','ClaimCount','LossYearMo']]\n",
    "X2 = cleaned_combined['hashed_loss_desc_padded']\n",
    "y = cleaned_combined['EstimateTotal_bins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_dummies = pd.get_dummies(X1,sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(X1_dummies,pd.DataFrame(X2),left_index=True,right_index=True)\n",
    "all_data['EstimateTotal_bins'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017=all_data[all_data[\"LossYearMo\"].apply(lambda all_data:all_data>=201701)]\n",
    "learning=all_data[all_data[\"LossYearMo\"].apply(lambda all_data:all_data<201701)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_x = learning[learning.columns.difference(['LossYearMo','EstimateTotal_bins'])]\n",
    "learning_y = learning['EstimateTotal_bins']\n",
    "learning_y_dummies = pd.get_dummies(learning_y,sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_x1 = test2017[test2017.columns.difference(['LossYearMo','EstimateTotal_bins','hashed_loss_desc_padded'])]\n",
    "test2017_x2 = test2017['hashed_loss_desc_padded']\n",
    "test2017_y = test2017['EstimateTotal_bins']\n",
    "test2017_y_dummies = pd.get_dummies(test2017_y,sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(learning_x, learning_y_dummies, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X_train[X_train.columns.difference(['hashed_loss_desc_padded'])]\n",
    "X2_train = X_train['hashed_loss_desc_padded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_val = X_val[X_val.columns.difference(['hashed_loss_desc_padded'])]\n",
    "X2_val = X_val['hashed_loss_desc_padded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Custom Keras Combined Model using Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History \n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input\n",
    "input1 = Input(shape=(X1_train.shape[1],),name='input1')\n",
    "hidden1 = Dense(512, activation='relu')(input1)\n",
    "dropout1 = Dropout(0.25)(hidden1)\n",
    "hidden2 = Dense(512, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.25)(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second input\n",
    "input2 = Input(shape=(14,),name='input2')\n",
    "embedding = Embedding(11024,100,input_length=14)(input2)\n",
    "lstm = LSTM(15)(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge layers\n",
    "merge = concatenate([dropout2,lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "output = Dense(y_train.shape[1], activation='softmax',name='output')(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model(inputs=[input1,input2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             (None, 1064)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          545280      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             (None, 14)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 14, 100)      1102400     input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 15)           6960        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 527)          0           dropout_2[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            1056        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,918,352\n",
      "Trainable params: 1,918,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,to_file='combined_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=50,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 335176 samples, validate on 165087 samples\n",
      "Epoch 1/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.5691 - acc: 0.7016 - val_loss: 0.5420 - val_acc: 0.7218\n",
      "Epoch 2/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.5340 - acc: 0.7285 - val_loss: 0.5398 - val_acc: 0.7222\n",
      "Epoch 3/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.5204 - acc: 0.7384 - val_loss: 0.5385 - val_acc: 0.7246\n",
      "Epoch 4/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.5078 - acc: 0.7467 - val_loss: 0.5459 - val_acc: 0.7242\n",
      "Epoch 5/500\n",
      "335176/335176 [==============================] - 82s 243us/step - loss: 0.4961 - acc: 0.7539 - val_loss: 0.5546 - val_acc: 0.7200\n",
      "Epoch 6/500\n",
      "335176/335176 [==============================] - 82s 243us/step - loss: 0.4845 - acc: 0.7610 - val_loss: 0.5620 - val_acc: 0.7161\n",
      "Epoch 7/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.4727 - acc: 0.7680 - val_loss: 0.5704 - val_acc: 0.7172\n",
      "Epoch 8/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.4606 - acc: 0.7758 - val_loss: 0.5859 - val_acc: 0.7169\n",
      "Epoch 9/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.4494 - acc: 0.7814 - val_loss: 0.6054 - val_acc: 0.7098\n",
      "Epoch 10/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.4391 - acc: 0.7874 - val_loss: 0.6311 - val_acc: 0.7038\n",
      "Epoch 11/500\n",
      "335176/335176 [==============================] - 81s 242us/step - loss: 0.4297 - acc: 0.7929 - val_loss: 0.6444 - val_acc: 0.7061\n",
      "Epoch 12/500\n",
      "335176/335176 [==============================] - 81s 242us/step - loss: 0.4202 - acc: 0.7986 - val_loss: 0.6468 - val_acc: 0.7086\n",
      "Epoch 13/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.4117 - acc: 0.8030 - val_loss: 0.6634 - val_acc: 0.7069\n",
      "Epoch 14/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.4044 - acc: 0.8066 - val_loss: 0.6939 - val_acc: 0.6987\n",
      "Epoch 15/500\n",
      "335176/335176 [==============================] - 81s 242us/step - loss: 0.3976 - acc: 0.8110 - val_loss: 0.7092 - val_acc: 0.6990\n",
      "Epoch 16/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3907 - acc: 0.8145 - val_loss: 0.7328 - val_acc: 0.6982\n",
      "Epoch 17/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3855 - acc: 0.8178 - val_loss: 0.7381 - val_acc: 0.6984\n",
      "Epoch 18/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3795 - acc: 0.8210 - val_loss: 0.7601 - val_acc: 0.6941\n",
      "Epoch 19/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3744 - acc: 0.8237 - val_loss: 0.7735 - val_acc: 0.6959\n",
      "Epoch 20/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3697 - acc: 0.8264 - val_loss: 0.7854 - val_acc: 0.6895\n",
      "Epoch 21/500\n",
      "335176/335176 [==============================] - 82s 243us/step - loss: 0.3651 - acc: 0.8288 - val_loss: 0.7845 - val_acc: 0.6960\n",
      "Epoch 22/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3609 - acc: 0.8310 - val_loss: 0.8121 - val_acc: 0.6923\n",
      "Epoch 23/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3568 - acc: 0.8332 - val_loss: 0.8228 - val_acc: 0.6876\n",
      "Epoch 24/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3525 - acc: 0.8359 - val_loss: 0.8277 - val_acc: 0.6889\n",
      "Epoch 25/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3497 - acc: 0.8368 - val_loss: 0.8426 - val_acc: 0.6897\n",
      "Epoch 26/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3454 - acc: 0.8389 - val_loss: 0.8596 - val_acc: 0.6891\n",
      "Epoch 27/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3424 - acc: 0.8409 - val_loss: 0.8708 - val_acc: 0.6891\n",
      "Epoch 28/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3393 - acc: 0.8425 - val_loss: 0.8750 - val_acc: 0.6859\n",
      "Epoch 29/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3358 - acc: 0.8437 - val_loss: 0.8794 - val_acc: 0.6875\n",
      "Epoch 30/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3332 - acc: 0.8456 - val_loss: 0.8949 - val_acc: 0.6847\n",
      "Epoch 31/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3306 - acc: 0.8474 - val_loss: 0.9152 - val_acc: 0.6798\n",
      "Epoch 32/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3281 - acc: 0.8478 - val_loss: 0.9077 - val_acc: 0.6856\n",
      "Epoch 33/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3261 - acc: 0.8490 - val_loss: 0.9242 - val_acc: 0.6827\n",
      "Epoch 34/500\n",
      "335176/335176 [==============================] - 81s 242us/step - loss: 0.3231 - acc: 0.8512 - val_loss: 0.9320 - val_acc: 0.6798\n",
      "Epoch 35/500\n",
      "335176/335176 [==============================] - 82s 243us/step - loss: 0.3209 - acc: 0.8523 - val_loss: 0.9385 - val_acc: 0.6845\n",
      "Epoch 36/500\n",
      "335176/335176 [==============================] - 82s 243us/step - loss: 0.3187 - acc: 0.8536 - val_loss: 0.9729 - val_acc: 0.6823\n",
      "Epoch 37/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3167 - acc: 0.8545 - val_loss: 0.9586 - val_acc: 0.6789\n",
      "Epoch 38/500\n",
      "335176/335176 [==============================] - 82s 244us/step - loss: 0.3147 - acc: 0.8560 - val_loss: 0.9704 - val_acc: 0.6786\n",
      "Epoch 39/500\n",
      "335176/335176 [==============================] - 82s 244us/step - loss: 0.3115 - acc: 0.8572 - val_loss: 0.9734 - val_acc: 0.6822\n",
      "Epoch 40/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3111 - acc: 0.8577 - val_loss: 0.9889 - val_acc: 0.6814\n",
      "Epoch 41/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3082 - acc: 0.8588 - val_loss: 1.0028 - val_acc: 0.6782\n",
      "Epoch 42/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3070 - acc: 0.8594 - val_loss: 1.0077 - val_acc: 0.6792\n",
      "Epoch 43/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3048 - acc: 0.8605 - val_loss: 1.0143 - val_acc: 0.6775\n",
      "Epoch 44/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3033 - acc: 0.8611 - val_loss: 1.0162 - val_acc: 0.6790\n",
      "Epoch 45/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3013 - acc: 0.8620 - val_loss: 1.0246 - val_acc: 0.6782\n",
      "Epoch 46/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.3004 - acc: 0.8624 - val_loss: 1.0349 - val_acc: 0.6763\n",
      "Epoch 47/500\n",
      "335176/335176 [==============================] - 81s 242us/step - loss: 0.2997 - acc: 0.8636 - val_loss: 1.0379 - val_acc: 0.6761\n",
      "Epoch 48/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.2980 - acc: 0.8643 - val_loss: 1.0529 - val_acc: 0.6727\n",
      "Epoch 49/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.2974 - acc: 0.8645 - val_loss: 1.0392 - val_acc: 0.6783\n",
      "Epoch 50/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.2952 - acc: 0.8660 - val_loss: 1.0459 - val_acc: 0.6735\n",
      "Epoch 51/500\n",
      "335176/335176 [==============================] - 82s 243us/step - loss: 0.2935 - acc: 0.8661 - val_loss: 1.0702 - val_acc: 0.6738\n",
      "Epoch 52/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.2927 - acc: 0.8671 - val_loss: 1.0563 - val_acc: 0.6756\n",
      "Epoch 53/500\n",
      "335176/335176 [==============================] - 81s 243us/step - loss: 0.2918 - acc: 0.8674 - val_loss: 1.0533 - val_acc: 0.6720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76747ad358>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'input1':X1_train,'input2':np.stack(X2_train, axis=0)},\n",
    "          {'output':y_train.values},\n",
    "          validation_data=({'input1':X1_val,'input2':np.stack(X2_val, axis=0)},{'output':y_val.values}),\n",
    "         callbacks=[early_stop],epochs=500, batch_size=128,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_preds_proba = model.predict({'input1':test2017_x1,'input2':np.stack(test2017_x2, axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_preds = np.argmax(test2017_preds_proba,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {0:'a',1:'b'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2017_preds_names = pd.Series(test2017_preds).map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258036032989535"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test2017_y,test2017_preds_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
