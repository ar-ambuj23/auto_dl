{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('models/abalone.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train, Valid and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global x_train, x_test, x_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.pkl', 'rb') as fp:\n",
    "    x_train = pickle.load(fp)\n",
    "with open('x_test.pkl', 'rb') as fp:\n",
    "    x_test = pickle.load(fp)\n",
    "with open('x_valid.pkl', 'rb') as fp:\n",
    "    x_valid = pickle.load(fp)\n",
    "with open('y_train.pkl', 'rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "with open('y_test.pkl', 'rb') as fp:\n",
    "    y_test = pickle.load(fp)\n",
    "with open('y_valid.pkl', 'rb') as fp:\n",
    "    y_valid = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.pkl', 'rb') as fp:\n",
    "    best_params = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 32,\n",
       " 'dropout1': 0.39327924382539026,\n",
       " 'dropout2': 0.43077080171461557,\n",
       " 'early_stop_rounds': 40,\n",
       " 'nb_epochs': 500,\n",
       " 'num_layers': 'two_hidden',\n",
       " 'optimizer': 'rmsprop',\n",
       " 'units1': 32,\n",
       " 'units2': 512}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,mse = model.evaluate(x_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1113178751406"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = loss ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.348110106646608"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_error = (loss ** 0.5) / y_test.mean()*100\n",
    "pct_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_v,mse_v = model.evaluate(x_valid,y_valid,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1426875863273063"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v = loss_v ** 0.5\n",
    "rmse_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.86095706821611"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_error_v = (loss_v ** 0.5) / y_valid.mean()*100\n",
    "pct_error_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('abalone_intensity_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(best_params,feature_subset):   \n",
    "#     print('Training the best selected model...') \n",
    "\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(12345)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    \n",
    "    x_train_temp = x_train.copy() \n",
    "    y_train_temp = y_train.copy()\n",
    "    \n",
    "    x_valid_temp = x_valid.copy() \n",
    "    y_valid_temp = y_valid.copy()\n",
    "    \n",
    "    x_train_temp = x_train_temp[feature_subset]\n",
    "    x_valid_temp = x_valid_temp[feature_subset]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_params['units1'], input_shape=(x_train_temp.shape[1],)))\n",
    "    model.add(Activation(best_params['activation']))\n",
    "    model.add(Dropout(best_params['dropout1']))\n",
    "    if(best_params['num_layers'] == 'two_hidden'):\n",
    "        model.add(Dense(best_params['units2']))\n",
    "        model.add(Activation(best_params['activation']))\n",
    "        model.add(Dropout(best_params['dropout2']))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(loss='mse', metrics=['mse'],\n",
    "                  optimizer=best_params['optimizer'])\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=best_params['early_stop_rounds'])\n",
    "    history = History()\n",
    "    model.fit(x_train_temp, y_train_temp,\n",
    "              batch_size=best_params['batch_size'],\n",
    "              epochs=500,\n",
    "              callbacks=[early_stop, history],\n",
    "              verbose=0,\n",
    "              validation_data=(x_valid_temp,y_valid_temp)) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(best_params,feature_subset):\n",
    "    model = train_best_model(best_params,feature_subset)\n",
    "    x_valid_temp = x_valid.copy() \n",
    "    y_valid_temp = y_valid.copy()\n",
    "    \n",
    "    x_test_temp = x_test.copy() \n",
    "    y_test_temp = y_test.copy()\n",
    "    \n",
    "    x_valid_temp = x_valid_temp[feature_subset]\n",
    "    x_test_temp = x_test_temp[feature_subset]\n",
    "    \n",
    "    loss,mse = model.evaluate(x_test_temp,y_test_temp,verbose=0)\n",
    "    rmse = loss ** 0.5\n",
    "    pct_error = (loss ** 0.5) / y_test_temp.mean()*100\n",
    "    \n",
    "    loss_v,mse_v = model.evaluate(x_valid_temp,y_valid_temp,verbose=0)\n",
    "    rmse_v = loss_v ** 0.5\n",
    "    pct_error_v = (loss_v ** 0.5) / y_valid_temp.mean()*100\n",
    "    \n",
    "    return rmse, pct_error, rmse_v, pct_error_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Zero Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_zero = df[df['sum_of_intensities'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_features = list(df_non_zero['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1643321645635916, 21.884152026792, 2.1450984150750565, 21.885553758881464)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_zero_sorted = df_non_zero.sort_values(by=['sum_of_intensities'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_of_features(df):\n",
    "    feature_dict = {}\n",
    "    if(len(df)<=100):\n",
    "        for i in range(1,100):\n",
    "            if(i < len(df)):\n",
    "                drop_value = i\n",
    "                print(i,'No of features dropped:',drop_value)\n",
    "                subset_df = df.head(len(df) - drop_value)\n",
    "                subset_df.sort_values(by=['index'],inplace=True)\n",
    "                feature_subset = list(subset_df['feature_name'])\n",
    "\n",
    "                rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,feature_subset)\n",
    "\n",
    "                feature_dict[drop_value] = rmse, pct_error, rmse_v, pct_error_v\n",
    "        return feature_dict\n",
    "        \n",
    "    else:\n",
    "        for i in range(1,100):\n",
    "            drop_value = int(np.floor((i / 100) * len(df)))\n",
    "            print(i,'No of features dropped:',drop_value)\n",
    "            subset_df = df.head(len(df) - drop_value)\n",
    "            subset_df.sort_values(by=['index'],inplace=True)\n",
    "            feature_subset = list(subset_df['feature_name'])\n",
    "            \n",
    "            rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,feature_subset)\n",
    "            \n",
    "            feature_dict[drop_value] = rmse, pct_error, rmse_v, pct_error_v\n",
    "        return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 No of features dropped: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/izenda/env/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 No of features dropped: 2\n",
      "3 No of features dropped: 3\n",
      "4 No of features dropped: 4\n",
      "5 No of features dropped: 5\n",
      "6 No of features dropped: 6\n",
      "7 No of features dropped: 7\n",
      "8 No of features dropped: 8\n",
      "9 No of features dropped: 9\n"
     ]
    }
   ],
   "source": [
    "resultant_dict = simulation_of_features(df_non_zero_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (2.142774743537629,\n",
       "  21.666179071086813,\n",
       "  2.1652376703955256,\n",
       "  22.091026268619228),\n",
       " 2: (2.116159224571491,\n",
       "  21.397062309406945,\n",
       "  2.182589119627752,\n",
       "  22.268055943480604),\n",
       " 3: (2.1316155661421488,\n",
       "  21.553345588955448,\n",
       "  2.1554717332563067,\n",
       "  21.99138844279073),\n",
       " 4: (2.116225664356815,\n",
       "  21.397734100172922,\n",
       "  2.100405575057783,\n",
       "  21.429571158754047),\n",
       " 5: (2.1693940703053753,\n",
       "  21.935334334485894,\n",
       "  2.1440706279585298,\n",
       "  21.87506767114146),\n",
       " 6: (2.1522599933741917,\n",
       "  21.76208701573324,\n",
       "  2.1501087024986743,\n",
       "  21.936671653513447),\n",
       " 7: (2.1707548424181633,\n",
       "  21.949093471959173,\n",
       "  2.1376810541374733,\n",
       "  21.8098774866845),\n",
       " 8: (2.232102192465942,\n",
       "  22.569393237802704,\n",
       "  2.1979924410949576,\n",
       "  22.425209674827734),\n",
       " 9: (2.8336154477389237,\n",
       "  28.651457599295355,\n",
       "  2.7325219488553447,\n",
       "  27.878793620247354)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df = pd.DataFrame(resultant_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.columns = ['no_of_dropped_features', 'rmse_test', 'pct_error_test', 'rmse_valid', 'pct_error_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'no_of_dropped_features':[0],'rmse_test':[2.1643321645635916],'pct_error_test':[21.884152026792],'rmse_valid':[2.1450984150750565],'pct_error_valid':[21.885553758881464]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/izenda/env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "resultant_df = resultant_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.sort_values(by=['no_of_dropped_features'],inplace=True)\n",
    "resultant_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultant_df.to_csv('abalone_lime_feature_selection_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_dropped_features</th>\n",
       "      <th>pct_error_test</th>\n",
       "      <th>pct_error_valid</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>rmse_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.884152</td>\n",
       "      <td>21.885554</td>\n",
       "      <td>2.164332</td>\n",
       "      <td>2.145098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21.666179</td>\n",
       "      <td>22.091026</td>\n",
       "      <td>2.142775</td>\n",
       "      <td>2.165238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21.397062</td>\n",
       "      <td>22.268056</td>\n",
       "      <td>2.116159</td>\n",
       "      <td>2.182589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.553346</td>\n",
       "      <td>21.991388</td>\n",
       "      <td>2.131616</td>\n",
       "      <td>2.155472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.397734</td>\n",
       "      <td>21.429571</td>\n",
       "      <td>2.116226</td>\n",
       "      <td>2.100406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>21.935334</td>\n",
       "      <td>21.875068</td>\n",
       "      <td>2.169394</td>\n",
       "      <td>2.144071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>21.762087</td>\n",
       "      <td>21.936672</td>\n",
       "      <td>2.152260</td>\n",
       "      <td>2.150109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>21.949093</td>\n",
       "      <td>21.809877</td>\n",
       "      <td>2.170755</td>\n",
       "      <td>2.137681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>22.569393</td>\n",
       "      <td>22.425210</td>\n",
       "      <td>2.232102</td>\n",
       "      <td>2.197992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>28.651458</td>\n",
       "      <td>27.878794</td>\n",
       "      <td>2.833615</td>\n",
       "      <td>2.732522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_dropped_features  pct_error_test  pct_error_valid  rmse_test  \\\n",
       "0                       0       21.884152        21.885554   2.164332   \n",
       "1                       1       21.666179        22.091026   2.142775   \n",
       "2                       2       21.397062        22.268056   2.116159   \n",
       "3                       3       21.553346        21.991388   2.131616   \n",
       "4                       4       21.397734        21.429571   2.116226   \n",
       "5                       5       21.935334        21.875068   2.169394   \n",
       "6                       6       21.762087        21.936672   2.152260   \n",
       "7                       7       21.949093        21.809877   2.170755   \n",
       "8                       8       22.569393        22.425210   2.232102   \n",
       "9                       9       28.651458        27.878794   2.833615   \n",
       "\n",
       "   rmse_valid  \n",
       "0    2.145098  \n",
       "1    2.165238  \n",
       "2    2.182589  \n",
       "3    2.155472  \n",
       "4    2.100406  \n",
       "5    2.144071  \n",
       "6    2.150109  \n",
       "7    2.137681  \n",
       "8    2.197992  \n",
       "9    2.732522  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('abalone_lime_feature_selection_results.csv',index_col=0)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
