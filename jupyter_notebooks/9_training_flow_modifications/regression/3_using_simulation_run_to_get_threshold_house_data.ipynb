{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('models/train_no_null.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train, Valid and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global x_train, x_test, x_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.pkl', 'rb') as fp:\n",
    "    x_train = pickle.load(fp)\n",
    "with open('x_test.pkl', 'rb') as fp:\n",
    "    x_test = pickle.load(fp)\n",
    "with open('x_valid.pkl', 'rb') as fp:\n",
    "    x_valid = pickle.load(fp)\n",
    "with open('y_train.pkl', 'rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "with open('y_test.pkl', 'rb') as fp:\n",
    "    y_test = pickle.load(fp)\n",
    "with open('y_valid.pkl', 'rb') as fp:\n",
    "    y_valid = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.pkl', 'rb') as fp:\n",
    "    best_params = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 32,\n",
       " 'dropout1': 0.36373495616497264,\n",
       " 'dropout2': 0.6121737368795496,\n",
       " 'early_stop_rounds': 40,\n",
       " 'nb_epochs': 500,\n",
       " 'num_layers': 'one_hidden',\n",
       " 'optimizer': 'nadam',\n",
       " 'units1': 256,\n",
       " 'units2': 128}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,mse = model.evaluate(x_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34985.13477075421"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = loss ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.437331888312688"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_error = (loss ** 0.5) / y_test.mean()*100\n",
    "pct_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_v,mse_v = model.evaluate(x_valid,y_valid,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40898.65497425861"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v = loss_v ** 0.5\n",
    "rmse_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.85238068805628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_error_v = (loss_v ** 0.5) / y_valid.mean()*100\n",
    "pct_error_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('house_pred_intensity_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(best_params,feature_subset):   \n",
    "#     print('Training the best selected model...') \n",
    "\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(12345)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    \n",
    "    x_train_temp = x_train.copy() \n",
    "    y_train_temp = y_train.copy()\n",
    "    \n",
    "    x_valid_temp = x_valid.copy() \n",
    "    y_valid_temp = y_valid.copy()\n",
    "    \n",
    "    x_train_temp = x_train_temp[feature_subset]\n",
    "    x_valid_temp = x_valid_temp[feature_subset]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_params['units1'], input_shape=(x_train_temp.shape[1],)))\n",
    "    model.add(Activation(best_params['activation']))\n",
    "    model.add(Dropout(best_params['dropout1']))\n",
    "    if(best_params['num_layers'] == 'two_hidden'):\n",
    "        model.add(Dense(best_params['units2']))\n",
    "        model.add(Activation(best_params['activation']))\n",
    "        model.add(Dropout(best_params['dropout2']))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(loss='mse', metrics=['mse'],\n",
    "                  optimizer=best_params['optimizer'])\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=best_params['early_stop_rounds'])\n",
    "    history = History()\n",
    "    model.fit(x_train_temp, y_train_temp,\n",
    "              batch_size=best_params['batch_size'],\n",
    "              epochs=500,\n",
    "              callbacks=[early_stop, history],\n",
    "              verbose=0,\n",
    "              validation_data=(x_valid_temp,y_valid_temp)) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(best_params,feature_subset):\n",
    "    model = train_best_model(best_params,feature_subset)\n",
    "    x_valid_temp = x_valid.copy() \n",
    "    y_valid_temp = y_valid.copy()\n",
    "    \n",
    "    x_test_temp = x_test.copy() \n",
    "    y_test_temp = y_test.copy()\n",
    "    \n",
    "    x_valid_temp = x_valid_temp[feature_subset]\n",
    "    x_test_temp = x_test_temp[feature_subset]\n",
    "    \n",
    "    loss,mse = model.evaluate(x_test_temp,y_test_temp,verbose=0)\n",
    "    rmse = loss ** 0.5\n",
    "    pct_error = (loss ** 0.5) / y_test_temp.mean()*100\n",
    "    \n",
    "    loss_v,mse_v = model.evaluate(x_valid_temp,y_valid_temp,verbose=0)\n",
    "    rmse_v = loss_v ** 0.5\n",
    "    pct_error_v = (loss_v ** 0.5) / y_valid_temp.mean()*100\n",
    "    \n",
    "    return rmse, pct_error, rmse_v, pct_error_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('house_pred_intensity_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = list(df['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = list(df1['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "Train on 870 samples, validate on 290 samples\n",
      "Epoch 1/500\n",
      "870/870 [==============================] - 0s 408us/step - loss: 34472061339.9540 - mean_squared_error: 34472061339.9540 - val_loss: 32321957902.1241 - val_mean_squared_error: 32321957902.1241\n",
      "Epoch 2/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 23831477245.6460 - mean_squared_error: 23831477245.6460 - val_loss: 18316696653.6828 - val_mean_squared_error: 18316696653.6828\n",
      "Epoch 3/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 13368228395.5494 - mean_squared_error: 13368228395.5494 - val_loss: 9144594791.2828 - val_mean_squared_error: 9144594791.2828\n",
      "Epoch 4/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 8886484043.9172 - mean_squared_error: 8886484043.9172 - val_loss: 6119100989.7931 - val_mean_squared_error: 6119100989.7931\n",
      "Epoch 5/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 7461228948.8920 - mean_squared_error: 7461228948.8920 - val_loss: 5388117719.8345 - val_mean_squared_error: 5388117719.8345\n",
      "Epoch 6/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 6657781816.4966 - mean_squared_error: 6657781816.4966 - val_loss: 4724063329.5448 - val_mean_squared_error: 4724063329.5448\n",
      "Epoch 7/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 5788996603.2920 - mean_squared_error: 5788996603.2920 - val_loss: 4133229868.5793 - val_mean_squared_error: 4133229868.5793\n",
      "Epoch 8/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 5098688149.4805 - mean_squared_error: 5098688149.4805 - val_loss: 3700707267.0897 - val_mean_squared_error: 3700707267.0897\n",
      "Epoch 9/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 4546740806.0322 - mean_squared_error: 4546740806.0322 - val_loss: 3537101471.7793 - val_mean_squared_error: 3537101471.7793\n",
      "Epoch 10/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 4323386501.5908 - mean_squared_error: 4323386501.5908 - val_loss: 3438073106.9793 - val_mean_squared_error: 3438073106.9793\n",
      "Epoch 11/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 4014264487.2828 - mean_squared_error: 4014264487.2828 - val_loss: 3211670581.8483 - val_mean_squared_error: 3211670581.8483\n",
      "Epoch 12/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 3736141388.5057 - mean_squared_error: 3736141388.5057 - val_loss: 3117645165.4621 - val_mean_squared_error: 3117645165.4621\n",
      "Epoch 13/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 3446920145.8023 - mean_squared_error: 3446920145.8023 - val_loss: 3069651908.8552 - val_mean_squared_error: 3069651908.8552\n",
      "Epoch 14/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 3429530982.9885 - mean_squared_error: 3429530982.9885 - val_loss: 2958392277.1862 - val_mean_squared_error: 2958392277.1862\n",
      "Epoch 15/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 3334306027.4023 - mean_squared_error: 3334306027.4023 - val_loss: 2864594123.0345 - val_mean_squared_error: 2864594123.0345\n",
      "Epoch 16/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 3142249409.6184 - mean_squared_error: 3142249409.6184 - val_loss: 2802288725.1862 - val_mean_squared_error: 2802288725.1862\n",
      "Epoch 17/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 3298939056.8460 - mean_squared_error: 3298939056.8460 - val_loss: 2732136682.1517 - val_mean_squared_error: 2732136682.1517\n",
      "Epoch 18/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 3196241983.5586 - mean_squared_error: 3196241983.5586 - val_loss: 2694649634.2069 - val_mean_squared_error: 2694649634.2069\n",
      "Epoch 19/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 3248689264.1103 - mean_squared_error: 3248689264.1103 - val_loss: 2752393135.0069 - val_mean_squared_error: 2752393135.0069\n",
      "Epoch 20/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 3068501258.7402 - mean_squared_error: 3068501258.7402 - val_loss: 2601094596.4138 - val_mean_squared_error: 2601094596.4138\n",
      "Epoch 21/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 3115934869.3333 - mean_squared_error: 3115934869.3333 - val_loss: 2484874148.6345 - val_mean_squared_error: 2484874148.6345\n",
      "Epoch 22/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2820419107.3103 - mean_squared_error: 2820419107.3103 - val_loss: 2407844178.0966 - val_mean_squared_error: 2407844178.0966\n",
      "Epoch 23/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2932696713.7103 - mean_squared_error: 2932696713.7103 - val_loss: 2685820192.9931 - val_mean_squared_error: 2685820192.9931\n",
      "Epoch 24/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2898117027.9724 - mean_squared_error: 2898117027.9724 - val_loss: 2281197975.6138 - val_mean_squared_error: 2281197975.6138\n",
      "Epoch 25/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 3097319601.7287 - mean_squared_error: 3097319601.7287 - val_loss: 2281345980.4690 - val_mean_squared_error: 2281345980.4690\n",
      "Epoch 26/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2879336915.2736 - mean_squared_error: 2879336915.2736 - val_loss: 2235107995.5862 - val_mean_squared_error: 2235107995.5862\n",
      "Epoch 27/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2635995842.5747 - mean_squared_error: 2635995842.5747 - val_loss: 2167472129.3241 - val_mean_squared_error: 2167472129.3241\n",
      "Epoch 28/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2651843340.2115 - mean_squared_error: 2651843340.2115 - val_loss: 2204732115.8621 - val_mean_squared_error: 2204732115.8621\n",
      "Epoch 29/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2570818009.1586 - mean_squared_error: 2570818009.1586 - val_loss: 2345612011.2552 - val_mean_squared_error: 2345612011.2552\n",
      "Epoch 30/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2789538005.3333 - mean_squared_error: 2789538005.3333 - val_loss: 2079992299.6966 - val_mean_squared_error: 2079992299.6966\n",
      "Epoch 31/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2718600577.0299 - mean_squared_error: 2718600577.0299 - val_loss: 2121341576.9379 - val_mean_squared_error: 2121341576.9379\n",
      "Epoch 32/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2785816512.7356 - mean_squared_error: 2785816512.7356 - val_loss: 2079089810.5379 - val_mean_squared_error: 2079089810.5379\n",
      "Epoch 33/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2805354542.1977 - mean_squared_error: 2805354542.1977 - val_loss: 2099454272.1103 - val_mean_squared_error: 2099454272.1103\n",
      "Epoch 34/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2725717430.4368 - mean_squared_error: 2725717430.4368 - val_loss: 1990028992.5517 - val_mean_squared_error: 1990028992.5517\n",
      "Epoch 35/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2525463930.7034 - mean_squared_error: 2525463930.7034 - val_loss: 1915578926.7862 - val_mean_squared_error: 1915578926.7862\n",
      "Epoch 36/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2808945313.5448 - mean_squared_error: 2808945313.5448 - val_loss: 1957964278.0690 - val_mean_squared_error: 1957964278.0690\n",
      "Epoch 37/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2580033330.7586 - mean_squared_error: 2580033330.7586 - val_loss: 1965637222.8414 - val_mean_squared_error: 1965637222.8414\n",
      "Epoch 38/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2415776308.6713 - mean_squared_error: 2415776308.6713 - val_loss: 1888838307.3103 - val_mean_squared_error: 1888838307.3103\n",
      "Epoch 39/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2557701707.9172 - mean_squared_error: 2557701707.9172 - val_loss: 1895332106.3724 - val_mean_squared_error: 1895332106.3724\n",
      "Epoch 40/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2573472255.4115 - mean_squared_error: 2573472255.4115 - val_loss: 1877924087.1724 - val_mean_squared_error: 1877924087.1724\n",
      "Epoch 41/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 0s 111us/step - loss: 2434914739.7885 - mean_squared_error: 2434914739.7885 - val_loss: 1813343466.8138 - val_mean_squared_error: 1813343466.8138\n",
      "Epoch 42/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2515486322.1701 - mean_squared_error: 2515486322.1701 - val_loss: 1973698812.0276 - val_mean_squared_error: 1973698812.0276\n",
      "Epoch 43/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2475597919.3379 - mean_squared_error: 2475597919.3379 - val_loss: 1880072031.4483 - val_mean_squared_error: 1880072031.4483\n",
      "Epoch 44/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2372018042.7034 - mean_squared_error: 2372018042.7034 - val_loss: 1835924977.6552 - val_mean_squared_error: 1835924977.6552\n",
      "Epoch 45/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2731842361.0851 - mean_squared_error: 2731842361.0851 - val_loss: 1755115396.4138 - val_mean_squared_error: 1755115396.4138\n",
      "Epoch 46/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2425818825.2690 - mean_squared_error: 2425818825.2690 - val_loss: 2061588899.8621 - val_mean_squared_error: 2061588899.8621\n",
      "Epoch 47/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2449439645.0575 - mean_squared_error: 2449439645.0575 - val_loss: 1815130155.4759 - val_mean_squared_error: 1815130155.4759\n",
      "Epoch 48/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2555447734.1057 - mean_squared_error: 2555447734.1057 - val_loss: 1831180012.8000 - val_mean_squared_error: 1831180012.8000\n",
      "Epoch 49/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2521719683.0897 - mean_squared_error: 2521719683.0897 - val_loss: 1767914724.4138 - val_mean_squared_error: 1767914724.4138\n",
      "Epoch 50/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2559262616.4230 - mean_squared_error: 2559262616.4230 - val_loss: 1732757721.3793 - val_mean_squared_error: 1732757721.3793\n",
      "Epoch 51/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2552912037.9586 - mean_squared_error: 2552912037.9586 - val_loss: 1684956748.8000 - val_mean_squared_error: 1684956748.8000\n",
      "Epoch 52/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2761862563.0161 - mean_squared_error: 2761862563.0161 - val_loss: 1715455802.4828 - val_mean_squared_error: 1715455802.4828\n",
      "Epoch 53/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2434282082.2805 - mean_squared_error: 2434282082.2805 - val_loss: 1869736290.9793 - val_mean_squared_error: 1869736290.9793\n",
      "Epoch 54/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2463905985.8391 - mean_squared_error: 2463905985.8391 - val_loss: 1786511870.7862 - val_mean_squared_error: 1786511870.7862\n",
      "Epoch 55/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2408211700.8184 - mean_squared_error: 2408211700.8184 - val_loss: 1808416896.9379 - val_mean_squared_error: 1808416896.9379\n",
      "Epoch 56/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2465382155.1816 - mean_squared_error: 2465382155.1816 - val_loss: 1670077001.2690 - val_mean_squared_error: 1670077001.2690\n",
      "Epoch 57/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2601483251.6414 - mean_squared_error: 2601483251.6414 - val_loss: 1716870990.4552 - val_mean_squared_error: 1716870990.4552\n",
      "Epoch 58/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2306276763.0713 - mean_squared_error: 2306276763.0713 - val_loss: 1751856241.9862 - val_mean_squared_error: 1751856241.9862\n",
      "Epoch 59/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2366009650.6115 - mean_squared_error: 2366009650.6115 - val_loss: 1782611231.1172 - val_mean_squared_error: 1782611231.1172\n",
      "Epoch 60/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2297566907.1448 - mean_squared_error: 2297566907.1448 - val_loss: 1664455457.7655 - val_mean_squared_error: 1664455457.7655\n",
      "Epoch 61/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2484479819.6230 - mean_squared_error: 2484479819.6230 - val_loss: 1779259588.9655 - val_mean_squared_error: 1779259588.9655\n",
      "Epoch 62/500\n",
      "870/870 [==============================] - 0s 113us/step - loss: 2365206481.8023 - mean_squared_error: 2365206481.8023 - val_loss: 1665643671.1724 - val_mean_squared_error: 1665643671.1724\n",
      "Epoch 63/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2341106153.6368 - mean_squared_error: 2341106153.6368 - val_loss: 1701001080.7172 - val_mean_squared_error: 1701001080.7172\n",
      "Epoch 64/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2472833247.6322 - mean_squared_error: 2472833247.6322 - val_loss: 1709859514.6483 - val_mean_squared_error: 1709859514.6483\n",
      "Epoch 65/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2325236336.4046 - mean_squared_error: 2325236336.4046 - val_loss: 1701785572.7448 - val_mean_squared_error: 1701785572.7448\n",
      "Epoch 66/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 2402094789.5908 - mean_squared_error: 2402094789.5908 - val_loss: 1693379546.2621 - val_mean_squared_error: 1693379546.2621\n",
      "Epoch 67/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2248738680.0552 - mean_squared_error: 2248738680.0552 - val_loss: 1664288704.6621 - val_mean_squared_error: 1664288704.6621\n",
      "Epoch 68/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 2575326830.6391 - mean_squared_error: 2575326830.6391 - val_loss: 1678313439.4483 - val_mean_squared_error: 1678313439.4483\n",
      "Epoch 69/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2545541404.5425 - mean_squared_error: 2545541404.5425 - val_loss: 1787704178.6483 - val_mean_squared_error: 1787704178.6483\n",
      "Epoch 70/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2513093062.0322 - mean_squared_error: 2513093062.0322 - val_loss: 1670329522.4276 - val_mean_squared_error: 1670329522.4276\n",
      "Epoch 71/500\n",
      "870/870 [==============================] - 0s 114us/step - loss: 2408012484.4138 - mean_squared_error: 2408012484.4138 - val_loss: 1775311134.7310 - val_mean_squared_error: 1775311134.7310\n",
      "Epoch 72/500\n",
      "870/870 [==============================] - 0s 113us/step - loss: 2269462932.0092 - mean_squared_error: 2269462932.0092 - val_loss: 1681263310.8966 - val_mean_squared_error: 1681263310.8966\n",
      "Epoch 73/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2336668653.7563 - mean_squared_error: 2336668653.7563 - val_loss: 1639554019.5310 - val_mean_squared_error: 1639554019.5310\n",
      "Epoch 74/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 2487779637.7011 - mean_squared_error: 2487779637.7011 - val_loss: 1674049922.8138 - val_mean_squared_error: 1674049922.8138\n",
      "Epoch 75/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2315929762.1333 - mean_squared_error: 2315929762.1333 - val_loss: 1721559914.9793 - val_mean_squared_error: 1721559914.9793\n",
      "Epoch 76/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2355403546.0414 - mean_squared_error: 2355403546.0414 - val_loss: 1744005830.5103 - val_mean_squared_error: 1744005830.5103\n",
      "Epoch 77/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2466836679.2092 - mean_squared_error: 2466836679.2092 - val_loss: 1749357852.7448 - val_mean_squared_error: 1749357852.7448\n",
      "Epoch 78/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2216795206.7678 - mean_squared_error: 2216795206.7678 - val_loss: 1675015993.8207 - val_mean_squared_error: 1675015993.8207\n",
      "Epoch 79/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2184332939.7701 - mean_squared_error: 2184332939.7701 - val_loss: 1713192608.1103 - val_mean_squared_error: 1713192608.1103\n",
      "Epoch 80/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2287295470.7862 - mean_squared_error: 2287295470.7862 - val_loss: 1698544304.0552 - val_mean_squared_error: 1698544304.0552\n",
      "Epoch 81/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2190666590.6023 - mean_squared_error: 2190666590.6023 - val_loss: 1692995046.9517 - val_mean_squared_error: 1692995046.9517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2415518636.4322 - mean_squared_error: 2415518636.4322 - val_loss: 1706911072.8828 - val_mean_squared_error: 1706911072.8828\n",
      "Epoch 83/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2220229391.8897 - mean_squared_error: 2220229391.8897 - val_loss: 1673094889.4345 - val_mean_squared_error: 1673094889.4345\n",
      "Epoch 84/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2300158875.9540 - mean_squared_error: 2300158875.9540 - val_loss: 1711024810.5931 - val_mean_squared_error: 1711024810.5931\n",
      "Epoch 85/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2154958436.1195 - mean_squared_error: 2154958436.1195 - val_loss: 1660410486.1793 - val_mean_squared_error: 1660410486.1793\n",
      "Epoch 86/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2175986005.3333 - mean_squared_error: 2175986005.3333 - val_loss: 1663534310.5103 - val_mean_squared_error: 1663534310.5103\n",
      "Epoch 87/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 2246055700.8920 - mean_squared_error: 2246055700.8920 - val_loss: 1704172178.7586 - val_mean_squared_error: 1704172178.7586\n",
      "Epoch 88/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2297475836.1747 - mean_squared_error: 2297475836.1747 - val_loss: 1679872485.8483 - val_mean_squared_error: 1679872485.8483\n",
      "Epoch 89/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2254347871.3379 - mean_squared_error: 2254347871.3379 - val_loss: 1624656951.2828 - val_mean_squared_error: 1624656951.2828\n",
      "Epoch 90/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2397157418.6667 - mean_squared_error: 2397157418.6667 - val_loss: 1739410846.2897 - val_mean_squared_error: 1739410846.2897\n",
      "Epoch 91/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2393522886.9149 - mean_squared_error: 2393522886.9149 - val_loss: 1700901225.6000 - val_mean_squared_error: 1700901225.6000\n",
      "Epoch 92/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2198129683.4207 - mean_squared_error: 2198129683.4207 - val_loss: 1676330638.6759 - val_mean_squared_error: 1676330638.6759\n",
      "Epoch 93/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2172092084.3770 - mean_squared_error: 2172092084.3770 - val_loss: 1629295252.1379 - val_mean_squared_error: 1629295252.1379\n",
      "Epoch 94/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2429949879.0253 - mean_squared_error: 2429949879.0253 - val_loss: 1667294042.9241 - val_mean_squared_error: 1667294042.9241\n",
      "Epoch 95/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2280567550.8230 - mean_squared_error: 2280567550.8230 - val_loss: 1636604192.8276 - val_mean_squared_error: 1636604192.8276\n",
      "Epoch 96/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2443864719.5954 - mean_squared_error: 2443864719.5954 - val_loss: 1865134637.5724 - val_mean_squared_error: 1865134637.5724\n",
      "Epoch 97/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2306742952.6069 - mean_squared_error: 2306742952.6069 - val_loss: 1711315188.5793 - val_mean_squared_error: 1711315188.5793\n",
      "Epoch 98/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2292837616.6989 - mean_squared_error: 2292837616.6989 - val_loss: 1794887954.8690 - val_mean_squared_error: 1794887954.8690\n",
      "Epoch 99/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2264015463.5770 - mean_squared_error: 2264015463.5770 - val_loss: 1659874619.3655 - val_mean_squared_error: 1659874619.3655\n",
      "Epoch 100/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 2352496205.3885 - mean_squared_error: 2352496205.3885 - val_loss: 1740582552.2759 - val_mean_squared_error: 1740582552.2759\n",
      "Epoch 101/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2246005687.6138 - mean_squared_error: 2246005687.6138 - val_loss: 1696006353.1034 - val_mean_squared_error: 1696006353.1034\n",
      "Epoch 102/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2279631502.4184 - mean_squared_error: 2279631502.4184 - val_loss: 1622157082.5379 - val_mean_squared_error: 1622157082.5379\n",
      "Epoch 103/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2252270252.4322 - mean_squared_error: 2252270252.4322 - val_loss: 1656566481.8207 - val_mean_squared_error: 1656566481.8207\n",
      "Epoch 104/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2110422944.6621 - mean_squared_error: 2110422944.6621 - val_loss: 1704583318.8414 - val_mean_squared_error: 1704583318.8414\n",
      "Epoch 105/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2184935734.7310 - mean_squared_error: 2184935734.7310 - val_loss: 1804085099.5862 - val_mean_squared_error: 1804085099.5862\n",
      "Epoch 106/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2238966702.7862 - mean_squared_error: 2238966702.7862 - val_loss: 1717755385.2690 - val_mean_squared_error: 1717755385.2690\n",
      "Epoch 107/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2408079824.0368 - mean_squared_error: 2408079824.0368 - val_loss: 1659630775.7241 - val_mean_squared_error: 1659630775.7241\n",
      "Epoch 108/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2158341734.9885 - mean_squared_error: 2158341734.9885 - val_loss: 1745929031.0621 - val_mean_squared_error: 1745929031.0621\n",
      "Epoch 109/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2178578121.7103 - mean_squared_error: 2178578121.7103 - val_loss: 1645346680.7724 - val_mean_squared_error: 1645346680.7724\n",
      "Epoch 110/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2217374713.5264 - mean_squared_error: 2217374713.5264 - val_loss: 1699237931.0345 - val_mean_squared_error: 1699237931.0345\n",
      "Epoch 111/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2238318051.7517 - mean_squared_error: 2238318051.7517 - val_loss: 1656423113.1034 - val_mean_squared_error: 1656423113.1034\n",
      "Epoch 112/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2309625334.8782 - mean_squared_error: 2309625334.8782 - val_loss: 1759049962.2069 - val_mean_squared_error: 1759049962.2069\n",
      "Epoch 113/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2275024589.9770 - mean_squared_error: 2275024589.9770 - val_loss: 1678229283.5862 - val_mean_squared_error: 1678229283.5862\n",
      "Epoch 114/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2241865009.1402 - mean_squared_error: 2241865009.1402 - val_loss: 1775598915.8621 - val_mean_squared_error: 1775598915.8621\n",
      "Epoch 115/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2239560533.8851 - mean_squared_error: 2239560533.8851 - val_loss: 1705844321.5448 - val_mean_squared_error: 1705844321.5448\n",
      "Epoch 116/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2265060218.5563 - mean_squared_error: 2265060218.5563 - val_loss: 1721666472.4966 - val_mean_squared_error: 1721666472.4966\n",
      "Epoch 117/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2309758415.8897 - mean_squared_error: 2309758415.8897 - val_loss: 1731158206.7034 - val_mean_squared_error: 1731158206.7034\n",
      "Epoch 118/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 1980310162.9793 - mean_squared_error: 1980310162.9793 - val_loss: 1674027902.6207 - val_mean_squared_error: 1674027902.6207\n",
      "Epoch 119/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2401151002.4828 - mean_squared_error: 2401151002.4828 - val_loss: 1818412346.8138 - val_mean_squared_error: 1818412346.8138\n",
      "Epoch 120/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2196014952.0920 - mean_squared_error: 2196014952.0920 - val_loss: 1683101716.9103 - val_mean_squared_error: 1683101716.9103\n",
      "Epoch 121/500\n",
      "870/870 [==============================] - 0s 113us/step - loss: 2360917457.2138 - mean_squared_error: 2360917457.2138 - val_loss: 1823124353.6000 - val_mean_squared_error: 1823124353.6000\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 0s 109us/step - loss: 2183830669.5356 - mean_squared_error: 2183830669.5356 - val_loss: 1662461474.2069 - val_mean_squared_error: 1662461474.2069\n",
      "Epoch 123/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2111105442.3540 - mean_squared_error: 2111105442.3540 - val_loss: 1656637069.2414 - val_mean_squared_error: 1656637069.2414\n",
      "Epoch 124/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2030093390.7862 - mean_squared_error: 2030093390.7862 - val_loss: 1730581440.9931 - val_mean_squared_error: 1730581440.9931\n",
      "Epoch 125/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2258834569.1218 - mean_squared_error: 2258834569.1218 - val_loss: 1779868774.0690 - val_mean_squared_error: 1779868774.0690\n",
      "Epoch 126/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2196983913.3425 - mean_squared_error: 2196983913.3425 - val_loss: 1717836696.7448 - val_mean_squared_error: 1717836696.7448\n",
      "Epoch 127/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2240794709.1126 - mean_squared_error: 2240794709.1126 - val_loss: 1663032701.8483 - val_mean_squared_error: 1663032701.8483\n",
      "Epoch 128/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 2225146082.7218 - mean_squared_error: 2225146082.7218 - val_loss: 1687556577.3793 - val_mean_squared_error: 1687556577.3793\n",
      "Epoch 129/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2172196712.6069 - mean_squared_error: 2172196712.6069 - val_loss: 1629273835.0345 - val_mean_squared_error: 1629273835.0345\n",
      "Epoch 130/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2159228299.6230 - mean_squared_error: 2159228299.6230 - val_loss: 1663937529.4345 - val_mean_squared_error: 1663937529.4345\n",
      "Epoch 131/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2116923961.9678 - mean_squared_error: 2116923961.9678 - val_loss: 1717895674.6483 - val_mean_squared_error: 1717895674.6483\n",
      "Epoch 132/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2167038858.2989 - mean_squared_error: 2167038858.2989 - val_loss: 2250988063.0069 - val_mean_squared_error: 2250988063.0069\n",
      "Epoch 133/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2439235576.9379 - mean_squared_error: 2439235576.9379 - val_loss: 1869937265.9862 - val_mean_squared_error: 1869937265.9862\n",
      "Epoch 134/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2447707901.7195 - mean_squared_error: 2447707901.7195 - val_loss: 1748517998.6207 - val_mean_squared_error: 1748517998.6207\n",
      "Epoch 135/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2316814538.7402 - mean_squared_error: 2316814538.7402 - val_loss: 1743575326.5103 - val_mean_squared_error: 1743575326.5103\n",
      "Epoch 136/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2082665973.4805 - mean_squared_error: 2082665973.4805 - val_loss: 1740576159.7793 - val_mean_squared_error: 1740576159.7793\n",
      "Epoch 137/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2160737658.5563 - mean_squared_error: 2160737658.5563 - val_loss: 1663097512.5517 - val_mean_squared_error: 1663097512.5517\n",
      "Epoch 138/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2224733586.2437 - mean_squared_error: 2224733586.2437 - val_loss: 1697958776.3862 - val_mean_squared_error: 1697958776.3862\n",
      "Epoch 139/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2118594231.3195 - mean_squared_error: 2118594231.3195 - val_loss: 1802635530.3172 - val_mean_squared_error: 1802635530.3172\n",
      "Epoch 140/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2136813340.8368 - mean_squared_error: 2136813340.8368 - val_loss: 1730198125.6276 - val_mean_squared_error: 1730198125.6276\n",
      "Epoch 141/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2095391001.1586 - mean_squared_error: 2095391001.1586 - val_loss: 1748182941.7931 - val_mean_squared_error: 1748182941.7931\n",
      "Epoch 142/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2232512728.1287 - mean_squared_error: 2232512728.1287 - val_loss: 1716025911.5034 - val_mean_squared_error: 1716025911.5034\n"
     ]
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35675.11526823791, 19.820676986564678, 41424.94310802911, 22.13357938904041)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "Train on 870 samples, validate on 290 samples\n",
      "Epoch 1/500\n",
      "870/870 [==============================] - 1s 645us/step - loss: 17239474700.3586 - mean_squared_error: 17239474700.3586 - val_loss: 5220950585.3793 - val_mean_squared_error: 5220950585.3793\n",
      "Epoch 2/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 7097127079.4299 - mean_squared_error: 7097127079.4299 - val_loss: 4091925707.9172 - val_mean_squared_error: 4091925707.9172\n",
      "Epoch 3/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 4779007841.1034 - mean_squared_error: 4779007841.1034 - val_loss: 3060018774.5103 - val_mean_squared_error: 3060018774.5103\n",
      "Epoch 4/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 3892789036.1379 - mean_squared_error: 3892789036.1379 - val_loss: 2619949918.0138 - val_mean_squared_error: 2619949918.0138\n",
      "Epoch 5/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 3609646170.7034 - mean_squared_error: 3609646170.7034 - val_loss: 2715917608.2759 - val_mean_squared_error: 2715917608.2759\n",
      "Epoch 6/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 3010945549.5356 - mean_squared_error: 3010945549.5356 - val_loss: 2173386620.9103 - val_mean_squared_error: 2173386620.9103\n",
      "Epoch 7/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 3143590219.9172 - mean_squared_error: 3143590219.9172 - val_loss: 2227260150.8414 - val_mean_squared_error: 2227260150.8414\n",
      "Epoch 8/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 2730432442.4828 - mean_squared_error: 2730432442.4828 - val_loss: 2381536863.0069 - val_mean_squared_error: 2381536863.0069\n",
      "Epoch 9/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 2898609077.7011 - mean_squared_error: 2898609077.7011 - val_loss: 2317384768.0000 - val_mean_squared_error: 2317384768.0000\n",
      "Epoch 10/500\n",
      "870/870 [==============================] - 0s 258us/step - loss: 2756753862.0322 - mean_squared_error: 2756753862.0322 - val_loss: 1766076754.6483 - val_mean_squared_error: 1766076754.6483\n",
      "Epoch 11/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 2614865832.6069 - mean_squared_error: 2614865832.6069 - val_loss: 1935545295.8897 - val_mean_squared_error: 1935545295.8897\n",
      "Epoch 12/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 2695781909.7747 - mean_squared_error: 2695781909.7747 - val_loss: 2013346857.4897 - val_mean_squared_error: 2013346857.4897\n",
      "Epoch 13/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 3341115666.0966 - mean_squared_error: 3341115666.0966 - val_loss: 2154641201.1034 - val_mean_squared_error: 2154641201.1034\n",
      "Epoch 14/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 2526316073.1954 - mean_squared_error: 2526316073.1954 - val_loss: 1752617372.2483 - val_mean_squared_error: 1752617372.2483\n",
      "Epoch 15/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2829818380.9471 - mean_squared_error: 2829818380.9471 - val_loss: 1776984169.4897 - val_mean_squared_error: 1776984169.4897\n",
      "Epoch 16/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 2473999629.9770 - mean_squared_error: 2473999629.9770 - val_loss: 2016988365.7931 - val_mean_squared_error: 2016988365.7931\n",
      "Epoch 17/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2606687547.2920 - mean_squared_error: 2606687547.2920 - val_loss: 1826440821.7931 - val_mean_squared_error: 1826440821.7931\n",
      "Epoch 18/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2756851140.0460 - mean_squared_error: 2756851140.0460 - val_loss: 1732299793.1034 - val_mean_squared_error: 1732299793.1034\n",
      "Epoch 19/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 2575172223.7057 - mean_squared_error: 2575172223.7057 - val_loss: 1761231625.4345 - val_mean_squared_error: 1761231625.4345\n",
      "Epoch 20/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2492879266.4276 - mean_squared_error: 2492879266.4276 - val_loss: 1637520547.8621 - val_mean_squared_error: 1637520547.8621\n",
      "Epoch 21/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 2831162210.8690 - mean_squared_error: 2831162210.8690 - val_loss: 1727979558.8414 - val_mean_squared_error: 1727979558.8414\n",
      "Epoch 22/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2815701565.2046 - mean_squared_error: 2815701565.2046 - val_loss: 1667912991.5034 - val_mean_squared_error: 1667912991.5034\n",
      "Epoch 23/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2434810524.8368 - mean_squared_error: 2434810524.8368 - val_loss: 1634923077.4069 - val_mean_squared_error: 1634923077.4069\n",
      "Epoch 24/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2620525144.2759 - mean_squared_error: 2620525144.2759 - val_loss: 2019126368.1103 - val_mean_squared_error: 2019126368.1103\n",
      "Epoch 25/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 2425894480.0368 - mean_squared_error: 2425894480.0368 - val_loss: 1947800866.4276 - val_mean_squared_error: 1947800866.4276\n",
      "Epoch 26/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2511185265.6552 - mean_squared_error: 2511185265.6552 - val_loss: 1737521612.1379 - val_mean_squared_error: 1737521612.1379\n",
      "Epoch 27/500\n",
      "870/870 [==============================] - 0s 270us/step - loss: 2371194705.8023 - mean_squared_error: 2371194705.8023 - val_loss: 1664406080.0000 - val_mean_squared_error: 1664406080.0000\n",
      "Epoch 28/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2675089200.8460 - mean_squared_error: 2675089200.8460 - val_loss: 2146966002.4276 - val_mean_squared_error: 2146966002.4276\n",
      "Epoch 29/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 2399858469.6644 - mean_squared_error: 2399858469.6644 - val_loss: 1620304039.7241 - val_mean_squared_error: 1620304039.7241\n",
      "Epoch 30/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 2354015647.4851 - mean_squared_error: 2354015647.4851 - val_loss: 1798103320.9379 - val_mean_squared_error: 1798103320.9379\n",
      "Epoch 31/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 2453260312.1287 - mean_squared_error: 2453260312.1287 - val_loss: 1995668448.2207 - val_mean_squared_error: 1995668448.2207\n",
      "Epoch 32/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 2590391052.9471 - mean_squared_error: 2590391052.9471 - val_loss: 2326456143.5586 - val_mean_squared_error: 2326456143.5586\n",
      "Epoch 33/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 2246012163.8253 - mean_squared_error: 2246012163.8253 - val_loss: 2065157994.7034 - val_mean_squared_error: 2065157994.7034\n",
      "Epoch 34/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2398939084.1379 - mean_squared_error: 2398939084.1379 - val_loss: 1719078487.8345 - val_mean_squared_error: 1719078487.8345\n",
      "Epoch 35/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2363584889.8207 - mean_squared_error: 2363584889.8207 - val_loss: 1752854502.7862 - val_mean_squared_error: 1752854502.7862\n",
      "Epoch 36/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 2806627435.8437 - mean_squared_error: 2806627435.8437 - val_loss: 1860617591.8345 - val_mean_squared_error: 1860617591.8345\n",
      "Epoch 37/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2519850807.0253 - mean_squared_error: 2519850807.0253 - val_loss: 1699551986.0966 - val_mean_squared_error: 1699551986.0966\n",
      "Epoch 38/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 2412109760.4414 - mean_squared_error: 2412109760.4414 - val_loss: 1656215446.9517 - val_mean_squared_error: 1656215446.9517\n",
      "Epoch 39/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2197468936.3862 - mean_squared_error: 2197468936.3862 - val_loss: 1911154452.9655 - val_mean_squared_error: 1911154452.9655\n",
      "Epoch 40/500\n",
      "870/870 [==============================] - 0s 269us/step - loss: 2361129207.2460 - mean_squared_error: 2361129207.2460 - val_loss: 1848981286.8966 - val_mean_squared_error: 1848981286.8966\n",
      "Epoch 41/500\n",
      "870/870 [==============================] - 0s 271us/step - loss: 2507569022.2345 - mean_squared_error: 2507569022.2345 - val_loss: 1799371267.7517 - val_mean_squared_error: 1799371267.7517\n",
      "Epoch 42/500\n",
      "870/870 [==============================] - 0s 268us/step - loss: 2366457765.9586 - mean_squared_error: 2366457765.9586 - val_loss: 1649733437.6828 - val_mean_squared_error: 1649733437.6828\n",
      "Epoch 43/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2383527685.2966 - mean_squared_error: 2383527685.2966 - val_loss: 1599431894.0690 - val_mean_squared_error: 1599431894.0690\n",
      "Epoch 44/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2156665173.3333 - mean_squared_error: 2156665173.3333 - val_loss: 1717004142.0138 - val_mean_squared_error: 1717004142.0138\n",
      "Epoch 45/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2107576459.7701 - mean_squared_error: 2107576459.7701 - val_loss: 1819426336.0000 - val_mean_squared_error: 1819426336.0000\n",
      "Epoch 46/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2114070279.5034 - mean_squared_error: 2114070279.5034 - val_loss: 1772167396.1931 - val_mean_squared_error: 1772167396.1931\n",
      "Epoch 47/500\n",
      "870/870 [==============================] - 0s 258us/step - loss: 2091150037.9218 - mean_squared_error: 2091150037.9218 - val_loss: 1616075351.3931 - val_mean_squared_error: 1616075351.3931\n",
      "Epoch 48/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2003131265.4713 - mean_squared_error: 2003131265.4713 - val_loss: 1934994288.2207 - val_mean_squared_error: 1934994288.2207\n",
      "Epoch 49/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 1960561389.1678 - mean_squared_error: 1960561389.1678 - val_loss: 1767143477.7379 - val_mean_squared_error: 1767143477.7379\n",
      "Epoch 50/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2091465515.5494 - mean_squared_error: 2091465515.5494 - val_loss: 1637282824.1655 - val_mean_squared_error: 1637282824.1655\n",
      "Epoch 51/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2329617877.6276 - mean_squared_error: 2329617877.6276 - val_loss: 1635016154.3724 - val_mean_squared_error: 1635016154.3724\n",
      "Epoch 52/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1994488118.7310 - mean_squared_error: 1994488118.7310 - val_loss: 1516871200.4414 - val_mean_squared_error: 1516871200.4414\n",
      "Epoch 53/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2245264970.7402 - mean_squared_error: 2245264970.7402 - val_loss: 2220243920.1103 - val_mean_squared_error: 2220243920.1103\n",
      "Epoch 54/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2189421643.9172 - mean_squared_error: 2189421643.9172 - val_loss: 1801119041.8759 - val_mean_squared_error: 1801119041.8759\n",
      "Epoch 55/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2286436489.1218 - mean_squared_error: 2286436489.1218 - val_loss: 1509647643.1448 - val_mean_squared_error: 1509647643.1448\n",
      "Epoch 56/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2224699241.3425 - mean_squared_error: 2224699241.3425 - val_loss: 1868970676.3034 - val_mean_squared_error: 1868970676.3034\n",
      "Epoch 57/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 2134055788.2851 - mean_squared_error: 2134055788.2851 - val_loss: 1593288605.5724 - val_mean_squared_error: 1593288605.5724\n",
      "Epoch 58/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2345082721.6920 - mean_squared_error: 2345082721.6920 - val_loss: 1733234695.3931 - val_mean_squared_error: 1733234695.3931\n",
      "Epoch 59/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2240707210.2989 - mean_squared_error: 2240707210.2989 - val_loss: 1807470307.4207 - val_mean_squared_error: 1807470307.4207\n",
      "Epoch 60/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 2094588376.7908 - mean_squared_error: 2094588376.7908 - val_loss: 1547422596.8552 - val_mean_squared_error: 1547422596.8552\n",
      "Epoch 61/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 2022878968.9379 - mean_squared_error: 2022878968.9379 - val_loss: 1749052380.9655 - val_mean_squared_error: 1749052380.9655\n",
      "Epoch 62/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1920699041.8391 - mean_squared_error: 1920699041.8391 - val_loss: 1723126784.3310 - val_mean_squared_error: 1723126784.3310\n",
      "Epoch 63/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1859785725.4989 - mean_squared_error: 1859785725.4989 - val_loss: 1798944740.4138 - val_mean_squared_error: 1798944740.4138\n",
      "Epoch 64/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 2099559604.0828 - mean_squared_error: 2099559604.0828 - val_loss: 1861537015.7241 - val_mean_squared_error: 1861537015.7241\n",
      "Epoch 65/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 2075692990.0874 - mean_squared_error: 2075692990.0874 - val_loss: 1668764992.3310 - val_mean_squared_error: 1668764992.3310\n",
      "Epoch 66/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1867498792.6069 - mean_squared_error: 1867498792.6069 - val_loss: 1864610530.9793 - val_mean_squared_error: 1864610530.9793\n",
      "Epoch 67/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 2016218754.0598 - mean_squared_error: 2016218754.0598 - val_loss: 1729110391.7241 - val_mean_squared_error: 1729110391.7241\n",
      "Epoch 68/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1902099024.9195 - mean_squared_error: 1902099024.9195 - val_loss: 1728743682.3172 - val_mean_squared_error: 1728743682.3172\n",
      "Epoch 69/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1939553664.5885 - mean_squared_error: 1939553664.5885 - val_loss: 2452438318.7862 - val_mean_squared_error: 2452438318.7862\n",
      "Epoch 70/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1898281009.4345 - mean_squared_error: 1898281009.4345 - val_loss: 1659601385.9310 - val_mean_squared_error: 1659601385.9310\n",
      "Epoch 71/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1816045139.7149 - mean_squared_error: 1816045139.7149 - val_loss: 1625194438.1793 - val_mean_squared_error: 1625194438.1793\n",
      "Epoch 72/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1931176039.4299 - mean_squared_error: 1931176039.4299 - val_loss: 1504569604.6345 - val_mean_squared_error: 1504569604.6345\n",
      "Epoch 73/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1934596136.0184 - mean_squared_error: 1934596136.0184 - val_loss: 4919688591.0069 - val_mean_squared_error: 4919688591.0069\n",
      "Epoch 74/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2224185640.6069 - mean_squared_error: 2224185640.6069 - val_loss: 1696016606.8966 - val_mean_squared_error: 1696016606.8966\n",
      "Epoch 75/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2042680927.9264 - mean_squared_error: 2042680927.9264 - val_loss: 1636542231.1724 - val_mean_squared_error: 1636542231.1724\n",
      "Epoch 76/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 2269347238.4000 - mean_squared_error: 2269347238.4000 - val_loss: 1682122555.1448 - val_mean_squared_error: 1682122555.1448\n",
      "Epoch 77/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1831816816.1103 - mean_squared_error: 1831816816.1103 - val_loss: 1657039360.1103 - val_mean_squared_error: 1657039360.1103\n",
      "Epoch 78/500\n",
      "870/870 [==============================] - 0s 268us/step - loss: 1715781244.1747 - mean_squared_error: 1715781244.1747 - val_loss: 1607749182.6759 - val_mean_squared_error: 1607749182.6759\n",
      "Epoch 79/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1941755824.5885 - mean_squared_error: 1941755824.5885 - val_loss: 1823289042.0966 - val_mean_squared_error: 1823289042.0966\n",
      "Epoch 80/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1909772724.9287 - mean_squared_error: 1909772724.9287 - val_loss: 1592231478.6207 - val_mean_squared_error: 1592231478.6207\n",
      "Epoch 81/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1989702712.4966 - mean_squared_error: 1989702712.4966 - val_loss: 1682972204.1379 - val_mean_squared_error: 1682972204.1379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1774307539.2736 - mean_squared_error: 1774307539.2736 - val_loss: 2243614284.3586 - val_mean_squared_error: 2243614284.3586\n",
      "Epoch 83/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1825978157.1678 - mean_squared_error: 1825978157.1678 - val_loss: 1591641062.1793 - val_mean_squared_error: 1591641062.1793\n",
      "Epoch 84/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1788730721.6920 - mean_squared_error: 1788730721.6920 - val_loss: 1569999120.5517 - val_mean_squared_error: 1569999120.5517\n",
      "Epoch 85/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1752451546.9241 - mean_squared_error: 1752451546.9241 - val_loss: 1648279241.7103 - val_mean_squared_error: 1648279241.7103\n",
      "Epoch 86/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1699597335.5402 - mean_squared_error: 1699597335.5402 - val_loss: 1493729471.5586 - val_mean_squared_error: 1493729471.5586\n",
      "Epoch 87/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1823899870.3080 - mean_squared_error: 1823899870.3080 - val_loss: 1477487568.9379 - val_mean_squared_error: 1477487568.9379\n",
      "Epoch 88/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2043601466.9241 - mean_squared_error: 2043601466.9241 - val_loss: 1751640070.6207 - val_mean_squared_error: 1751640070.6207\n",
      "Epoch 89/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1756383929.0851 - mean_squared_error: 1756383929.0851 - val_loss: 1936003422.5655 - val_mean_squared_error: 1936003422.5655\n",
      "Epoch 90/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 2011961935.4483 - mean_squared_error: 2011961935.4483 - val_loss: 1793448711.1172 - val_mean_squared_error: 1793448711.1172\n",
      "Epoch 91/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 1905802002.8322 - mean_squared_error: 1905802002.8322 - val_loss: 1572968487.3379 - val_mean_squared_error: 1572968487.3379\n",
      "Epoch 92/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1603164196.7816 - mean_squared_error: 1603164196.7816 - val_loss: 1942712381.2414 - val_mean_squared_error: 1942712381.2414\n",
      "Epoch 93/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1946451907.9724 - mean_squared_error: 1946451907.9724 - val_loss: 1480740639.3379 - val_mean_squared_error: 1480740639.3379\n",
      "Epoch 94/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 2083344427.9908 - mean_squared_error: 2083344427.9908 - val_loss: 1986000307.3103 - val_mean_squared_error: 1986000307.3103\n",
      "Epoch 95/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1864681130.0782 - mean_squared_error: 1864681130.0782 - val_loss: 1552836170.1517 - val_mean_squared_error: 1552836170.1517\n",
      "Epoch 96/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1763050341.2230 - mean_squared_error: 1763050341.2230 - val_loss: 1986865457.4345 - val_mean_squared_error: 1986865457.4345\n",
      "Epoch 97/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 1748003799.9816 - mean_squared_error: 1748003799.9816 - val_loss: 1719974747.0897 - val_mean_squared_error: 1719974747.0897\n",
      "Epoch 98/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1753887885.5356 - mean_squared_error: 1753887885.5356 - val_loss: 1962168878.6759 - val_mean_squared_error: 1962168878.6759\n",
      "Epoch 99/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1675972163.3839 - mean_squared_error: 1675972163.3839 - val_loss: 1590499975.9448 - val_mean_squared_error: 1590499975.9448\n",
      "Epoch 100/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1795627786.2989 - mean_squared_error: 1795627786.2989 - val_loss: 1564518298.4828 - val_mean_squared_error: 1564518298.4828\n",
      "Epoch 101/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1797079315.4207 - mean_squared_error: 1797079315.4207 - val_loss: 1568590487.0621 - val_mean_squared_error: 1568590487.0621\n",
      "Epoch 102/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1754219130.1149 - mean_squared_error: 1754219130.1149 - val_loss: 1655512712.4966 - val_mean_squared_error: 1655512712.4966\n",
      "Epoch 103/500\n",
      "870/870 [==============================] - 0s 258us/step - loss: 1632743602.3172 - mean_squared_error: 1632743602.3172 - val_loss: 1652445395.4207 - val_mean_squared_error: 1652445395.4207\n",
      "Epoch 104/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1800689021.2046 - mean_squared_error: 1800689021.2046 - val_loss: 1592414079.2828 - val_mean_squared_error: 1592414079.2828\n",
      "Epoch 105/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1843744167.7241 - mean_squared_error: 1843744167.7241 - val_loss: 1555281256.8828 - val_mean_squared_error: 1555281256.8828\n",
      "Epoch 106/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1614240394.2989 - mean_squared_error: 1614240394.2989 - val_loss: 1607763663.8897 - val_mean_squared_error: 1607763663.8897\n",
      "Epoch 107/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1644497196.8736 - mean_squared_error: 1644497196.8736 - val_loss: 1525945296.8828 - val_mean_squared_error: 1525945296.8828\n",
      "Epoch 108/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1371026741.8483 - mean_squared_error: 1371026741.8483 - val_loss: 1384796893.1310 - val_mean_squared_error: 1384796893.1310\n",
      "Epoch 109/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1490035858.2437 - mean_squared_error: 1490035858.2437 - val_loss: 1568715525.1862 - val_mean_squared_error: 1568715525.1862\n",
      "Epoch 110/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1569851809.2506 - mean_squared_error: 1569851809.2506 - val_loss: 2067012332.9103 - val_mean_squared_error: 2067012332.9103\n",
      "Epoch 111/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1427171863.3563 - mean_squared_error: 1427171863.3563 - val_loss: 1353341876.4138 - val_mean_squared_error: 1353341876.4138\n",
      "Epoch 112/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1526516585.9310 - mean_squared_error: 1526516585.9310 - val_loss: 1553322376.0552 - val_mean_squared_error: 1553322376.0552\n",
      "Epoch 113/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1657559432.5333 - mean_squared_error: 1657559432.5333 - val_loss: 1396911037.7655 - val_mean_squared_error: 1396911037.7655\n",
      "Epoch 114/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1501112510.0138 - mean_squared_error: 1501112510.0138 - val_loss: 1467161785.9034 - val_mean_squared_error: 1467161785.9034\n",
      "Epoch 115/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 2230388645.3701 - mean_squared_error: 2230388645.3701 - val_loss: 1541643611.1448 - val_mean_squared_error: 1541643611.1448\n",
      "Epoch 116/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1809674378.0046 - mean_squared_error: 1809674378.0046 - val_loss: 1613063622.2345 - val_mean_squared_error: 1613063622.2345\n",
      "Epoch 117/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1587935214.7126 - mean_squared_error: 1587935214.7126 - val_loss: 1569621675.1448 - val_mean_squared_error: 1569621675.1448\n",
      "Epoch 118/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1637275123.0529 - mean_squared_error: 1637275123.0529 - val_loss: 1459814406.9793 - val_mean_squared_error: 1459814406.9793\n",
      "Epoch 119/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1392108618.1517 - mean_squared_error: 1392108618.1517 - val_loss: 1433011577.4345 - val_mean_squared_error: 1433011577.4345\n",
      "Epoch 120/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1515959674.1149 - mean_squared_error: 1515959674.1149 - val_loss: 1835846012.4690 - val_mean_squared_error: 1835846012.4690\n",
      "Epoch 121/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1575951377.3609 - mean_squared_error: 1575951377.3609 - val_loss: 1657724056.4966 - val_mean_squared_error: 1657724056.4966\n",
      "Epoch 122/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1398823462.2529 - mean_squared_error: 1398823462.2529 - val_loss: 1451044685.2414 - val_mean_squared_error: 1451044685.2414\n",
      "Epoch 123/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1591829445.4437 - mean_squared_error: 1591829445.4437 - val_loss: 1383339064.5517 - val_mean_squared_error: 1383339064.5517\n",
      "Epoch 124/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1412098189.2414 - mean_squared_error: 1412098189.2414 - val_loss: 1485303191.5034 - val_mean_squared_error: 1485303191.5034\n",
      "Epoch 125/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1513086478.7126 - mean_squared_error: 1513086478.7126 - val_loss: 1489789512.8828 - val_mean_squared_error: 1489789512.8828\n",
      "Epoch 126/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1412977474.5011 - mean_squared_error: 1412977474.5011 - val_loss: 1245585104.8276 - val_mean_squared_error: 1245585104.8276\n",
      "Epoch 127/500\n",
      "870/870 [==============================] - 0s 268us/step - loss: 1488909238.1425 - mean_squared_error: 1488909238.1425 - val_loss: 1586388837.2414 - val_mean_squared_error: 1586388837.2414\n",
      "Epoch 128/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 1416914452.4506 - mean_squared_error: 1416914452.4506 - val_loss: 1506431356.8000 - val_mean_squared_error: 1506431356.8000\n",
      "Epoch 129/500\n",
      "870/870 [==============================] - 0s 258us/step - loss: 1326324000.0736 - mean_squared_error: 1326324000.0736 - val_loss: 1257136428.9103 - val_mean_squared_error: 1257136428.9103\n",
      "Epoch 130/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1663429245.9402 - mean_squared_error: 1663429245.9402 - val_loss: 1319549937.7655 - val_mean_squared_error: 1319549937.7655\n",
      "Epoch 131/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1887303061.4805 - mean_squared_error: 1887303061.4805 - val_loss: 1863386810.4828 - val_mean_squared_error: 1863386810.4828\n",
      "Epoch 132/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1440545955.6046 - mean_squared_error: 1440545955.6046 - val_loss: 1813619362.4276 - val_mean_squared_error: 1813619362.4276\n",
      "Epoch 133/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1531652672.7356 - mean_squared_error: 1531652672.7356 - val_loss: 1372501328.1103 - val_mean_squared_error: 1372501328.1103\n",
      "Epoch 134/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1414679577.4529 - mean_squared_error: 1414679577.4529 - val_loss: 1262226066.8138 - val_mean_squared_error: 1262226066.8138\n",
      "Epoch 135/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1586606631.1356 - mean_squared_error: 1586606631.1356 - val_loss: 1464144806.5655 - val_mean_squared_error: 1464144806.5655\n",
      "Epoch 136/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1426270886.5471 - mean_squared_error: 1426270886.5471 - val_loss: 1399335925.6276 - val_mean_squared_error: 1399335925.6276\n",
      "Epoch 137/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1643480185.6736 - mean_squared_error: 1643480185.6736 - val_loss: 1249017441.7655 - val_mean_squared_error: 1249017441.7655\n",
      "Epoch 138/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1562373714.0966 - mean_squared_error: 1562373714.0966 - val_loss: 1489252294.1241 - val_mean_squared_error: 1489252294.1241\n",
      "Epoch 139/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1562137022.3816 - mean_squared_error: 1562137022.3816 - val_loss: 1516765860.1379 - val_mean_squared_error: 1516765860.1379\n",
      "Epoch 140/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1355734150.7678 - mean_squared_error: 1355734150.7678 - val_loss: 1190392933.1862 - val_mean_squared_error: 1190392933.1862\n",
      "Epoch 141/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1427196656.1103 - mean_squared_error: 1427196656.1103 - val_loss: 1474956925.9034 - val_mean_squared_error: 1474956925.9034\n",
      "Epoch 142/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1307167641.9678 - mean_squared_error: 1307167641.9678 - val_loss: 1246307081.8207 - val_mean_squared_error: 1246307081.8207\n",
      "Epoch 143/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1380055261.8667 - mean_squared_error: 1380055261.8667 - val_loss: 1302613502.2345 - val_mean_squared_error: 1302613502.2345\n",
      "Epoch 144/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1119936016.4782 - mean_squared_error: 1119936016.4782 - val_loss: 1161300602.8138 - val_mean_squared_error: 1161300602.8138\n",
      "Epoch 145/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 1469136829.4989 - mean_squared_error: 1469136829.4989 - val_loss: 1507056382.1793 - val_mean_squared_error: 1507056382.1793\n",
      "Epoch 146/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1355611132.0276 - mean_squared_error: 1355611132.0276 - val_loss: 1181636218.2621 - val_mean_squared_error: 1181636218.2621\n",
      "Epoch 147/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1322492982.7310 - mean_squared_error: 1322492982.7310 - val_loss: 1348473783.3931 - val_mean_squared_error: 1348473783.3931\n",
      "Epoch 148/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1658957683.3471 - mean_squared_error: 1658957683.3471 - val_loss: 1515233907.8621 - val_mean_squared_error: 1515233907.8621\n",
      "Epoch 149/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1493074419.6414 - mean_squared_error: 1493074419.6414 - val_loss: 1411517103.1172 - val_mean_squared_error: 1411517103.1172\n",
      "Epoch 150/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1349770648.5701 - mean_squared_error: 1349770648.5701 - val_loss: 1492657452.3034 - val_mean_squared_error: 1492657452.3034\n",
      "Epoch 151/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1349664373.7011 - mean_squared_error: 1349664373.7011 - val_loss: 2863927804.9103 - val_mean_squared_error: 2863927804.9103\n",
      "Epoch 152/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1504225463.6138 - mean_squared_error: 1504225463.6138 - val_loss: 1484246547.6414 - val_mean_squared_error: 1484246547.6414\n",
      "Epoch 153/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1376964797.2046 - mean_squared_error: 1376964797.2046 - val_loss: 1236474970.9241 - val_mean_squared_error: 1236474970.9241\n",
      "Epoch 154/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1206999856.4046 - mean_squared_error: 1206999856.4046 - val_loss: 1305503572.8552 - val_mean_squared_error: 1305503572.8552\n",
      "Epoch 155/500\n",
      "870/870 [==============================] - 0s 258us/step - loss: 1537882523.0713 - mean_squared_error: 1537882523.0713 - val_loss: 1359372655.6690 - val_mean_squared_error: 1359372655.6690\n",
      "Epoch 156/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1257114101.1126 - mean_squared_error: 1257114101.1126 - val_loss: 1555734044.6897 - val_mean_squared_error: 1555734044.6897\n",
      "Epoch 157/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1172133493.9586 - mean_squared_error: 1172133493.9586 - val_loss: 1260521816.1931 - val_mean_squared_error: 1260521816.1931\n",
      "Epoch 158/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1388518776.5701 - mean_squared_error: 1388518776.5701 - val_loss: 1456790212.1103 - val_mean_squared_error: 1456790212.1103\n",
      "Epoch 159/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1428705584.6253 - mean_squared_error: 1428705584.6253 - val_loss: 1352385688.4966 - val_mean_squared_error: 1352385688.4966\n",
      "Epoch 160/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1332287453.5724 - mean_squared_error: 1332287453.5724 - val_loss: 1700025369.6000 - val_mean_squared_error: 1700025369.6000\n",
      "Epoch 161/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1349404098.8690 - mean_squared_error: 1349404098.8690 - val_loss: 1293970636.1931 - val_mean_squared_error: 1293970636.1931\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 0s 261us/step - loss: 1158225668.3402 - mean_squared_error: 1158225668.3402 - val_loss: 1118620584.4414 - val_mean_squared_error: 1118620584.4414\n",
      "Epoch 163/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1853630367.4851 - mean_squared_error: 1853630367.4851 - val_loss: 2038064165.5724 - val_mean_squared_error: 2038064165.5724\n",
      "Epoch 164/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1965805031.2828 - mean_squared_error: 1965805031.2828 - val_loss: 1623762220.4690 - val_mean_squared_error: 1623762220.4690\n",
      "Epoch 165/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1315129710.0506 - mean_squared_error: 1315129710.0506 - val_loss: 1577603031.3931 - val_mean_squared_error: 1577603031.3931\n",
      "Epoch 166/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1318246385.1402 - mean_squared_error: 1318246385.1402 - val_loss: 1199016736.1103 - val_mean_squared_error: 1199016736.1103\n",
      "Epoch 167/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 1263004246.5103 - mean_squared_error: 1263004246.5103 - val_loss: 1431922649.3793 - val_mean_squared_error: 1431922649.3793\n",
      "Epoch 168/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1415573032.2023 - mean_squared_error: 1415573032.2023 - val_loss: 1248326126.8966 - val_mean_squared_error: 1248326126.8966\n",
      "Epoch 169/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1331665571.3839 - mean_squared_error: 1331665571.3839 - val_loss: 1381812767.5586 - val_mean_squared_error: 1381812767.5586\n",
      "Epoch 170/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1266627388.4690 - mean_squared_error: 1266627388.4690 - val_loss: 1247227840.3310 - val_mean_squared_error: 1247227840.3310\n",
      "Epoch 171/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1354453382.0322 - mean_squared_error: 1354453382.0322 - val_loss: 1596745375.3379 - val_mean_squared_error: 1596745375.3379\n",
      "Epoch 172/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1207999104.2943 - mean_squared_error: 1207999104.2943 - val_loss: 1227082211.1448 - val_mean_squared_error: 1227082211.1448\n",
      "Epoch 173/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1359001401.1218 - mean_squared_error: 1359001401.1218 - val_loss: 1327269807.9724 - val_mean_squared_error: 1327269807.9724\n",
      "Epoch 174/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1285107191.8345 - mean_squared_error: 1285107191.8345 - val_loss: 1085885837.2414 - val_mean_squared_error: 1085885837.2414\n",
      "Epoch 175/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 1399323125.2598 - mean_squared_error: 1399323125.2598 - val_loss: 1251251415.2276 - val_mean_squared_error: 1251251415.2276\n",
      "Epoch 176/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1180786388.0092 - mean_squared_error: 1180786388.0092 - val_loss: 1215100280.9655 - val_mean_squared_error: 1215100280.9655\n",
      "Epoch 177/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 1303108743.9448 - mean_squared_error: 1303108743.9448 - val_loss: 1240817504.2207 - val_mean_squared_error: 1240817504.2207\n",
      "Epoch 178/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1241429944.7172 - mean_squared_error: 1241429944.7172 - val_loss: 1218690787.6966 - val_mean_squared_error: 1218690787.6966\n",
      "Epoch 179/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1151778043.8805 - mean_squared_error: 1151778043.8805 - val_loss: 1184938322.5931 - val_mean_squared_error: 1184938322.5931\n",
      "Epoch 180/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1186639140.7816 - mean_squared_error: 1186639140.7816 - val_loss: 1132844528.9931 - val_mean_squared_error: 1132844528.9931\n",
      "Epoch 181/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1316905941.3333 - mean_squared_error: 1316905941.3333 - val_loss: 1406597535.7241 - val_mean_squared_error: 1406597535.7241\n",
      "Epoch 182/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1310254511.9632 - mean_squared_error: 1310254511.9632 - val_loss: 1062613493.9310 - val_mean_squared_error: 1062613493.9310\n",
      "Epoch 183/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1461916586.8138 - mean_squared_error: 1461916586.8138 - val_loss: 1221037229.6828 - val_mean_squared_error: 1221037229.6828\n",
      "Epoch 184/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1132186522.3356 - mean_squared_error: 1132186522.3356 - val_loss: 1118183291.9172 - val_mean_squared_error: 1118183291.9172\n",
      "Epoch 185/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1645293063.2644 - mean_squared_error: 1645293063.2644 - val_loss: 2200638412.6897 - val_mean_squared_error: 2200638412.6897\n",
      "Epoch 186/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1337942110.1609 - mean_squared_error: 1337942110.1609 - val_loss: 1268380037.2414 - val_mean_squared_error: 1268380037.2414\n",
      "Epoch 187/500\n",
      "870/870 [==============================] - 0s 271us/step - loss: 1206911532.8736 - mean_squared_error: 1206911532.8736 - val_loss: 1379281597.1310 - val_mean_squared_error: 1379281597.1310\n",
      "Epoch 188/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1077322134.8782 - mean_squared_error: 1077322134.8782 - val_loss: 1148311893.9034 - val_mean_squared_error: 1148311893.9034\n",
      "Epoch 189/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1072843126.8782 - mean_squared_error: 1072843126.8782 - val_loss: 1241672868.4138 - val_mean_squared_error: 1241672868.4138\n",
      "Epoch 190/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1207422686.9701 - mean_squared_error: 1207422686.9701 - val_loss: 981692174.5655 - val_mean_squared_error: 981692174.5655\n",
      "Epoch 191/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1364608688.8460 - mean_squared_error: 1364608688.8460 - val_loss: 1115579062.3448 - val_mean_squared_error: 1115579062.3448\n",
      "Epoch 192/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1267564311.5402 - mean_squared_error: 1267564311.5402 - val_loss: 1205120914.4276 - val_mean_squared_error: 1205120914.4276\n",
      "Epoch 193/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 1190900507.0713 - mean_squared_error: 1190900507.0713 - val_loss: 1190183049.9586 - val_mean_squared_error: 1190183049.9586\n",
      "Epoch 194/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1224253232.8460 - mean_squared_error: 1224253232.8460 - val_loss: 1235715239.1724 - val_mean_squared_error: 1235715239.1724\n",
      "Epoch 195/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1188840254.3080 - mean_squared_error: 1188840254.3080 - val_loss: 1414754537.4897 - val_mean_squared_error: 1414754537.4897\n",
      "Epoch 196/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1161887329.2506 - mean_squared_error: 1161887329.2506 - val_loss: 1632315383.6138 - val_mean_squared_error: 1632315383.6138\n",
      "Epoch 197/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1178866199.3931 - mean_squared_error: 1178866199.3931 - val_loss: 1120715318.8414 - val_mean_squared_error: 1120715318.8414\n",
      "Epoch 198/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1194439756.8736 - mean_squared_error: 1194439756.8736 - val_loss: 1124835076.5793 - val_mean_squared_error: 1124835076.5793\n",
      "Epoch 199/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1065007402.0046 - mean_squared_error: 1065007402.0046 - val_loss: 1136751843.4483 - val_mean_squared_error: 1136751843.4483\n",
      "Epoch 200/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1085468185.3057 - mean_squared_error: 1085468185.3057 - val_loss: 1035014456.7724 - val_mean_squared_error: 1035014456.7724\n",
      "Epoch 201/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1692622370.5011 - mean_squared_error: 1692622370.5011 - val_loss: 1365428140.2483 - val_mean_squared_error: 1365428140.2483\n",
      "Epoch 202/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1366061482.3724 - mean_squared_error: 1366061482.3724 - val_loss: 1368659815.8345 - val_mean_squared_error: 1368659815.8345\n",
      "Epoch 203/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1191295250.0966 - mean_squared_error: 1191295250.0966 - val_loss: 1344136390.9517 - val_mean_squared_error: 1344136390.9517\n",
      "Epoch 204/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1264217656.4966 - mean_squared_error: 1264217656.4966 - val_loss: 1278381790.6483 - val_mean_squared_error: 1278381790.6483\n",
      "Epoch 205/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1400970930.9057 - mean_squared_error: 1400970930.9057 - val_loss: 1309433024.0552 - val_mean_squared_error: 1309433024.0552\n",
      "Epoch 206/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1304493814.5839 - mean_squared_error: 1304493814.5839 - val_loss: 1451364652.8000 - val_mean_squared_error: 1451364652.8000\n",
      "Epoch 207/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1180022580.4506 - mean_squared_error: 1180022580.4506 - val_loss: 1091368401.8207 - val_mean_squared_error: 1091368401.8207\n",
      "Epoch 208/500\n",
      "870/870 [==============================] - 0s 266us/step - loss: 1194944327.6506 - mean_squared_error: 1194944327.6506 - val_loss: 1454107122.7586 - val_mean_squared_error: 1454107122.7586\n",
      "Epoch 209/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1193637900.3954 - mean_squared_error: 1193637900.3954 - val_loss: 1447160104.0552 - val_mean_squared_error: 1447160104.0552\n",
      "Epoch 210/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1047449984.2943 - mean_squared_error: 1047449984.2943 - val_loss: 1058069255.6690 - val_mean_squared_error: 1058069255.6690\n",
      "Epoch 211/500\n",
      "870/870 [==============================] - 0s 265us/step - loss: 1108022674.8322 - mean_squared_error: 1108022674.8322 - val_loss: 1138220674.2069 - val_mean_squared_error: 1138220674.2069\n",
      "Epoch 212/500\n",
      "870/870 [==============================] - 0s 259us/step - loss: 1290085735.8713 - mean_squared_error: 1290085735.8713 - val_loss: 1176944588.6345 - val_mean_squared_error: 1176944588.6345\n",
      "Epoch 213/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1160553792.5885 - mean_squared_error: 1160553792.5885 - val_loss: 1233822671.4483 - val_mean_squared_error: 1233822671.4483\n",
      "Epoch 214/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1102181425.1402 - mean_squared_error: 1102181425.1402 - val_loss: 1122195770.5931 - val_mean_squared_error: 1122195770.5931\n",
      "Epoch 215/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 965620229.4437 - mean_squared_error: 965620229.4437 - val_loss: 1123377209.3793 - val_mean_squared_error: 1123377209.3793\n",
      "Epoch 216/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1325212267.6230 - mean_squared_error: 1325212267.6230 - val_loss: 1760058171.5862 - val_mean_squared_error: 1760058171.5862\n",
      "Epoch 217/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1178492689.6552 - mean_squared_error: 1178492689.6552 - val_loss: 1515666632.6069 - val_mean_squared_error: 1515666632.6069\n",
      "Epoch 218/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1077215229.5724 - mean_squared_error: 1077215229.5724 - val_loss: 1317052190.8414 - val_mean_squared_error: 1317052190.8414\n",
      "Epoch 219/500\n",
      "870/870 [==============================] - 0s 269us/step - loss: 1094035432.9747 - mean_squared_error: 1094035432.9747 - val_loss: 1317760925.4345 - val_mean_squared_error: 1317760925.4345\n",
      "Epoch 220/500\n",
      "870/870 [==============================] - 0s 268us/step - loss: 1115065296.2575 - mean_squared_error: 1115065296.2575 - val_loss: 1163941474.1793 - val_mean_squared_error: 1163941474.1793\n",
      "Epoch 221/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1143213831.5770 - mean_squared_error: 1143213831.5770 - val_loss: 1256312386.3724 - val_mean_squared_error: 1256312386.3724\n",
      "Epoch 222/500\n",
      "870/870 [==============================] - 0s 270us/step - loss: 1032203423.0437 - mean_squared_error: 1032203423.0437 - val_loss: 984190678.6207 - val_mean_squared_error: 984190678.6207\n",
      "Epoch 223/500\n",
      "870/870 [==============================] - 0s 263us/step - loss: 1105827483.8069 - mean_squared_error: 1105827483.8069 - val_loss: 1370540025.7103 - val_mean_squared_error: 1370540025.7103\n",
      "Epoch 224/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 1141010446.7126 - mean_squared_error: 1141010446.7126 - val_loss: 1034618248.2759 - val_mean_squared_error: 1034618248.2759\n",
      "Epoch 225/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1053327897.8943 - mean_squared_error: 1053327897.8943 - val_loss: 1213563716.7448 - val_mean_squared_error: 1213563716.7448\n",
      "Epoch 226/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1147334768.8828 - mean_squared_error: 1147334768.8828 - val_loss: 992151995.1448 - val_mean_squared_error: 992151995.1448\n",
      "Epoch 227/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1019643944.6069 - mean_squared_error: 1019643944.6069 - val_loss: 1164865565.4069 - val_mean_squared_error: 1164865565.4069\n",
      "Epoch 228/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1149689029.5908 - mean_squared_error: 1149689029.5908 - val_loss: 1040598097.9862 - val_mean_squared_error: 1040598097.9862\n",
      "Epoch 229/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1115439116.3586 - mean_squared_error: 1115439116.3586 - val_loss: 1188973293.3517 - val_mean_squared_error: 1188973293.3517\n",
      "Epoch 230/500\n",
      "870/870 [==============================] - 0s 264us/step - loss: 1137412877.6828 - mean_squared_error: 1137412877.6828 - val_loss: 993907154.6483 - val_mean_squared_error: 993907154.6483\n",
      "Epoch 231/500\n",
      "870/870 [==============================] - 0s 269us/step - loss: 1053814304.9563 - mean_squared_error: 1053814304.9563 - val_loss: 1211839803.5586 - val_mean_squared_error: 1211839803.5586\n",
      "Epoch 232/500\n",
      "870/870 [==============================] - 0s 267us/step - loss: 1084987975.2092 - mean_squared_error: 1084987975.2092 - val_loss: 1395101345.5448 - val_mean_squared_error: 1395101345.5448\n",
      "Epoch 233/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 983887806.0874 - mean_squared_error: 983887806.0874 - val_loss: 1381163820.1379 - val_mean_squared_error: 1381163820.1379\n",
      "Epoch 234/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1137742438.1057 - mean_squared_error: 1137742438.1057 - val_loss: 1167886804.7724 - val_mean_squared_error: 1167886804.7724\n",
      "Epoch 235/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1062023751.9448 - mean_squared_error: 1062023751.9448 - val_loss: 990351729.7103 - val_mean_squared_error: 990351729.7103\n",
      "Epoch 236/500\n",
      "870/870 [==============================] - 0s 261us/step - loss: 1156917282.1333 - mean_squared_error: 1156917282.1333 - val_loss: 1272542125.6828 - val_mean_squared_error: 1272542125.6828\n",
      "Epoch 237/500\n",
      "870/870 [==============================] - 0s 268us/step - loss: 987294864.0368 - mean_squared_error: 987294864.0368 - val_loss: 1030312942.0690 - val_mean_squared_error: 1030312942.0690\n",
      "Epoch 238/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1284468751.1540 - mean_squared_error: 1284468751.1540 - val_loss: 1180165994.3172 - val_mean_squared_error: 1180165994.3172\n",
      "Epoch 239/500\n",
      "870/870 [==============================] - 0s 262us/step - loss: 1264015416.7908 - mean_squared_error: 1264015416.7908 - val_loss: 1368987841.7655 - val_mean_squared_error: 1368987841.7655\n",
      "Epoch 240/500\n",
      "870/870 [==============================] - 0s 260us/step - loss: 1122914345.7839 - mean_squared_error: 1122914345.7839 - val_loss: 1590098432.0000 - val_mean_squared_error: 1590098432.0000\n"
     ]
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34433.73763803584, 19.13098208742896, 39876.03827449469, 21.305990851146735)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Zero Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_zero = df[df['sum_of_intensities'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_features = list(df_non_zero['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "Train on 870 samples, validate on 290 samples\n",
      "Epoch 1/500\n",
      "870/870 [==============================] - 0s 433us/step - loss: 35574007812.7080 - mean_squared_error: 35574007812.7080 - val_loss: 34774573889.3241 - val_mean_squared_error: 34774573889.3241\n",
      "Epoch 2/500\n",
      "870/870 [==============================] - 0s 112us/step - loss: 27417852534.8782 - mean_squared_error: 27417852534.8782 - val_loss: 23517212926.2345 - val_mean_squared_error: 23517212926.2345\n",
      "Epoch 3/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 18283679160.2023 - mean_squared_error: 18283679160.2023 - val_loss: 14392677594.9241 - val_mean_squared_error: 14392677594.9241\n",
      "Epoch 4/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 13306831215.2276 - mean_squared_error: 13306831215.2276 - val_loss: 9735694607.8897 - val_mean_squared_error: 9735694607.8897\n",
      "Epoch 5/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 11740242468.4874 - mean_squared_error: 11740242468.4874 - val_loss: 8454458590.4552 - val_mean_squared_error: 8454458590.4552\n",
      "Epoch 6/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 10679670014.2345 - mean_squared_error: 10679670014.2345 - val_loss: 7484629752.0552 - val_mean_squared_error: 7484629752.0552\n",
      "Epoch 7/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 9188301116.6161 - mean_squared_error: 9188301116.6161 - val_loss: 6410857095.9448 - val_mean_squared_error: 6410857095.9448\n",
      "Epoch 8/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 8395768848.4782 - mean_squared_error: 8395768848.4782 - val_loss: 5510125039.2276 - val_mean_squared_error: 5510125039.2276\n",
      "Epoch 9/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 7529511002.0414 - mean_squared_error: 7529511002.0414 - val_loss: 4937087473.8759 - val_mean_squared_error: 4937087473.8759\n",
      "Epoch 10/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 6558072389.4437 - mean_squared_error: 6558072389.4437 - val_loss: 4453514218.8138 - val_mean_squared_error: 4453514218.8138\n",
      "Epoch 11/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 6256722070.6575 - mean_squared_error: 6256722070.6575 - val_loss: 4001994936.4966 - val_mean_squared_error: 4001994936.4966\n",
      "Epoch 12/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 5343316651.1080 - mean_squared_error: 5343316651.1080 - val_loss: 3544508377.6000 - val_mean_squared_error: 3544508377.6000\n",
      "Epoch 13/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 4778608399.3011 - mean_squared_error: 4778608399.3011 - val_loss: 3302013221.0759 - val_mean_squared_error: 3302013221.0759\n",
      "Epoch 14/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 4189137563.9540 - mean_squared_error: 4189137563.9540 - val_loss: 2956302044.2483 - val_mean_squared_error: 2956302044.2483\n",
      "Epoch 15/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 3769299353.8943 - mean_squared_error: 3769299353.8943 - val_loss: 2653482568.3862 - val_mean_squared_error: 2653482568.3862\n",
      "Epoch 16/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 3460203221.4805 - mean_squared_error: 3460203221.4805 - val_loss: 2497632435.6414 - val_mean_squared_error: 2497632435.6414\n",
      "Epoch 17/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 3223876382.0138 - mean_squared_error: 3223876382.0138 - val_loss: 2333083651.5310 - val_mean_squared_error: 2333083651.5310\n",
      "Epoch 18/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 3140453835.0345 - mean_squared_error: 3140453835.0345 - val_loss: 2194997197.6828 - val_mean_squared_error: 2194997197.6828\n",
      "Epoch 19/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 3184515212.9471 - mean_squared_error: 3184515212.9471 - val_loss: 2192949494.7310 - val_mean_squared_error: 2192949494.7310\n",
      "Epoch 20/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 3049430360.4230 - mean_squared_error: 3049430360.4230 - val_loss: 2156288226.4276 - val_mean_squared_error: 2156288226.4276\n",
      "Epoch 21/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 3018041645.0207 - mean_squared_error: 3018041645.0207 - val_loss: 2046622023.7241 - val_mean_squared_error: 2046622023.7241\n",
      "Epoch 22/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2507739154.8322 - mean_squared_error: 2507739154.8322 - val_loss: 1942241004.3586 - val_mean_squared_error: 1942241004.3586\n",
      "Epoch 23/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2687037597.7195 - mean_squared_error: 2687037597.7195 - val_loss: 2169498539.6966 - val_mean_squared_error: 2169498539.6966\n",
      "Epoch 24/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2655262383.8161 - mean_squared_error: 2655262383.8161 - val_loss: 1948129435.5862 - val_mean_squared_error: 1948129435.5862\n",
      "Epoch 25/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2927183697.9494 - mean_squared_error: 2927183697.9494 - val_loss: 1905248039.2828 - val_mean_squared_error: 1905248039.2828\n",
      "Epoch 26/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2697665415.3563 - mean_squared_error: 2697665415.3563 - val_loss: 1892280523.2552 - val_mean_squared_error: 1892280523.2552\n",
      "Epoch 27/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2411417202.6115 - mean_squared_error: 2411417202.6115 - val_loss: 1848535322.2621 - val_mean_squared_error: 1848535322.2621\n",
      "Epoch 28/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2488727013.9586 - mean_squared_error: 2488727013.9586 - val_loss: 1897542703.6690 - val_mean_squared_error: 1897542703.6690\n",
      "Epoch 29/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2563878796.6529 - mean_squared_error: 2563878796.6529 - val_loss: 2013713765.7379 - val_mean_squared_error: 2013713765.7379\n",
      "Epoch 30/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2842083514.2621 - mean_squared_error: 2842083514.2621 - val_loss: 1916013817.8207 - val_mean_squared_error: 1916013817.8207\n",
      "Epoch 31/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2701640660.7448 - mean_squared_error: 2701640660.7448 - val_loss: 1860918668.8000 - val_mean_squared_error: 1860918668.8000\n",
      "Epoch 32/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2553859742.6023 - mean_squared_error: 2553859742.6023 - val_loss: 1854350952.6069 - val_mean_squared_error: 1854350952.6069\n",
      "Epoch 33/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2718832950.8782 - mean_squared_error: 2718832950.8782 - val_loss: 1885141622.7310 - val_mean_squared_error: 1885141622.7310\n",
      "Epoch 34/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2574733780.4506 - mean_squared_error: 2574733780.4506 - val_loss: 1806882722.2069 - val_mean_squared_error: 1806882722.2069\n",
      "Epoch 35/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2415534693.3701 - mean_squared_error: 2415534693.3701 - val_loss: 1792223680.4414 - val_mean_squared_error: 1792223680.4414\n",
      "Epoch 36/500\n",
      "870/870 [==============================] - 0s 105us/step - loss: 2737685559.6138 - mean_squared_error: 2737685559.6138 - val_loss: 1826797998.7862 - val_mean_squared_error: 1826797998.7862\n",
      "Epoch 37/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2591734892.5793 - mean_squared_error: 2591734892.5793 - val_loss: 1895944728.0552 - val_mean_squared_error: 1895944728.0552\n",
      "Epoch 38/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2543355317.4805 - mean_squared_error: 2543355317.4805 - val_loss: 1826936756.3034 - val_mean_squared_error: 1826936756.3034\n",
      "Epoch 39/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2520851379.7885 - mean_squared_error: 2520851379.7885 - val_loss: 1826831312.3310 - val_mean_squared_error: 1826831312.3310\n",
      "Epoch 40/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2595559415.1724 - mean_squared_error: 2595559415.1724 - val_loss: 1852093465.0483 - val_mean_squared_error: 1852093465.0483\n",
      "Epoch 41/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 0s 108us/step - loss: 2394700209.1402 - mean_squared_error: 2394700209.1402 - val_loss: 1802282214.1793 - val_mean_squared_error: 1802282214.1793\n",
      "Epoch 42/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2717880418.8690 - mean_squared_error: 2717880418.8690 - val_loss: 1929458729.4897 - val_mean_squared_error: 1929458729.4897\n",
      "Epoch 43/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2411508309.9218 - mean_squared_error: 2411508309.9218 - val_loss: 1873219901.5724 - val_mean_squared_error: 1873219901.5724\n",
      "Epoch 44/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2465171111.1356 - mean_squared_error: 2465171111.1356 - val_loss: 1791374696.3862 - val_mean_squared_error: 1791374696.3862\n",
      "Epoch 45/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2759936700.3218 - mean_squared_error: 2759936700.3218 - val_loss: 1715894073.8207 - val_mean_squared_error: 1715894073.8207\n",
      "Epoch 46/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2526536768.1471 - mean_squared_error: 2526536768.1471 - val_loss: 1833658985.3793 - val_mean_squared_error: 1833658985.3793\n",
      "Epoch 47/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2656876822.3632 - mean_squared_error: 2656876822.3632 - val_loss: 1855014007.5034 - val_mean_squared_error: 1855014007.5034\n",
      "Epoch 48/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2510691580.5057 - mean_squared_error: 2510691580.5057 - val_loss: 1855456703.6690 - val_mean_squared_error: 1855456703.6690\n",
      "Epoch 49/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2610160538.1885 - mean_squared_error: 2610160538.1885 - val_loss: 1769879376.3310 - val_mean_squared_error: 1769879376.3310\n",
      "Epoch 50/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2550272939.2552 - mean_squared_error: 2550272939.2552 - val_loss: 1753198639.7793 - val_mean_squared_error: 1753198639.7793\n",
      "Epoch 51/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2468685910.8046 - mean_squared_error: 2468685910.8046 - val_loss: 1726706431.3379 - val_mean_squared_error: 1726706431.3379\n",
      "Epoch 52/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2734356621.2414 - mean_squared_error: 2734356621.2414 - val_loss: 1720016281.3793 - val_mean_squared_error: 1720016281.3793\n",
      "Epoch 53/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2555439583.2644 - mean_squared_error: 2555439583.2644 - val_loss: 1812971871.5586 - val_mean_squared_error: 1812971871.5586\n",
      "Epoch 54/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2569562131.7885 - mean_squared_error: 2569562131.7885 - val_loss: 1837684110.7862 - val_mean_squared_error: 1837684110.7862\n",
      "Epoch 55/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2578399969.3977 - mean_squared_error: 2578399969.3977 - val_loss: 1778909041.4345 - val_mean_squared_error: 1778909041.4345\n",
      "Epoch 56/500\n",
      "870/870 [==============================] - 0s 106us/step - loss: 2476077757.4989 - mean_squared_error: 2476077757.4989 - val_loss: 1710016986.7034 - val_mean_squared_error: 1710016986.7034\n",
      "Epoch 57/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2832461683.3471 - mean_squared_error: 2832461683.3471 - val_loss: 1735612041.6000 - val_mean_squared_error: 1735612041.6000\n",
      "Epoch 58/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2371665287.0621 - mean_squared_error: 2371665287.0621 - val_loss: 1763453157.7379 - val_mean_squared_error: 1763453157.7379\n",
      "Epoch 59/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2380181239.6138 - mean_squared_error: 2380181239.6138 - val_loss: 1785867477.1862 - val_mean_squared_error: 1785867477.1862\n",
      "Epoch 60/500\n",
      "870/870 [==============================] - 0s 106us/step - loss: 2400252468.9655 - mean_squared_error: 2400252468.9655 - val_loss: 1739489011.6414 - val_mean_squared_error: 1739489011.6414\n",
      "Epoch 61/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2565015941.8851 - mean_squared_error: 2565015941.8851 - val_loss: 1793341625.1586 - val_mean_squared_error: 1793341625.1586\n",
      "Epoch 62/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2379624274.6851 - mean_squared_error: 2379624274.6851 - val_loss: 1722891622.0690 - val_mean_squared_error: 1722891622.0690\n",
      "Epoch 63/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2439048733.4253 - mean_squared_error: 2439048733.4253 - val_loss: 1722377724.9103 - val_mean_squared_error: 1722377724.9103\n",
      "Epoch 64/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2519055816.0920 - mean_squared_error: 2519055816.0920 - val_loss: 1741425752.6069 - val_mean_squared_error: 1741425752.6069\n",
      "Epoch 65/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2409255351.6138 - mean_squared_error: 2409255351.6138 - val_loss: 1783773231.0069 - val_mean_squared_error: 1783773231.0069\n",
      "Epoch 66/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2444553763.8989 - mean_squared_error: 2444553763.8989 - val_loss: 1729535068.8552 - val_mean_squared_error: 1729535068.8552\n",
      "Epoch 67/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2185900956.5425 - mean_squared_error: 2185900956.5425 - val_loss: 1739184126.8414 - val_mean_squared_error: 1739184126.8414\n",
      "Epoch 68/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2525578019.3103 - mean_squared_error: 2525578019.3103 - val_loss: 1733984375.7241 - val_mean_squared_error: 1733984375.7241\n",
      "Epoch 69/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2578020029.7931 - mean_squared_error: 2578020029.7931 - val_loss: 1803495932.9103 - val_mean_squared_error: 1803495932.9103\n",
      "Epoch 70/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2554572403.2000 - mean_squared_error: 2554572403.2000 - val_loss: 1718482858.5931 - val_mean_squared_error: 1718482858.5931\n",
      "Epoch 71/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2575270757.9586 - mean_squared_error: 2575270757.9586 - val_loss: 1792852953.9310 - val_mean_squared_error: 1792852953.9310\n",
      "Epoch 72/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2466039417.5264 - mean_squared_error: 2466039417.5264 - val_loss: 1744908321.5448 - val_mean_squared_error: 1744908321.5448\n",
      "Epoch 73/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2436738899.5678 - mean_squared_error: 2436738899.5678 - val_loss: 1712356055.5034 - val_mean_squared_error: 1712356055.5034\n",
      "Epoch 74/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2595792291.6046 - mean_squared_error: 2595792291.6046 - val_loss: 1730872135.5586 - val_mean_squared_error: 1730872135.5586\n",
      "Epoch 75/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2383487777.8391 - mean_squared_error: 2383487777.8391 - val_loss: 1720837469.8483 - val_mean_squared_error: 1720837469.8483\n",
      "Epoch 76/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2369261027.6046 - mean_squared_error: 2369261027.6046 - val_loss: 1783442867.8621 - val_mean_squared_error: 1783442867.8621\n",
      "Epoch 77/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2494169494.3632 - mean_squared_error: 2494169494.3632 - val_loss: 1819856253.0207 - val_mean_squared_error: 1819856253.0207\n",
      "Epoch 78/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2312718617.3057 - mean_squared_error: 2312718617.3057 - val_loss: 1708161811.4207 - val_mean_squared_error: 1708161811.4207\n",
      "Epoch 79/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2222552532.7448 - mean_squared_error: 2222552532.7448 - val_loss: 1729115184.7724 - val_mean_squared_error: 1729115184.7724\n",
      "Epoch 80/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2410451869.2782 - mean_squared_error: 2410451869.2782 - val_loss: 1781134828.3586 - val_mean_squared_error: 1781134828.3586\n",
      "Epoch 81/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2327403409.2138 - mean_squared_error: 2327403409.2138 - val_loss: 1761094404.0276 - val_mean_squared_error: 1761094404.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2432963634.6115 - mean_squared_error: 2432963634.6115 - val_loss: 1724993866.9241 - val_mean_squared_error: 1724993866.9241\n",
      "Epoch 83/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2380246781.9402 - mean_squared_error: 2380246781.9402 - val_loss: 1695086890.6483 - val_mean_squared_error: 1695086890.6483\n",
      "Epoch 84/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2269452378.6299 - mean_squared_error: 2269452378.6299 - val_loss: 1753948430.4552 - val_mean_squared_error: 1753948430.4552\n",
      "Epoch 85/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2323825220.3402 - mean_squared_error: 2323825220.3402 - val_loss: 1747460706.3172 - val_mean_squared_error: 1747460706.3172\n",
      "Epoch 86/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2278804019.7885 - mean_squared_error: 2278804019.7885 - val_loss: 1742724884.8000 - val_mean_squared_error: 1742724884.8000\n",
      "Epoch 87/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2196522840.3494 - mean_squared_error: 2196522840.3494 - val_loss: 1731082245.6828 - val_mean_squared_error: 1731082245.6828\n",
      "Epoch 88/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2461270876.3954 - mean_squared_error: 2461270876.3954 - val_loss: 1783484347.3103 - val_mean_squared_error: 1783484347.3103\n",
      "Epoch 89/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2401979276.6529 - mean_squared_error: 2401979276.6529 - val_loss: 1654758424.7724 - val_mean_squared_error: 1654758424.7724\n",
      "Epoch 90/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2376063617.9126 - mean_squared_error: 2376063617.9126 - val_loss: 1726742674.0966 - val_mean_squared_error: 1726742674.0966\n",
      "Epoch 91/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2396662474.4460 - mean_squared_error: 2396662474.4460 - val_loss: 1775807961.1586 - val_mean_squared_error: 1775807961.1586\n",
      "Epoch 92/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2390834998.4368 - mean_squared_error: 2390834998.4368 - val_loss: 1765863105.0483 - val_mean_squared_error: 1765863105.0483\n",
      "Epoch 93/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2224534633.6368 - mean_squared_error: 2224534633.6368 - val_loss: 1718639919.5034 - val_mean_squared_error: 1718639919.5034\n",
      "Epoch 94/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2543411762.9057 - mean_squared_error: 2543411762.9057 - val_loss: 1736652813.0207 - val_mean_squared_error: 1736652813.0207\n",
      "Epoch 95/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2458568478.0138 - mean_squared_error: 2458568478.0138 - val_loss: 1733333635.4207 - val_mean_squared_error: 1733333635.4207\n",
      "Epoch 96/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2742912882.7586 - mean_squared_error: 2742912882.7586 - val_loss: 1854705052.2483 - val_mean_squared_error: 1854705052.2483\n",
      "Epoch 97/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2314472531.8621 - mean_squared_error: 2314472531.8621 - val_loss: 1785631736.0000 - val_mean_squared_error: 1785631736.0000\n",
      "Epoch 98/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2406412488.0920 - mean_squared_error: 2406412488.0920 - val_loss: 1835545467.5310 - val_mean_squared_error: 1835545467.5310\n",
      "Epoch 99/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2232476809.7103 - mean_squared_error: 2232476809.7103 - val_loss: 1742745741.9034 - val_mean_squared_error: 1742745741.9034\n",
      "Epoch 100/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2279067290.1885 - mean_squared_error: 2279067290.1885 - val_loss: 1754652594.3724 - val_mean_squared_error: 1754652594.3724\n",
      "Epoch 101/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2300706489.0851 - mean_squared_error: 2300706489.0851 - val_loss: 1813903932.4690 - val_mean_squared_error: 1813903932.4690\n",
      "Epoch 102/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2577669527.2460 - mean_squared_error: 2577669527.2460 - val_loss: 1685388823.4483 - val_mean_squared_error: 1685388823.4483\n",
      "Epoch 103/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2370309395.1264 - mean_squared_error: 2370309395.1264 - val_loss: 1685149265.5448 - val_mean_squared_error: 1685149265.5448\n",
      "Epoch 104/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2186352552.9011 - mean_squared_error: 2186352552.9011 - val_loss: 1750088949.1862 - val_mean_squared_error: 1750088949.1862\n",
      "Epoch 105/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2337979720.6805 - mean_squared_error: 2337979720.6805 - val_loss: 1888118135.6138 - val_mean_squared_error: 1888118135.6138\n",
      "Epoch 106/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2345629124.4138 - mean_squared_error: 2345629124.4138 - val_loss: 1767915882.6207 - val_mean_squared_error: 1767915882.6207\n",
      "Epoch 107/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2363272829.6460 - mean_squared_error: 2363272829.6460 - val_loss: 1727059753.3241 - val_mean_squared_error: 1727059753.3241\n",
      "Epoch 108/500\n",
      "870/870 [==============================] - 0s 111us/step - loss: 2227825081.5264 - mean_squared_error: 2227825081.5264 - val_loss: 1824669800.7724 - val_mean_squared_error: 1824669800.7724\n",
      "Epoch 109/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2331827404.9471 - mean_squared_error: 2331827404.9471 - val_loss: 1763614185.6000 - val_mean_squared_error: 1763614185.6000\n",
      "Epoch 110/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2366261197.6828 - mean_squared_error: 2366261197.6828 - val_loss: 1709624075.2828 - val_mean_squared_error: 1709624075.2828\n",
      "Epoch 111/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2386050738.7586 - mean_squared_error: 2386050738.7586 - val_loss: 1723686299.8069 - val_mean_squared_error: 1723686299.8069\n",
      "Epoch 112/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2424806648.3494 - mean_squared_error: 2424806648.3494 - val_loss: 1774085522.8138 - val_mean_squared_error: 1774085522.8138\n",
      "Epoch 113/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2439704488.0184 - mean_squared_error: 2439704488.0184 - val_loss: 1760640192.9379 - val_mean_squared_error: 1760640192.9379\n",
      "Epoch 114/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2407034029.0207 - mean_squared_error: 2407034029.0207 - val_loss: 1872564996.9655 - val_mean_squared_error: 1872564996.9655\n",
      "Epoch 115/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2345651151.4299 - mean_squared_error: 2345651151.4299 - val_loss: 1767879946.7034 - val_mean_squared_error: 1767879946.7034\n",
      "Epoch 116/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2332540841.0483 - mean_squared_error: 2332540841.0483 - val_loss: 1762020116.4138 - val_mean_squared_error: 1762020116.4138\n",
      "Epoch 117/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2469180991.5586 - mean_squared_error: 2469180991.5586 - val_loss: 1848003317.9586 - val_mean_squared_error: 1848003317.9586\n",
      "Epoch 118/500\n",
      "870/870 [==============================] - 0s 109us/step - loss: 2092006976.5885 - mean_squared_error: 2092006976.5885 - val_loss: 1744952720.2207 - val_mean_squared_error: 1744952720.2207\n",
      "Epoch 119/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2604538507.6230 - mean_squared_error: 2604538507.6230 - val_loss: 1878364818.8138 - val_mean_squared_error: 1878364818.8138\n",
      "Epoch 120/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2325772060.0276 - mean_squared_error: 2325772060.0276 - val_loss: 1791944496.2759 - val_mean_squared_error: 1791944496.2759\n",
      "Epoch 121/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2363191918.6391 - mean_squared_error: 2363191918.6391 - val_loss: 1850408895.2828 - val_mean_squared_error: 1850408895.2828\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 0s 106us/step - loss: 2205106213.8851 - mean_squared_error: 2205106213.8851 - val_loss: 1738783467.6414 - val_mean_squared_error: 1738783467.6414\n",
      "Epoch 123/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2135124189.8667 - mean_squared_error: 2135124189.8667 - val_loss: 1743373080.9655 - val_mean_squared_error: 1743373080.9655\n",
      "Epoch 124/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2200435534.2713 - mean_squared_error: 2200435534.2713 - val_loss: 1799393179.2276 - val_mean_squared_error: 1799393179.2276\n",
      "Epoch 125/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2294152221.4253 - mean_squared_error: 2294152221.4253 - val_loss: 1820382365.4897 - val_mean_squared_error: 1820382365.4897\n",
      "Epoch 126/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2315855894.9517 - mean_squared_error: 2315855894.9517 - val_loss: 1788451768.7172 - val_mean_squared_error: 1788451768.7172\n",
      "Epoch 127/500\n",
      "870/870 [==============================] - 0s 110us/step - loss: 2380303040.2943 - mean_squared_error: 2380303040.2943 - val_loss: 1710360894.3724 - val_mean_squared_error: 1710360894.3724\n",
      "Epoch 128/500\n",
      "870/870 [==============================] - 0s 107us/step - loss: 2277698864.8460 - mean_squared_error: 2277698864.8460 - val_loss: 1789029825.1862 - val_mean_squared_error: 1789029825.1862\n",
      "Epoch 129/500\n",
      "870/870 [==============================] - 0s 108us/step - loss: 2312514410.5195 - mean_squared_error: 2312514410.5195 - val_loss: 1710364064.5517 - val_mean_squared_error: 1710364064.5517\n"
     ]
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36565.48059412098, 20.31535355289599, 41356.5480250918, 22.097035512708093)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, pct_error, rmse_v, pct_error_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_zero_sorted = df_non_zero.sort_values(by=['sum_of_intensities'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_of_features(df):\n",
    "    feature_dict = {}\n",
    "    if(len(df)<=100):\n",
    "        for i in range(1,100):\n",
    "            drop_value = i\n",
    "            print(i,'No of features dropped:',drop_value)\n",
    "            subset_df = df.head(len(df) - drop_value)\n",
    "            subset_df.sort_values(by=['index'],inplace=True)\n",
    "            feature_subset = list(subset_df['feature_name'])\n",
    "\n",
    "            rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,feature_subset)\n",
    "\n",
    "            feature_dict[drop_value] = rmse, pct_error, rmse_v, pct_error_v\n",
    "        return feature_dict\n",
    "        \n",
    "    else:\n",
    "        for i in range(1,100):\n",
    "            drop_value = int(np.floor((i / 100) * len(df)))\n",
    "            print(i,'No of features dropped:',drop_value)\n",
    "            subset_df = df.head(len(df) - drop_value)\n",
    "            subset_df.sort_values(by=['index'],inplace=True)\n",
    "            feature_subset = list(subset_df['feature_name'])\n",
    "            \n",
    "            rmse, pct_error, rmse_v, pct_error_v = get_results(best_params,feature_subset)\n",
    "            \n",
    "            feature_dict[drop_value] = rmse, pct_error, rmse_v, pct_error_v\n",
    "        return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 No of features dropped: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/izenda/env/lib/python3.5/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 No of features dropped: 5\n",
      "3 No of features dropped: 8\n",
      "4 No of features dropped: 11\n",
      "5 No of features dropped: 14\n",
      "6 No of features dropped: 16\n",
      "7 No of features dropped: 19\n",
      "8 No of features dropped: 22\n",
      "9 No of features dropped: 25\n",
      "10 No of features dropped: 28\n",
      "11 No of features dropped: 30\n",
      "12 No of features dropped: 33\n",
      "13 No of features dropped: 36\n",
      "14 No of features dropped: 39\n",
      "15 No of features dropped: 42\n",
      "16 No of features dropped: 44\n",
      "17 No of features dropped: 47\n",
      "18 No of features dropped: 50\n",
      "19 No of features dropped: 53\n",
      "20 No of features dropped: 56\n",
      "21 No of features dropped: 58\n",
      "22 No of features dropped: 61\n",
      "23 No of features dropped: 64\n",
      "24 No of features dropped: 67\n",
      "25 No of features dropped: 70\n",
      "26 No of features dropped: 72\n",
      "27 No of features dropped: 75\n",
      "28 No of features dropped: 78\n",
      "29 No of features dropped: 81\n",
      "30 No of features dropped: 84\n",
      "31 No of features dropped: 86\n",
      "32 No of features dropped: 89\n",
      "33 No of features dropped: 92\n",
      "34 No of features dropped: 95\n",
      "35 No of features dropped: 98\n",
      "36 No of features dropped: 100\n",
      "37 No of features dropped: 103\n",
      "38 No of features dropped: 106\n",
      "39 No of features dropped: 109\n",
      "40 No of features dropped: 112\n",
      "41 No of features dropped: 114\n",
      "42 No of features dropped: 117\n",
      "43 No of features dropped: 120\n",
      "44 No of features dropped: 123\n",
      "45 No of features dropped: 126\n",
      "46 No of features dropped: 128\n",
      "47 No of features dropped: 131\n",
      "48 No of features dropped: 134\n",
      "49 No of features dropped: 137\n",
      "50 No of features dropped: 140\n",
      "51 No of features dropped: 142\n",
      "52 No of features dropped: 145\n",
      "53 No of features dropped: 148\n",
      "54 No of features dropped: 151\n",
      "55 No of features dropped: 154\n",
      "56 No of features dropped: 156\n",
      "57 No of features dropped: 159\n",
      "58 No of features dropped: 162\n",
      "59 No of features dropped: 165\n",
      "60 No of features dropped: 168\n",
      "61 No of features dropped: 170\n",
      "62 No of features dropped: 173\n",
      "63 No of features dropped: 176\n",
      "64 No of features dropped: 179\n",
      "65 No of features dropped: 182\n",
      "66 No of features dropped: 184\n",
      "67 No of features dropped: 187\n",
      "68 No of features dropped: 190\n",
      "69 No of features dropped: 193\n",
      "70 No of features dropped: 196\n",
      "71 No of features dropped: 198\n",
      "72 No of features dropped: 201\n",
      "73 No of features dropped: 204\n",
      "74 No of features dropped: 207\n",
      "75 No of features dropped: 210\n",
      "76 No of features dropped: 212\n",
      "77 No of features dropped: 215\n",
      "78 No of features dropped: 218\n",
      "79 No of features dropped: 221\n",
      "80 No of features dropped: 224\n",
      "81 No of features dropped: 226\n",
      "82 No of features dropped: 229\n",
      "83 No of features dropped: 232\n",
      "84 No of features dropped: 235\n",
      "85 No of features dropped: 238\n",
      "86 No of features dropped: 240\n",
      "87 No of features dropped: 243\n",
      "88 No of features dropped: 246\n",
      "89 No of features dropped: 249\n",
      "90 No of features dropped: 252\n",
      "91 No of features dropped: 254\n",
      "92 No of features dropped: 257\n",
      "93 No of features dropped: 260\n",
      "94 No of features dropped: 263\n",
      "95 No of features dropped: 266\n",
      "96 No of features dropped: 268\n",
      "97 No of features dropped: 271\n",
      "98 No of features dropped: 274\n",
      "99 No of features dropped: 277\n"
     ]
    }
   ],
   "source": [
    "resultant_dict = simulation_of_features(df_non_zero_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: (36495.71739541758,\n",
       "  20.276593935256276,\n",
       "  41284.968443649115,\n",
       "  22.058790140967588),\n",
       " 5: (36637.26862071263,\n",
       "  20.35523814123936,\n",
       "  41306.33148461917,\n",
       "  22.070204533549102),\n",
       " 8: (36632.22250322485,\n",
       "  20.3524345773543,\n",
       "  41342.38864126645,\n",
       "  22.089470074532816),\n",
       " 11: (36605.178669548295,\n",
       "  20.337409339516913,\n",
       "  41361.593637009486,\n",
       "  22.099731411448502),\n",
       " 14: (36572.69901794294,\n",
       "  20.319364024785187,\n",
       "  41288.52589379716,\n",
       "  22.06069090652975),\n",
       " 16: (36569.44401021835,\n",
       "  20.317555580545758,\n",
       "  41340.483904212866,\n",
       "  22.088452362844453),\n",
       " 19: (36641.85444668564,\n",
       "  20.357785972539812,\n",
       "  41434.259709602135,\n",
       "  22.138557301502832),\n",
       " 22: (36540.19126642527,\n",
       "  20.30130309807068,\n",
       "  41401.16203899729,\n",
       "  22.12087303050663),\n",
       " 25: (36372.24257315855,\n",
       "  20.20799276747957,\n",
       "  41307.491388366834,\n",
       "  22.07082427662553),\n",
       " 28: (36360.70337707456,\n",
       "  20.201581725033158,\n",
       "  41289.24398502802,\n",
       "  22.061074586701025),\n",
       " 30: (36439.309977208955,\n",
       "  20.245254633125004,\n",
       "  41304.45539898688,\n",
       "  22.0692021304758),\n",
       " 33: (36458.13290474903,\n",
       "  20.255712431618665,\n",
       "  41315.36696995525,\n",
       "  22.075032244029792),\n",
       " 36: (36486.38590034273,\n",
       "  20.271409465681625,\n",
       "  41357.4025553363,\n",
       "  22.09749209300943),\n",
       " 39: (36500.67187857819,\n",
       "  20.27934658818041,\n",
       "  41383.25206733958,\n",
       "  22.111303632221453),\n",
       " 42: (36459.918883665065,\n",
       "  20.2567047006256,\n",
       "  41304.958576840174,\n",
       "  22.069470981224338),\n",
       " 44: (36468.81553994588,\n",
       "  20.261647578849725,\n",
       "  41287.59283585458,\n",
       "  22.060192368438997),\n",
       " 47: (36447.61960766838,\n",
       "  20.24987136666533,\n",
       "  41330.927154138335,\n",
       "  22.083346137691066),\n",
       " 50: (35759.30873506396,\n",
       "  19.867453892477688,\n",
       "  41621.58804771621,\n",
       "  22.23864788298299),\n",
       " 53: (35680.37411543189,\n",
       "  19.823598740587613,\n",
       "  41587.99349878728,\n",
       "  22.220698127112023),\n",
       " 56: (35700.22246025002,\n",
       "  19.834626248933418,\n",
       "  41599.38538206445,\n",
       "  22.22678487422592),\n",
       " 58: (35685.05544756142,\n",
       "  19.82619963399212,\n",
       "  41624.71331312686,\n",
       "  22.24031772981652),\n",
       " 61: (35717.52342461091,\n",
       "  19.844238462477083,\n",
       "  41617.001736607934,\n",
       "  22.23619739124053),\n",
       " 64: (35756.43552120556,\n",
       "  19.865857568446987,\n",
       "  41658.5430043032,\n",
       "  22.258393123508814),\n",
       " 67: (35756.61709284589,\n",
       "  19.86595844752771,\n",
       "  41665.97626940665,\n",
       "  22.26236475873491),\n",
       " 70: (35739.18561503769,\n",
       "  19.85627372223847,\n",
       "  41609.94513549988,\n",
       "  22.23242700969928),\n",
       " 72: (35775.77646562284,\n",
       "  19.876603171061795,\n",
       "  41654.7447576814,\n",
       "  22.256363699040477),\n",
       " 75: (35754.088501751314,\n",
       "  19.86455359187581,\n",
       "  41629.967815969074,\n",
       "  22.24312524014924),\n",
       " 78: (35770.551355862626,\n",
       "  19.87370016116266,\n",
       "  41650.1656450736,\n",
       "  22.25391705349719),\n",
       " 81: (35744.28691120272,\n",
       "  19.859107942751553,\n",
       "  41863.195276832455,\n",
       "  22.367739980289304),\n",
       " 84: (35743.685902504614,\n",
       "  19.85877402934492,\n",
       "  41829.006430037734,\n",
       "  22.349472687736185),\n",
       " 86: (35758.62257393145,\n",
       "  19.867072669373965,\n",
       "  41838.43307146985,\n",
       "  22.35450939511236),\n",
       " 89: (35735.634286076114,\n",
       "  19.854300645383884,\n",
       "  41823.65140608757,\n",
       "  22.346611468411826),\n",
       " 92: (35701.22795081251,\n",
       "  19.835184887735345,\n",
       "  41785.55273577798,\n",
       "  22.32625513523075),\n",
       " 95: (35841.63231432584,\n",
       "  19.913191910719785,\n",
       "  41737.41222650869,\n",
       "  22.30053339118485),\n",
       " 98: (35830.565535366484,\n",
       "  19.907043337705073,\n",
       "  41726.936878249035,\n",
       "  22.2949363538702),\n",
       " 100: (35850.765479373586,\n",
       "  19.918266190449934,\n",
       "  41747.902821744145,\n",
       "  22.306138575044166),\n",
       " 103: (35868.18082063046,\n",
       "  19.9279419504599,\n",
       "  41728.95738800162,\n",
       "  22.296015923560823),\n",
       " 106: (35831.0315853082,\n",
       "  19.907302269604376,\n",
       "  41782.00701143315,\n",
       "  22.324360634830995),\n",
       " 109: (35867.79285652555,\n",
       "  19.927726402138667,\n",
       "  41757.35708376058,\n",
       "  22.311190040253422),\n",
       " 112: (36077.752534751424,\n",
       "  20.044377544847748,\n",
       "  41936.78549304483,\n",
       "  22.4070596454617),\n",
       " 114: (36098.40791607853,\n",
       "  20.05585343324336,\n",
       "  41980.747077514075,\n",
       "  22.430548566554016),\n",
       " 117: (36129.306853172835,\n",
       "  20.073020521471932,\n",
       "  41981.94291112672,\n",
       "  22.431187507158775),\n",
       " 120: (36116.194212169336,\n",
       "  20.065735291422445,\n",
       "  41945.933721958034,\n",
       "  22.411947595467847),\n",
       " 123: (36070.00472639558,\n",
       "  20.040072953100243,\n",
       "  41947.40848384253,\n",
       "  22.41273556901232),\n",
       " 126: (36110.42556179995,\n",
       "  20.06253029671506,\n",
       "  41981.35953376746,\n",
       "  22.43087580536449),\n",
       " 128: (36082.29043102919,\n",
       "  20.04689874696984,\n",
       "  41970.95028411585,\n",
       "  22.425314084906756),\n",
       " 131: (36100.447643415486,\n",
       "  20.056986681906537,\n",
       "  41983.5220654567,\n",
       "  22.432031258172238),\n",
       " 134: (36120.29107591652,\n",
       "  20.06801146102639,\n",
       "  42004.76102276158,\n",
       "  22.443379352155667),\n",
       " 137: (36091.17246117107,\n",
       "  20.051833499082157,\n",
       "  41938.0561587255,\n",
       "  22.40773856926002),\n",
       " 140: (36126.26496797147,\n",
       "  20.071330485614915,\n",
       "  41975.17800171742,\n",
       "  22.427572978127795),\n",
       " 142: (36126.210554729834,\n",
       "  20.07130025425398,\n",
       "  41965.58472811279,\n",
       "  22.42244723824748),\n",
       " 145: (36111.03258665178,\n",
       "  20.062867552626372,\n",
       "  42008.966458323535,\n",
       "  22.445626339957997),\n",
       " 148: (36109.498487478086,\n",
       "  20.062015225059703,\n",
       "  42014.68252392498,\n",
       "  22.44868046586114),\n",
       " 151: (36102.10361254395,\n",
       "  20.057906718995365,\n",
       "  41974.25591692258,\n",
       "  22.427080303051415),\n",
       " 154: (36132.41782332661,\n",
       "  20.074748940120873,\n",
       "  41985.291770760174,\n",
       "  22.43297682163934),\n",
       " 156: (36117.028409614395,\n",
       "  20.066198761770814,\n",
       "  41992.700327228464,\n",
       "  22.43693525490312),\n",
       " 159: (36117.01330788285,\n",
       "  20.066190371425314,\n",
       "  42008.52678239962,\n",
       "  22.445391418646405),\n",
       " 162: (36105.795848529226,\n",
       "  20.05995808214506,\n",
       "  41972.096498375744,\n",
       "  22.425926513613106),\n",
       " 165: (36092.79638972631,\n",
       "  20.052735734803072,\n",
       "  41998.8103568792,\n",
       "  22.440199878006915),\n",
       " 168: (36117.206889681096,\n",
       "  20.06629792320937,\n",
       "  41983.646431306624,\n",
       "  22.43209770754322),\n",
       " 170: (36115.995205216626,\n",
       "  20.065624725485993,\n",
       "  42015.66785329754,\n",
       "  22.44920693287004),\n",
       " 173: (36094.466748650215,\n",
       "  20.053663766694022,\n",
       "  41959.54928655734,\n",
       "  22.419222467981236),\n",
       " 176: (36102.11510191079,\n",
       "  20.057913102353268,\n",
       "  41983.614800587835,\n",
       "  22.432080807072808),\n",
       " 179: (36155.05401809747,\n",
       "  20.08732534530933,\n",
       "  42005.865118887945,\n",
       "  22.443969276907094),\n",
       " 182: (36111.10502600706,\n",
       "  20.062907799085323,\n",
       "  41985.60004178773,\n",
       "  22.43314153257796),\n",
       " 184: (36106.19113525453,\n",
       "  20.06017769882858,\n",
       "  41993.22174400744,\n",
       "  22.437213850811922),\n",
       " 187: (36115.5905624839,\n",
       "  20.065399910714124,\n",
       "  42013.03943268582,\n",
       "  22.44780255299858),\n",
       " 190: (36106.896115652606,\n",
       "  20.060569377696243,\n",
       "  41997.77271467028,\n",
       "  22.43964545995621),\n",
       " 193: (36137.97098045479,\n",
       "  20.07783420930265,\n",
       "  41995.446016492526,\n",
       "  22.438402292073096),\n",
       " 196: (36136.28856126232,\n",
       "  20.07689947686747,\n",
       "  41945.37504898484,\n",
       "  22.41164909336556),\n",
       " 198: (36159.35002913091,\n",
       "  20.08971215881741,\n",
       "  41997.905553688644,\n",
       "  22.439716436588604),\n",
       " 201: (36143.14662446431,\n",
       "  20.080709736608977,\n",
       "  41984.05626047534,\n",
       "  22.432316681566146),\n",
       " 204: (36119.065185621315,\n",
       "  20.06733037070953,\n",
       "  41976.10279884628,\n",
       "  22.42806710241946),\n",
       " 207: (36126.72124942529,\n",
       "  20.07158399025655,\n",
       "  42084.18174842518,\n",
       "  22.485814291221875),\n",
       " 210: (36106.999871563494,\n",
       "  20.060627023267386,\n",
       "  42084.90011328086,\n",
       "  22.48619811759243),\n",
       " 212: (36147.69242239285,\n",
       "  20.083235328795865,\n",
       "  42108.99961798649,\n",
       "  22.499074618092322),\n",
       " 215: (36094.63510373083,\n",
       "  20.053757302808673,\n",
       "  42076.57383324868,\n",
       "  22.481749339482413),\n",
       " 218: (36103.88132622128,\n",
       "  20.0588943959323,\n",
       "  42099.88497125739,\n",
       "  22.49420461123545),\n",
       " 221: (36127.6567697118,\n",
       "  20.072103754391122,\n",
       "  42092.602137471236,\n",
       "  22.490313352305712),\n",
       " 224: (36121.99603729303,\n",
       "  20.068958717635496,\n",
       "  42124.91110511443,\n",
       "  22.507576214886925),\n",
       " 226: (36159.06616803495,\n",
       "  20.089554448910945,\n",
       "  42130.459823153426,\n",
       "  22.51054092604907),\n",
       " 229: (36111.12481981941,\n",
       "  20.062918796296064,\n",
       "  42106.962545894705,\n",
       "  22.49798619905099),\n",
       " 232: (36109.90635341268,\n",
       "  20.06224183060485,\n",
       "  42150.80626643273,\n",
       "  22.521412144783945),\n",
       " 235: (36133.4555856975,\n",
       "  20.075325508762283,\n",
       "  42138.40328480783,\n",
       "  22.514785162153224),\n",
       " 238: (36121.71976132177,\n",
       "  20.068805221935644,\n",
       "  42126.995152833966,\n",
       "  22.508689733269577),\n",
       " 240: (36113.5602407822,\n",
       "  20.06427188771194,\n",
       "  42126.853770568916,\n",
       "  22.508614191932573),\n",
       " 243: (36106.30941464929,\n",
       "  20.060243413477572,\n",
       "  42110.82472419323,\n",
       "  22.500049782572695),\n",
       " 246: (36157.66871419341,\n",
       "  20.088778039893384,\n",
       "  42139.37667411276,\n",
       "  22.515305249517038),\n",
       " 249: (36127.69139605031,\n",
       "  20.072122992380002,\n",
       "  42096.41560169161,\n",
       "  22.492350907622296),\n",
       " 252: (36147.40488002061,\n",
       "  20.083075573615332,\n",
       "  42148.02615020804,\n",
       "  22.519926713095856),\n",
       " 254: (36136.353062339425,\n",
       "  20.076935312911868,\n",
       "  42139.49838498236,\n",
       "  22.515370280317146),\n",
       " 257: (36157.983424595644,\n",
       "  20.088952889313774,\n",
       "  42133.71596108816,\n",
       "  22.51228069880608),\n",
       " 260: (36115.43220690303,\n",
       "  20.065311930204636,\n",
       "  42136.81221008047,\n",
       "  22.513935042004597),\n",
       " 263: (36161.342541144775,\n",
       "  20.090819175199044,\n",
       "  42186.61493428684,\n",
       "  22.540544916812085),\n",
       " 266: (36127.39035033908,\n",
       "  20.07195573490219,\n",
       "  42201.10950004138,\n",
       "  22.548289444571633),\n",
       " 268: (36153.575161364795,\n",
       "  20.08650370979709,\n",
       "  42179.82133544019,\n",
       "  22.536915058853864),\n",
       " 271: (36291.96304353437,\n",
       "  20.163390399320416,\n",
       "  43001.85519654737,\n",
       "  22.976132360319962),\n",
       " 274: (40202.37406335473,\n",
       "  22.335969047652572,\n",
       "  45646.165085134046,\n",
       "  24.389001961507507),\n",
       " 277: (84321.57376675152,\n",
       "  46.84808063164299,\n",
       "  91055.46056469253,\n",
       "  48.65144316453225)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df = pd.DataFrame(resultant_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.columns = ['no_of_dropped_features', 'rmse_test', 'pct_error_test', 'rmse_valid', 'pct_error_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'no_of_dropped_features':[0],'rmse_test':[36565.48059412098],'pct_error_test':[20.31535355289599],'rmse_valid':[41356.5480250918],'pct_error_valid':[22.097035512708093]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/izenda/env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "resultant_df = resultant_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.sort_values(by=['no_of_dropped_features'],inplace=True)\n",
    "resultant_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultant_df.to_csv('house_pred_lime_feature_selection_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_dropped_features</th>\n",
       "      <th>pct_error_test</th>\n",
       "      <th>pct_error_valid</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>rmse_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.315354</td>\n",
       "      <td>22.097036</td>\n",
       "      <td>36565.480594</td>\n",
       "      <td>41356.548025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.276594</td>\n",
       "      <td>22.058790</td>\n",
       "      <td>36495.717395</td>\n",
       "      <td>41284.968444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>20.355238</td>\n",
       "      <td>22.070205</td>\n",
       "      <td>36637.268621</td>\n",
       "      <td>41306.331485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>20.352435</td>\n",
       "      <td>22.089470</td>\n",
       "      <td>36632.222503</td>\n",
       "      <td>41342.388641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>20.337409</td>\n",
       "      <td>22.099731</td>\n",
       "      <td>36605.178670</td>\n",
       "      <td>41361.593637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>20.319364</td>\n",
       "      <td>22.060691</td>\n",
       "      <td>36572.699018</td>\n",
       "      <td>41288.525894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>20.317556</td>\n",
       "      <td>22.088452</td>\n",
       "      <td>36569.444010</td>\n",
       "      <td>41340.483904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>20.357786</td>\n",
       "      <td>22.138557</td>\n",
       "      <td>36641.854447</td>\n",
       "      <td>41434.259710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>20.301303</td>\n",
       "      <td>22.120873</td>\n",
       "      <td>36540.191266</td>\n",
       "      <td>41401.162039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>20.207993</td>\n",
       "      <td>22.070824</td>\n",
       "      <td>36372.242573</td>\n",
       "      <td>41307.491388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>20.201582</td>\n",
       "      <td>22.061075</td>\n",
       "      <td>36360.703377</td>\n",
       "      <td>41289.243985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>20.245255</td>\n",
       "      <td>22.069202</td>\n",
       "      <td>36439.309977</td>\n",
       "      <td>41304.455399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>20.255712</td>\n",
       "      <td>22.075032</td>\n",
       "      <td>36458.132905</td>\n",
       "      <td>41315.366970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>20.271409</td>\n",
       "      <td>22.097492</td>\n",
       "      <td>36486.385900</td>\n",
       "      <td>41357.402555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39</td>\n",
       "      <td>20.279347</td>\n",
       "      <td>22.111304</td>\n",
       "      <td>36500.671879</td>\n",
       "      <td>41383.252067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42</td>\n",
       "      <td>20.256705</td>\n",
       "      <td>22.069471</td>\n",
       "      <td>36459.918884</td>\n",
       "      <td>41304.958577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44</td>\n",
       "      <td>20.261648</td>\n",
       "      <td>22.060192</td>\n",
       "      <td>36468.815540</td>\n",
       "      <td>41287.592836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47</td>\n",
       "      <td>20.249871</td>\n",
       "      <td>22.083346</td>\n",
       "      <td>36447.619608</td>\n",
       "      <td>41330.927154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>19.867454</td>\n",
       "      <td>22.238648</td>\n",
       "      <td>35759.308735</td>\n",
       "      <td>41621.588048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53</td>\n",
       "      <td>19.823599</td>\n",
       "      <td>22.220698</td>\n",
       "      <td>35680.374115</td>\n",
       "      <td>41587.993499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56</td>\n",
       "      <td>19.834626</td>\n",
       "      <td>22.226785</td>\n",
       "      <td>35700.222460</td>\n",
       "      <td>41599.385382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>58</td>\n",
       "      <td>19.826200</td>\n",
       "      <td>22.240318</td>\n",
       "      <td>35685.055448</td>\n",
       "      <td>41624.713313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>61</td>\n",
       "      <td>19.844238</td>\n",
       "      <td>22.236197</td>\n",
       "      <td>35717.523425</td>\n",
       "      <td>41617.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>19.865858</td>\n",
       "      <td>22.258393</td>\n",
       "      <td>35756.435521</td>\n",
       "      <td>41658.543004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>67</td>\n",
       "      <td>19.865958</td>\n",
       "      <td>22.262365</td>\n",
       "      <td>35756.617093</td>\n",
       "      <td>41665.976269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>70</td>\n",
       "      <td>19.856274</td>\n",
       "      <td>22.232427</td>\n",
       "      <td>35739.185615</td>\n",
       "      <td>41609.945135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>72</td>\n",
       "      <td>19.876603</td>\n",
       "      <td>22.256364</td>\n",
       "      <td>35775.776466</td>\n",
       "      <td>41654.744758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75</td>\n",
       "      <td>19.864554</td>\n",
       "      <td>22.243125</td>\n",
       "      <td>35754.088502</td>\n",
       "      <td>41629.967816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78</td>\n",
       "      <td>19.873700</td>\n",
       "      <td>22.253917</td>\n",
       "      <td>35770.551356</td>\n",
       "      <td>41650.165645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>81</td>\n",
       "      <td>19.859108</td>\n",
       "      <td>22.367740</td>\n",
       "      <td>35744.286911</td>\n",
       "      <td>41863.195277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>196</td>\n",
       "      <td>20.076899</td>\n",
       "      <td>22.411649</td>\n",
       "      <td>36136.288561</td>\n",
       "      <td>41945.375049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>198</td>\n",
       "      <td>20.089712</td>\n",
       "      <td>22.439716</td>\n",
       "      <td>36159.350029</td>\n",
       "      <td>41997.905554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>201</td>\n",
       "      <td>20.080710</td>\n",
       "      <td>22.432317</td>\n",
       "      <td>36143.146624</td>\n",
       "      <td>41984.056260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>204</td>\n",
       "      <td>20.067330</td>\n",
       "      <td>22.428067</td>\n",
       "      <td>36119.065186</td>\n",
       "      <td>41976.102799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>207</td>\n",
       "      <td>20.071584</td>\n",
       "      <td>22.485814</td>\n",
       "      <td>36126.721249</td>\n",
       "      <td>42084.181748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>210</td>\n",
       "      <td>20.060627</td>\n",
       "      <td>22.486198</td>\n",
       "      <td>36106.999872</td>\n",
       "      <td>42084.900113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>212</td>\n",
       "      <td>20.083235</td>\n",
       "      <td>22.499075</td>\n",
       "      <td>36147.692422</td>\n",
       "      <td>42108.999618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>215</td>\n",
       "      <td>20.053757</td>\n",
       "      <td>22.481749</td>\n",
       "      <td>36094.635104</td>\n",
       "      <td>42076.573833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>218</td>\n",
       "      <td>20.058894</td>\n",
       "      <td>22.494205</td>\n",
       "      <td>36103.881326</td>\n",
       "      <td>42099.884971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>221</td>\n",
       "      <td>20.072104</td>\n",
       "      <td>22.490313</td>\n",
       "      <td>36127.656770</td>\n",
       "      <td>42092.602137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>224</td>\n",
       "      <td>20.068959</td>\n",
       "      <td>22.507576</td>\n",
       "      <td>36121.996037</td>\n",
       "      <td>42124.911105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>226</td>\n",
       "      <td>20.089554</td>\n",
       "      <td>22.510541</td>\n",
       "      <td>36159.066168</td>\n",
       "      <td>42130.459823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>229</td>\n",
       "      <td>20.062919</td>\n",
       "      <td>22.497986</td>\n",
       "      <td>36111.124820</td>\n",
       "      <td>42106.962546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>232</td>\n",
       "      <td>20.062242</td>\n",
       "      <td>22.521412</td>\n",
       "      <td>36109.906353</td>\n",
       "      <td>42150.806266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>235</td>\n",
       "      <td>20.075326</td>\n",
       "      <td>22.514785</td>\n",
       "      <td>36133.455586</td>\n",
       "      <td>42138.403285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>238</td>\n",
       "      <td>20.068805</td>\n",
       "      <td>22.508690</td>\n",
       "      <td>36121.719761</td>\n",
       "      <td>42126.995153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>240</td>\n",
       "      <td>20.064272</td>\n",
       "      <td>22.508614</td>\n",
       "      <td>36113.560241</td>\n",
       "      <td>42126.853771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>243</td>\n",
       "      <td>20.060243</td>\n",
       "      <td>22.500050</td>\n",
       "      <td>36106.309415</td>\n",
       "      <td>42110.824724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>246</td>\n",
       "      <td>20.088778</td>\n",
       "      <td>22.515305</td>\n",
       "      <td>36157.668714</td>\n",
       "      <td>42139.376674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>249</td>\n",
       "      <td>20.072123</td>\n",
       "      <td>22.492351</td>\n",
       "      <td>36127.691396</td>\n",
       "      <td>42096.415602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>252</td>\n",
       "      <td>20.083076</td>\n",
       "      <td>22.519927</td>\n",
       "      <td>36147.404880</td>\n",
       "      <td>42148.026150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>254</td>\n",
       "      <td>20.076935</td>\n",
       "      <td>22.515370</td>\n",
       "      <td>36136.353062</td>\n",
       "      <td>42139.498385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>257</td>\n",
       "      <td>20.088953</td>\n",
       "      <td>22.512281</td>\n",
       "      <td>36157.983425</td>\n",
       "      <td>42133.715961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>260</td>\n",
       "      <td>20.065312</td>\n",
       "      <td>22.513935</td>\n",
       "      <td>36115.432207</td>\n",
       "      <td>42136.812210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>263</td>\n",
       "      <td>20.090819</td>\n",
       "      <td>22.540545</td>\n",
       "      <td>36161.342541</td>\n",
       "      <td>42186.614934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>266</td>\n",
       "      <td>20.071956</td>\n",
       "      <td>22.548289</td>\n",
       "      <td>36127.390350</td>\n",
       "      <td>42201.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>268</td>\n",
       "      <td>20.086504</td>\n",
       "      <td>22.536915</td>\n",
       "      <td>36153.575161</td>\n",
       "      <td>42179.821335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>271</td>\n",
       "      <td>20.163390</td>\n",
       "      <td>22.976132</td>\n",
       "      <td>36291.963044</td>\n",
       "      <td>43001.855197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>274</td>\n",
       "      <td>22.335969</td>\n",
       "      <td>24.389002</td>\n",
       "      <td>40202.374063</td>\n",
       "      <td>45646.165085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>277</td>\n",
       "      <td>46.848081</td>\n",
       "      <td>48.651443</td>\n",
       "      <td>84321.573767</td>\n",
       "      <td>91055.460565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_of_dropped_features  pct_error_test  pct_error_valid     rmse_test  \\\n",
       "0                        0       20.315354        22.097036  36565.480594   \n",
       "1                        2       20.276594        22.058790  36495.717395   \n",
       "2                        5       20.355238        22.070205  36637.268621   \n",
       "3                        8       20.352435        22.089470  36632.222503   \n",
       "4                       11       20.337409        22.099731  36605.178670   \n",
       "5                       14       20.319364        22.060691  36572.699018   \n",
       "6                       16       20.317556        22.088452  36569.444010   \n",
       "7                       19       20.357786        22.138557  36641.854447   \n",
       "8                       22       20.301303        22.120873  36540.191266   \n",
       "9                       25       20.207993        22.070824  36372.242573   \n",
       "10                      28       20.201582        22.061075  36360.703377   \n",
       "11                      30       20.245255        22.069202  36439.309977   \n",
       "12                      33       20.255712        22.075032  36458.132905   \n",
       "13                      36       20.271409        22.097492  36486.385900   \n",
       "14                      39       20.279347        22.111304  36500.671879   \n",
       "15                      42       20.256705        22.069471  36459.918884   \n",
       "16                      44       20.261648        22.060192  36468.815540   \n",
       "17                      47       20.249871        22.083346  36447.619608   \n",
       "18                      50       19.867454        22.238648  35759.308735   \n",
       "19                      53       19.823599        22.220698  35680.374115   \n",
       "20                      56       19.834626        22.226785  35700.222460   \n",
       "21                      58       19.826200        22.240318  35685.055448   \n",
       "22                      61       19.844238        22.236197  35717.523425   \n",
       "23                      64       19.865858        22.258393  35756.435521   \n",
       "24                      67       19.865958        22.262365  35756.617093   \n",
       "25                      70       19.856274        22.232427  35739.185615   \n",
       "26                      72       19.876603        22.256364  35775.776466   \n",
       "27                      75       19.864554        22.243125  35754.088502   \n",
       "28                      78       19.873700        22.253917  35770.551356   \n",
       "29                      81       19.859108        22.367740  35744.286911   \n",
       "..                     ...             ...              ...           ...   \n",
       "70                     196       20.076899        22.411649  36136.288561   \n",
       "71                     198       20.089712        22.439716  36159.350029   \n",
       "72                     201       20.080710        22.432317  36143.146624   \n",
       "73                     204       20.067330        22.428067  36119.065186   \n",
       "74                     207       20.071584        22.485814  36126.721249   \n",
       "75                     210       20.060627        22.486198  36106.999872   \n",
       "76                     212       20.083235        22.499075  36147.692422   \n",
       "77                     215       20.053757        22.481749  36094.635104   \n",
       "78                     218       20.058894        22.494205  36103.881326   \n",
       "79                     221       20.072104        22.490313  36127.656770   \n",
       "80                     224       20.068959        22.507576  36121.996037   \n",
       "81                     226       20.089554        22.510541  36159.066168   \n",
       "82                     229       20.062919        22.497986  36111.124820   \n",
       "83                     232       20.062242        22.521412  36109.906353   \n",
       "84                     235       20.075326        22.514785  36133.455586   \n",
       "85                     238       20.068805        22.508690  36121.719761   \n",
       "86                     240       20.064272        22.508614  36113.560241   \n",
       "87                     243       20.060243        22.500050  36106.309415   \n",
       "88                     246       20.088778        22.515305  36157.668714   \n",
       "89                     249       20.072123        22.492351  36127.691396   \n",
       "90                     252       20.083076        22.519927  36147.404880   \n",
       "91                     254       20.076935        22.515370  36136.353062   \n",
       "92                     257       20.088953        22.512281  36157.983425   \n",
       "93                     260       20.065312        22.513935  36115.432207   \n",
       "94                     263       20.090819        22.540545  36161.342541   \n",
       "95                     266       20.071956        22.548289  36127.390350   \n",
       "96                     268       20.086504        22.536915  36153.575161   \n",
       "97                     271       20.163390        22.976132  36291.963044   \n",
       "98                     274       22.335969        24.389002  40202.374063   \n",
       "99                     277       46.848081        48.651443  84321.573767   \n",
       "\n",
       "      rmse_valid  \n",
       "0   41356.548025  \n",
       "1   41284.968444  \n",
       "2   41306.331485  \n",
       "3   41342.388641  \n",
       "4   41361.593637  \n",
       "5   41288.525894  \n",
       "6   41340.483904  \n",
       "7   41434.259710  \n",
       "8   41401.162039  \n",
       "9   41307.491388  \n",
       "10  41289.243985  \n",
       "11  41304.455399  \n",
       "12  41315.366970  \n",
       "13  41357.402555  \n",
       "14  41383.252067  \n",
       "15  41304.958577  \n",
       "16  41287.592836  \n",
       "17  41330.927154  \n",
       "18  41621.588048  \n",
       "19  41587.993499  \n",
       "20  41599.385382  \n",
       "21  41624.713313  \n",
       "22  41617.001737  \n",
       "23  41658.543004  \n",
       "24  41665.976269  \n",
       "25  41609.945135  \n",
       "26  41654.744758  \n",
       "27  41629.967816  \n",
       "28  41650.165645  \n",
       "29  41863.195277  \n",
       "..           ...  \n",
       "70  41945.375049  \n",
       "71  41997.905554  \n",
       "72  41984.056260  \n",
       "73  41976.102799  \n",
       "74  42084.181748  \n",
       "75  42084.900113  \n",
       "76  42108.999618  \n",
       "77  42076.573833  \n",
       "78  42099.884971  \n",
       "79  42092.602137  \n",
       "80  42124.911105  \n",
       "81  42130.459823  \n",
       "82  42106.962546  \n",
       "83  42150.806266  \n",
       "84  42138.403285  \n",
       "85  42126.995153  \n",
       "86  42126.853771  \n",
       "87  42110.824724  \n",
       "88  42139.376674  \n",
       "89  42096.415602  \n",
       "90  42148.026150  \n",
       "91  42139.498385  \n",
       "92  42133.715961  \n",
       "93  42136.812210  \n",
       "94  42186.614934  \n",
       "95  42201.109500  \n",
       "96  42179.821335  \n",
       "97  43001.855197  \n",
       "98  45646.165085  \n",
       "99  91055.460565  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('house_pred_lime_feature_selection_results.csv',index_col=0)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
