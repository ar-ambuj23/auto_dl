{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('models/iris.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train, Valid and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global x_train, x_test, x_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.pkl', 'rb') as fp:\n",
    "    x_train = pickle.load(fp)\n",
    "with open('x_test.pkl', 'rb') as fp:\n",
    "    x_test = pickle.load(fp)\n",
    "with open('x_valid.pkl', 'rb') as fp:\n",
    "    x_valid = pickle.load(fp)\n",
    "with open('y_train.pkl', 'rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "with open('y_test.pkl', 'rb') as fp:\n",
    "    y_test = pickle.load(fp)\n",
    "with open('y_valid.pkl', 'rb') as fp:\n",
    "    y_valid = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_params.pkl', 'rb') as fp:\n",
    "    best_params = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 128,\n",
       " 'dropout1': 0.5888517927868363,\n",
       " 'dropout2': 0.4037961236257436,\n",
       " 'early_stop_rounds': 50,\n",
       " 'num_layers': 'two_hidden',\n",
       " 'optimizer': 'adam',\n",
       " 'units1': 32,\n",
       " 'units2': 512}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999999761581421"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = model.evaluate(x_test,y_test,verbose=0)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_v,acc_v = model.evaluate(x_valid,y_valid,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333373069763"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('classify_intensity_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = y_train.isin([1]).stack().reset_index()\n",
    "t = t[t[0]==True]\n",
    "t = t.set_index('level_0').drop(0,axis=1)\n",
    "t.index.name = ''\n",
    "t.columns = ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global class_weights\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(t),t['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(best_params,feature_subset):   \n",
    "#     print('Training the best selected model...') \n",
    "\n",
    "\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(12345)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    \n",
    "    x_train_temp = x_train.copy() \n",
    "    y_train_temp = y_train.copy()\n",
    "    \n",
    "    x_valid_temp = x_valid.copy() \n",
    "    y_valid_temp = y_valid.copy()\n",
    "    \n",
    "    x_train_temp = x_train_temp[feature_subset]\n",
    "    x_valid_temp = x_valid_temp[feature_subset]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_params['units1'], input_shape=(x_train_temp.shape[1],)))\n",
    "    model.add(Activation(best_params['activation']))\n",
    "    model.add(Dropout(best_params['dropout1']))\n",
    "    if(best_params['num_layers'] == 'two_hidden'):\n",
    "        model.add(Dense(best_params['units2']))\n",
    "        model.add(Activation(best_params['activation']))\n",
    "        model.add(Dropout(best_params['dropout2']))\n",
    "    model.add(Dense(y_train_temp.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer=best_params['optimizer'])\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=best_params['early_stop_rounds'])\n",
    "    history = History()\n",
    "    model.fit(x_train_temp, y_train_temp,\n",
    "              batch_size=best_params['batch_size'],\n",
    "              epochs=500,\n",
    "              callbacks=[early_stop, history],\n",
    "              verbose=0,\n",
    "              validation_data=(x_valid_temp,y_valid_temp),\n",
    "              class_weight=class_weights) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(best_params,feature_subset):\n",
    "    model = train_best_model(best_params,feature_subset)\n",
    "    x_valid_temp = x_valid.copy() \n",
    "    y_valid_temp = y_valid.copy()\n",
    "    \n",
    "    x_test_temp = x_test.copy() \n",
    "    y_test_temp = y_test.copy()\n",
    "    \n",
    "    x_valid_temp = x_valid_temp[feature_subset]\n",
    "    x_test_temp = x_test_temp[feature_subset]\n",
    "    \n",
    "    loss,acc = model.evaluate(x_test_temp,y_test_temp,verbose=0)\n",
    "    \n",
    "    \n",
    "    loss_v,acc_v = model.evaluate(x_valid_temp,y_valid_temp,verbose=0)\n",
    "   \n",
    "    \n",
    "    return acc,acc_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Zero Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_zero = df[df['sum_of_intensities'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_features = list(df_non_zero['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, acc_v = get_results(best_params,non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9333333373069763, 0.9333333373069763)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, acc_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_zero_sorted = df_non_zero.sort_values(by=['sum_of_intensities'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_of_features(df):\n",
    "    feature_dict = {}\n",
    "    if(len(df)<=100):\n",
    "        for i in range(1,100):\n",
    "            if(i < len(df)):\n",
    "                drop_value = i\n",
    "                print('No of features dropped:',drop_value)\n",
    "                subset_df = df.head(len(df) - drop_value)\n",
    "                subset_df.sort_values(by=['index'],inplace=True)\n",
    "                feature_subset = list(subset_df['feature_name'])\n",
    "\n",
    "                acc, acc_v = get_results(best_params,feature_subset)\n",
    "\n",
    "                feature_dict[drop_value] = acc, acc_v\n",
    "        return feature_dict\n",
    "        \n",
    "    else:\n",
    "        for i in range(1,100):\n",
    "            drop_value = int(np.floor((i / 100) * len(df)))\n",
    "            print('No of features dropped:',drop_value)\n",
    "            subset_df = df.head(len(df) - drop_value)\n",
    "            print(list(subset_df['feature_name']))\n",
    "            subset_df.sort_values(by=['index'],inplace=True)\n",
    "            print(list(subset_df['feature_name']))\n",
    "            feature_subset = list(subset_df['feature_name'])\n",
    "            \n",
    "            acc, acc_v = get_results(best_params,feature_subset)\n",
    "            \n",
    "            feature_dict[drop_value] = acc, acc_v\n",
    "        return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of features dropped: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/izenda/env/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of features dropped: 2\n",
      "No of features dropped: 3\n"
     ]
    }
   ],
   "source": [
    "resultant_dict = simulation_of_features(df_non_zero_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0.8666666746139526, 0.8999999761581421),\n",
       " 2: (0.6333333253860474, 0.6666666865348816),\n",
       " 3: (0.3333333432674408, 0.30000001192092896)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df = pd.DataFrame(resultant_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.columns = ['no_of_dropped_features','acc_test', 'acc_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'no_of_dropped_features':[0],'acc_test':[0.9333333373069763],'acc_valid':[0.9333333373069763]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/izenda/env/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "resultant_df = resultant_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.sort_values(by=['no_of_dropped_features'],inplace=True)\n",
    "resultant_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultant_df.to_csv('iris_classify_lime_feature_selection_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_valid</th>\n",
       "      <th>no_of_dropped_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_valid  no_of_dropped_features\n",
       "0  0.933333   0.933333                       0\n",
       "1  0.866667   0.900000                       1\n",
       "2  0.633333   0.666667                       2\n",
       "3  0.333333   0.300000                       3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultant_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
