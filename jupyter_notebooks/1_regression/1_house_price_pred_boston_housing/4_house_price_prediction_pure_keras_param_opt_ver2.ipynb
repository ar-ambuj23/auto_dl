{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has shuffling, normalisation, udf for model training, hyperas, reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data is passed as some pct of the training data, for early stopping rounds. And then finally predictions are made on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Keras libraries used in this example\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, STATUS_FAIL\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from hyperas.utils import space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loding data directly from Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    Make sure to have every relevant import statement included here and return data as\n",
    "    used in model function below. This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    \n",
    "    boston_housing = keras.datasets.boston_housing\n",
    "    (x_train, y_train), (x_test, y_test) = boston_housing.load_data()    \n",
    "    \n",
    "    # Calculating column wise mean and std\n",
    "    mean = x_train.mean(axis=0)\n",
    "    std = x_train.std(axis=0)\n",
    "\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test #these names must be same as the args of create model. Else x_train not defined error is thrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([32, 64, 128, 256,512])}}, input_shape=(13,)))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    # If we choose 'two_hidden', add an additional layer\n",
    "    if {{choice(['one_hidden', 'two_hidden'])}} == 'two_hidden':\n",
    "        model.add(Dense({{choice([32, 64, 128, 256,512])}}))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mse', metrics=['mae'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'nadam','sgd'])}})\n",
    "    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience={{choice([10,20,30,40,50])}})\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size={{choice([16,32,64,128])}},\n",
    "              epochs=500,\n",
    "              callbacks=[early_stop],\n",
    "              verbose=0,\n",
    "              validation_split=0.2)\n",
    "#               validation_data=(x_test, y_test))\n",
    "    [loss, mae] = model.evaluate(x_test, y_test, verbose=0)\n",
    "#     print('loss:',loss)\n",
    "#     print('mae:',mae)\n",
    "    \n",
    "    # In cases where the loss turns out to be nan (due to bad network architecture)\n",
    "    # An Assertion error is raised by hyperopt. Because of the nan value of loss.\n",
    "    # So, to avoid such a case, we update loss to infinity in that case.\n",
    "    if(np.isnan(mae)):\n",
    "        print('nan loss')\n",
    "        return {'loss': np.inf, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "    print(\"Testing set Mean Abs Error: {:7.2f}\".format(mae))\n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error:    3.74\n",
      "Testing set Mean Abs Error:    3.95\n",
      "Testing set Mean Abs Error:    3.64\n",
      "Testing set Mean Abs Error:   17.50\n",
      "Testing set Mean Abs Error:    3.28\n",
      "Testing set Mean Abs Error:     nan\n",
      "Testing set Mean Abs Error:    4.15\n",
      "Testing set Mean Abs Error:    4.00\n",
      "Testing set Mean Abs Error:    3.65\n",
      "Testing set Mean Abs Error:    3.60\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d88c39cbb1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                           \u001b[0meval_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#gives actual values of params in best run instead of list indeces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                           return_space=True) #returns the search space of hyperopt. Can be used To display all the trails.\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nEvalutation of best performing model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                      verbose=verbose)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'misc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;31m# unpack the one-element lists to values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/izenda_fullcycle/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m                       if t['result']['status'] == STATUS_OK]\n\u001b[1;32m    583\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = data()\n",
    "    \n",
    "    trials=Trials()\n",
    "    best_run, best_model, space = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=100, #check how to pass maximum value\n",
    "                                          trials=trials,\n",
    "                                         notebook_name='4_house_price_prediction_pure_keras_param_opt_ver2',\n",
    "                                          eval_space = True, #gives actual values of params in best run instead of list indeces\n",
    "                                          verbose=False,\n",
    "                                          return_space=True) #returns the search space of hyperopt. Can be used To display all the trails.\n",
    "    \n",
    "    print(\"\\n\\nEvalutation of best performing model:\")\n",
    "    print(best_model.evaluate(X_test, Y_test, verbose=0))\n",
    "    print(\"\\n\\nBest performing model chosen hyper-parameters:\")\n",
    "    print(best_run)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 512)               7168      \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 270,337\n",
      "Trainable params: 270,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [1], 'Dropout': [0.3207527760045966], 'Dropout_1': [1], 'Dropout_2': [0.7371698374615214], 'batch_size': [2], 'optimizer': [0], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 64, 'Dropout': 0.3207527760045966, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.7371698374615214, 'batch_size': 64, 'optimizer': 'rmsprop', 'patience': 20}\n",
      "Trial 1 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [3], 'Dropout': [0.9770005173795487], 'Dropout_1': [1], 'Dropout_2': [0.42522861686845626], 'batch_size': [1], 'optimizer': [2], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 256, 'Dropout': 0.9770005173795487, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.42522861686845626, 'batch_size': 32, 'optimizer': 'nadam', 'patience': 50}\n",
      "Trial 2 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [4], 'Dropout': [0.14514364721165218], 'Dropout_1': [1], 'Dropout_2': [0.9758185183456943], 'batch_size': [0], 'optimizer': [2], 'patience': [2]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 512, 'Dropout': 0.14514364721165218, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.9758185183456943, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 30}\n",
      "Trial 3 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [2], 'Dropout': [0.9975531408239052], 'Dropout_1': [0], 'Dropout_2': [0.11729755246044238], 'batch_size': [3], 'optimizer': [2], 'patience': [1]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 128, 'Dropout': 0.9975531408239052, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.11729755246044238, 'batch_size': 128, 'optimizer': 'nadam', 'patience': 20}\n",
      "Trial 4 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [3], 'Dense_1': [2], 'Dropout': [0.587606728324542], 'Dropout_1': [1], 'Dropout_2': [0.2330896882313117], 'batch_size': [3], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 256, 'Dense_1': 128, 'Dropout': 0.587606728324542, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.2330896882313117, 'batch_size': 128, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 5 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [3], 'Dense_1': [0], 'Dropout': [0.9772817488940724], 'Dropout_1': [1], 'Dropout_2': [0.7428344092396598], 'batch_size': [2], 'optimizer': [3], 'patience': [2]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 256, 'Dense_1': 32, 'Dropout': 0.9772817488940724, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.7428344092396598, 'batch_size': 64, 'optimizer': 'sgd', 'patience': 30}\n",
      "Trial 6 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [0], 'Dropout': [0.5422412690636627], 'Dropout_1': [0], 'Dropout_2': [0.39730440328653105], 'batch_size': [0], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 32, 'Dropout': 0.5422412690636627, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.39730440328653105, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 7 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [2], 'Dropout': [0.7302305870589935], 'Dropout_1': [0], 'Dropout_2': [0.08078306361277332], 'batch_size': [3], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 128, 'Dropout': 0.7302305870589935, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.08078306361277332, 'batch_size': 128, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 8 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [1], 'Dropout': [0.6257491042113806], 'Dropout_1': [0], 'Dropout_2': [0.7357738125603991], 'batch_size': [3], 'optimizer': [3], 'patience': [4]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 64, 'Dropout': 0.6257491042113806, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.7357738125603991, 'batch_size': 128, 'optimizer': 'sgd', 'patience': 50}\n",
      "Trial 9 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [3], 'Dropout': [0.7446290506725413], 'Dropout_1': [0], 'Dropout_2': [0.09225974322037533], 'batch_size': [3], 'optimizer': [3], 'patience': [0]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 256, 'Dropout': 0.7446290506725413, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.09225974322037533, 'batch_size': 128, 'optimizer': 'sgd', 'patience': 10}\n",
      "Trial 10 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [2], 'Dropout': [0.0010052814907028917], 'Dropout_1': [0], 'Dropout_2': [0.5106207029550341], 'batch_size': [3], 'optimizer': [3], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 128, 'Dropout': 0.0010052814907028917, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5106207029550341, 'batch_size': 128, 'optimizer': 'sgd', 'patience': 20}\n",
      "Trial 11 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [2], 'Dropout': [0.13256157391301626], 'Dropout_1': [1], 'Dropout_2': [0.3050671811830158], 'batch_size': [0], 'optimizer': [0], 'patience': [1]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 128, 'Dropout': 0.13256157391301626, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.3050671811830158, 'batch_size': 16, 'optimizer': 'rmsprop', 'patience': 20}\n",
      "Trial 12 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [4], 'Dropout': [0.9992918522039433], 'Dropout_1': [0], 'Dropout_2': [0.8057421324867103], 'batch_size': [3], 'optimizer': [1], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 512, 'Dropout': 0.9992918522039433, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.8057421324867103, 'batch_size': 128, 'optimizer': 'adam', 'patience': 40}\n",
      "Trial 13 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.643128044948208], 'Dropout_1': [0], 'Dropout_2': [0.5172534041868964], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.643128044948208, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5172534041868964, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 14 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [2], 'Dropout': [0.4671776323322324], 'Dropout_1': [1], 'Dropout_2': [0.5226618564648536], 'batch_size': [0], 'optimizer': [3], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 128, 'Dropout': 0.4671776323322324, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.5226618564648536, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 20}\n",
      "Trial 15 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [3], 'Dense_1': [3], 'Dropout': [0.42208889978571484], 'Dropout_1': [1], 'Dropout_2': [0.6978532888931194], 'batch_size': [0], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 256, 'Dense_1': 256, 'Dropout': 0.42208889978571484, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.6978532888931194, 'batch_size': 16, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 16 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [1], 'Dropout': [0.4154823182005354], 'Dropout_1': [0], 'Dropout_2': [0.6627654657594161], 'batch_size': [1], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 64, 'Dropout': 0.4154823182005354, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.6627654657594161, 'batch_size': 32, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 17 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [3], 'Dropout': [0.7600323289991033], 'Dropout_1': [0], 'Dropout_2': [0.810557466404199], 'batch_size': [3], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 256, 'Dropout': 0.7600323289991033, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.810557466404199, 'batch_size': 128, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 18 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [3], 'Dropout': [0.36117159829314394], 'Dropout_1': [0], 'Dropout_2': [0.9608812210263653], 'batch_size': [0], 'optimizer': [3], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 256, 'Dropout': 0.36117159829314394, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.9608812210263653, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 50}\n",
      "Trial 19 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [0], 'Dropout': [0.0424438180227239], 'Dropout_1': [0], 'Dropout_2': [0.01170091734460954], 'batch_size': [0], 'optimizer': [2], 'patience': [1]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 32, 'Dropout': 0.0424438180227239, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.01170091734460954, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 20}\n",
      "Trial 20 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [3], 'Dropout': [0.8230396895143396], 'Dropout_1': [0], 'Dropout_2': [0.838986772861456], 'batch_size': [3], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 256, 'Dropout': 0.8230396895143396, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.838986772861456, 'batch_size': 128, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 21 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [3], 'Dropout': [0.8599659264047813], 'Dropout_1': [0], 'Dropout_2': [0.9251979089505205], 'batch_size': [3], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 256, 'Dropout': 0.8599659264047813, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.9251979089505205, 'batch_size': 128, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 22 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [3], 'Dropout': [0.8568409080872206], 'Dropout_1': [0], 'Dropout_2': [0.8578350255733117], 'batch_size': [3], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 256, 'Dropout': 0.8568409080872206, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.8578350255733117, 'batch_size': 128, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 23 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [3], 'Dropout': [0.861099764734504], 'Dropout_1': [0], 'Dropout_2': [0.6351003188490718], 'batch_size': [2], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 256, 'Dropout': 0.861099764734504, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.6351003188490718, 'batch_size': 64, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 24 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [3], 'Dropout': [0.7445454727175782], 'Dropout_1': [0], 'Dropout_2': [0.8759300329674415], 'batch_size': [1], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 256, 'Dropout': 0.7445454727175782, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.8759300329674415, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 25 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.76839357649636], 'Dropout_1': [0], 'Dropout_2': [0.6004661664985909], 'batch_size': [1], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.76839357649636, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.6004661664985909, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 26 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.7031994184200306], 'Dropout_1': [0], 'Dropout_2': [0.5924856785252335], 'batch_size': [1], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.7031994184200306, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5924856785252335, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 27 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.6766904916819706], 'Dropout_1': [0], 'Dropout_2': [0.5928630695483172], 'batch_size': [1], 'optimizer': [0], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.6766904916819706, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5928630695483172, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 10}\n",
      "Trial 28 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.5459113410903524], 'Dropout_1': [0], 'Dropout_2': [0.5821308850487259], 'batch_size': [1], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.5459113410903524, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5821308850487259, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 29 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.279429908869076], 'Dropout_1': [0], 'Dropout_2': [0.40140362590400713], 'batch_size': [1], 'optimizer': [0], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.279429908869076, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.40140362590400713, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 40}\n",
      "Trial 30 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.9239374618629188], 'Dropout_1': [0], 'Dropout_2': [0.3229933768709928], 'batch_size': [1], 'optimizer': [0], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.9239374618629188, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.3229933768709928, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 50}\n",
      "Trial 31 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [0], 'Dense_1': [4], 'Dropout': [0.676683306118], 'Dropout_1': [1], 'Dropout_2': [0.4348897165861483], 'batch_size': [1], 'optimizer': [2], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 32, 'Dense_1': 512, 'Dropout': 0.676683306118, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.4348897165861483, 'batch_size': 32, 'optimizer': 'nadam', 'patience': 30}\n",
      "Trial 32 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.800577983060126], 'Dropout_1': [0], 'Dropout_2': [0.22495592588080543], 'batch_size': [1], 'optimizer': [0], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.800577983060126, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.22495592588080543, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 10}\n",
      "Trial 33 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [4], 'Dropout': [0.935666771850825], 'Dropout_1': [1], 'Dropout_2': [0.45692430842848786], 'batch_size': [2], 'optimizer': [2], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 512, 'Dropout': 0.935666771850825, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.45692430842848786, 'batch_size': 64, 'optimizer': 'nadam', 'patience': 40}\n",
      "Trial 34 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [1], 'Dropout': [0.49765915603201805], 'Dropout_1': [0], 'Dropout_2': [0.607251904627954], 'batch_size': [1], 'optimizer': [0], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 64, 'Dropout': 0.49765915603201805, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.607251904627954, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 50}\n",
      "Trial 35 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [1], 'Dropout': [0.27009164194919144], 'Dropout_1': [0], 'Dropout_2': [0.7526701475161167], 'batch_size': [1], 'optimizer': [0], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 64, 'Dropout': 0.27009164194919144, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.7526701475161167, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 50}\n",
      "Trial 36 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [1], 'Dropout': [0.5113553989010144], 'Dropout_1': [1], 'Dropout_2': [0.32702112116372334], 'batch_size': [2], 'optimizer': [2], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 64, 'Dropout': 0.5113553989010144, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.32702112116372334, 'batch_size': 64, 'optimizer': 'nadam', 'patience': 50}\n",
      "Trial 37 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [0], 'Dense_1': [1], 'Dropout': [0.16733616993725475], 'Dropout_1': [0], 'Dropout_2': [0.19977997166593947], 'batch_size': [1], 'optimizer': [0], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 32, 'Dense_1': 64, 'Dropout': 0.16733616993725475, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.19977997166593947, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 50}\n",
      "Trial 38 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [3], 'Dense_1': [1], 'Dropout': [0.6053035373541426], 'Dropout_1': [0], 'Dropout_2': [0.6579124024771459], 'batch_size': [1], 'optimizer': [0], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 256, 'Dense_1': 64, 'Dropout': 0.6053035373541426, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.6579124024771459, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 30}\n",
      "Trial 39 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [1], 'Dropout': [0.34600520014299435], 'Dropout_1': [1], 'Dropout_2': [0.5663398815535632], 'batch_size': [1], 'optimizer': [2], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 64, 'Dropout': 0.34600520014299435, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.5663398815535632, 'batch_size': 32, 'optimizer': 'nadam', 'patience': 50}\n",
      "Trial 40 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [1], 'Dropout': [0.5548039695803386], 'Dropout_1': [0], 'Dropout_2': [0.7513498442839088], 'batch_size': [2], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 64, 'Dropout': 0.5548039695803386, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.7513498442839088, 'batch_size': 64, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 41 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [0], 'Dropout': [0.47446728423144124], 'Dropout_1': [0], 'Dropout_2': [0.4676915539521407], 'batch_size': [1], 'optimizer': [0], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 32, 'Dropout': 0.47446728423144124, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.4676915539521407, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 30}\n",
      "Trial 42 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [2], 'Dense_1': [1], 'Dropout': [0.23023572253450625], 'Dropout_1': [0], 'Dropout_2': [0.9013455770928651], 'batch_size': [1], 'optimizer': [3], 'patience': [4]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 128, 'Dense_1': 64, 'Dropout': 0.23023572253450625, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.9013455770928651, 'batch_size': 32, 'optimizer': 'sgd', 'patience': 50}\n",
      "Trial 43 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [2], 'Dropout': [0.4257046804139517], 'Dropout_1': [1], 'Dropout_2': [0.2753005129799372], 'batch_size': [1], 'optimizer': [0], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 128, 'Dropout': 0.4257046804139517, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.2753005129799372, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 10}\n",
      "Trial 44 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [0], 'Dropout': [0.5655744182316909], 'Dropout_1': [0], 'Dropout_2': [0.9985039905488347], 'batch_size': [2], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 32, 'Dropout': 0.5655744182316909, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.9985039905488347, 'batch_size': 64, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 45 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [2], 'Dense_1': [1], 'Dropout': [0.9338151400841518], 'Dropout_1': [0], 'Dropout_2': [0.38133311515403073], 'batch_size': [1], 'optimizer': [3], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 128, 'Dense_1': 64, 'Dropout': 0.9338151400841518, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.38133311515403073, 'batch_size': 32, 'optimizer': 'sgd', 'patience': 30}\n",
      "Trial 46 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [0], 'Dense_1': [2], 'Dropout': [0.6380431157235749], 'Dropout_1': [1], 'Dropout_2': [0.7085938958001465], 'batch_size': [1], 'optimizer': [0], 'patience': [0]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 32, 'Dense_1': 128, 'Dropout': 0.6380431157235749, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.7085938958001465, 'batch_size': 32, 'optimizer': 'rmsprop', 'patience': 10}\n",
      "Trial 47 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.5019853651385967], 'Dropout_1': [0], 'Dropout_2': [0.36861369789418563], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.5019853651385967, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.36861369789418563, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 48 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.7951363067771658], 'Dropout_1': [0], 'Dropout_2': [0.16419894308542338], 'batch_size': [0], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.7951363067771658, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.16419894308542338, 'batch_size': 16, 'optimizer': 'adam', 'patience': 20}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.18902903599679766], 'Dropout_1': [0], 'Dropout_2': [0.5349263679384925], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.18902903599679766, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5349263679384925, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 50 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.11729495644870092], 'Dropout_1': [1], 'Dropout_2': [0.09184988702290225], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.11729495644870092, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.09184988702290225, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 51 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.08197567690261004], 'Dropout_1': [1], 'Dropout_2': [0.023124321583162966], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.08197567690261004, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.023124321583162966, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 52 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.10941307011559842], 'Dropout_1': [1], 'Dropout_2': [0.11263614094931779], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.10941307011559842, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.11263614094931779, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 53 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.3083192157210941], 'Dropout_1': [1], 'Dropout_2': [0.04030129860477355], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.3083192157210941, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.04030129860477355, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 54 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.3885686418577905], 'Dropout_1': [1], 'Dropout_2': [0.15024999181642412], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.3885686418577905, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.15024999181642412, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 55 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [2], 'Dropout': [0.02026556460411516], 'Dropout_1': [1], 'Dropout_2': [0.27415386518165286], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 128, 'Dropout': 0.02026556460411516, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.27415386518165286, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 56 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.2110249644398478], 'Dropout_1': [1], 'Dropout_2': [0.37014500588493193], 'batch_size': [0], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.2110249644398478, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.37014500588493193, 'batch_size': 16, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 57 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.44791882496023455], 'Dropout_1': [1], 'Dropout_2': [0.05603310009121676], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.44791882496023455, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.05603310009121676, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 58 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.3686520950703723], 'Dropout_1': [1], 'Dropout_2': [0.07917664976257505], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.3686520950703723, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.07917664976257505, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 59 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [0], 'Dropout': [0.044606215206843935], 'Dropout_1': [1], 'Dropout_2': [0.07537947531750439], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 32, 'Dropout': 0.044606215206843935, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.07537947531750439, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 60 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.24429267367716817], 'Dropout_1': [1], 'Dropout_2': [0.14753597771806348], 'batch_size': [0], 'optimizer': [3], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.24429267367716817, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.14753597771806348, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 10}\n",
      "Trial 61 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [0], 'Dropout': [0.13277173769544437], 'Dropout_1': [1], 'Dropout_2': [0.006203859330586162], 'batch_size': [3], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 32, 'Dropout': 0.13277173769544437, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.006203859330586162, 'batch_size': 128, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 62 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.3281401018706931], 'Dropout_1': [1], 'Dropout_2': [0.18722345099364412], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.3281401018706931, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.18722345099364412, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 63 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.38525001090636196], 'Dropout_1': [1], 'Dropout_2': [0.11548897862196386], 'batch_size': [0], 'optimizer': [2], 'patience': [0]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.38525001090636196, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.11548897862196386, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 10}\n",
      "Trial 64 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [0], 'Dropout': [0.10107598589586109], 'Dropout_1': [1], 'Dropout_2': [0.2499788094945947], 'batch_size': [2], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 32, 'Dropout': 0.10107598589586109, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.2499788094945947, 'batch_size': 64, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 65 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.2923127857178076], 'Dropout_1': [1], 'Dropout_2': [0.3312013807424331], 'batch_size': [0], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.2923127857178076, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.3312013807424331, 'batch_size': 16, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 66 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [2], 'Dropout': [0.5035003091859702], 'Dropout_1': [1], 'Dropout_2': [0.21114538687974316], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 128, 'Dropout': 0.5035003091859702, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.21114538687974316, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 67 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.5887562538655167], 'Dropout_1': [1], 'Dropout_2': [0.08650034341526697], 'batch_size': [0], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.5887562538655167, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.08650034341526697, 'batch_size': 16, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 68 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [3], 'Dropout': [0.3857706573809672], 'Dropout_1': [1], 'Dropout_2': [0.2588366584620602], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 256, 'Dropout': 0.3857706573809672, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.2588366584620602, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 69 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.16298414911033643], 'Dropout_1': [1], 'Dropout_2': [0.3564767984679598], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.16298414911033643, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.3564767984679598, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 70 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.5289641101586726], 'Dropout_1': [1], 'Dropout_2': [0.41754814271605184], 'batch_size': [3], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.5289641101586726, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.41754814271605184, 'batch_size': 128, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 71 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [4], 'Dropout': [0.47027146097869066], 'Dropout_1': [1], 'Dropout_2': [0.49159123237982505], 'batch_size': [0], 'optimizer': [3], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 512, 'Dropout': 0.47027146097869066, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.49159123237982505, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 30}\n",
      "Trial 72 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.24457463999273177], 'Dropout_1': [1], 'Dropout_2': [0.29787248078246614], 'batch_size': [0], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.24457463999273177, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.29787248078246614, 'batch_size': 16, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 73 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [3], 'Dropout': [0.6840444674267051], 'Dropout_1': [1], 'Dropout_2': [0.1836174599483693], 'batch_size': [0], 'optimizer': [2], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 256, 'Dropout': 0.6840444674267051, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.1836174599483693, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 50}\n",
      "Trial 74 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.35764858485730644], 'Dropout_1': [1], 'Dropout_2': [0.1324519557314168], 'batch_size': [2], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.35764858485730644, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.1324519557314168, 'batch_size': 64, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 75 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [4], 'Dropout': [0.4364386851754722], 'Dropout_1': [1], 'Dropout_2': [0.22964849708686672], 'batch_size': [3], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 512, 'Dropout': 0.4364386851754722, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.22964849708686672, 'batch_size': 128, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 76 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [0], 'Dense_1': [2], 'Dropout': [0.004495457597666341], 'Dropout_1': [0], 'Dropout_2': [0.060192706668613954], 'batch_size': [0], 'optimizer': [3], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 32, 'Dense_1': 128, 'Dropout': 0.004495457597666341, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.060192706668613954, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 50}\n",
      "Trial 77 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.7254426987486634], 'Dropout_1': [1], 'Dropout_2': [0.0003894445532826446], 'batch_size': [0], 'optimizer': [2], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.7254426987486634, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.0003894445532826446, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 30}\n",
      "Trial 78 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.6178817583282785], 'Dropout_1': [0], 'Dropout_2': [0.5535524587876584], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.6178817583282785, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.5535524587876584, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 79 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [3], 'Dropout': [0.058218622155938704], 'Dropout_1': [1], 'Dropout_2': [0.7932413026619246], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 256, 'Dropout': 0.058218622155938704, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.7932413026619246, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 80 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.3260329849374189], 'Dropout_1': [0], 'Dropout_2': [0.4469029250057719], 'batch_size': [2], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.3260329849374189, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.4469029250057719, 'batch_size': 64, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 81 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [2], 'Dropout': [0.40624284312385006], 'Dropout_1': [0], 'Dropout_2': [0.35102008026554726], 'batch_size': [3], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 128, 'Dropout': 0.40624284312385006, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.35102008026554726, 'batch_size': 128, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 82 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.20501038858549286], 'Dropout_1': [1], 'Dropout_2': [0.29541414103190544], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.20501038858549286, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.29541414103190544, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 83 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [3], 'Dense_1': [4], 'Dropout': [0.6504856391942024], 'Dropout_1': [0], 'Dropout_2': [0.09843111703894067], 'batch_size': [0], 'optimizer': [2], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 256, 'Dense_1': 512, 'Dropout': 0.6504856391942024, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.09843111703894067, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 30}\n",
      "Trial 84 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.27236018899338915], 'Dropout_1': [1], 'Dropout_2': [0.4770161581370616], 'batch_size': [0], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.27236018899338915, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.4770161581370616, 'batch_size': 16, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 85 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.56591764981245], 'Dropout_1': [0], 'Dropout_2': [0.16731535346830517], 'batch_size': [2], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.56591764981245, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.16731535346830517, 'batch_size': 64, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 86 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [1], 'Dense_1': [3], 'Dropout': [0.48823705415341767], 'Dropout_1': [1], 'Dropout_2': [0.025895062893552256], 'batch_size': [3], 'optimizer': [1], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 64, 'Dense_1': 256, 'Dropout': 0.48823705415341767, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.025895062893552256, 'batch_size': 128, 'optimizer': 'adam', 'patience': 40}\n",
      "Trial 87 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.530480186425113], 'Dropout_1': [0], 'Dropout_2': [0.4145558606311452], 'batch_size': [0], 'optimizer': [3], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.530480186425113, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.4145558606311452, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 30}\n",
      "Trial 88 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [0], 'Dense_1': [2], 'Dropout': [0.17806516379847104], 'Dropout_1': [1], 'Dropout_2': [0.641060902515812], 'batch_size': [0], 'optimizer': [1], 'patience': [1]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 32, 'Dense_1': 128, 'Dropout': 0.17806516379847104, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.641060902515812, 'batch_size': 16, 'optimizer': 'adam', 'patience': 20}\n",
      "Trial 89 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [1], 'Dropout': [0.1487942534462338], 'Dropout_1': [1], 'Dropout_2': [0.21701435117614779], 'batch_size': [0], 'optimizer': [2], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 64, 'Dropout': 0.1487942534462338, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.21701435117614779, 'batch_size': 16, 'optimizer': 'nadam', 'patience': 10}\n",
      "Trial 90 vals: {'Activation': [1], 'Activation_1': [1], 'Dense': [3], 'Dense_1': [0], 'Dropout': [0.2935404828618959], 'Dropout_1': [0], 'Dropout_2': [0.6935947866685453], 'batch_size': [0], 'optimizer': [1], 'patience': [4]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'sigmoid', 'Dense': 256, 'Dense_1': 32, 'Dropout': 0.2935404828618959, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.6935947866685453, 'batch_size': 16, 'optimizer': 'adam', 'patience': 50}\n",
      "Trial 91 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [4], 'Dropout': [0.44452847169909016], 'Dropout_1': [1], 'Dropout_2': [0.3876340729876968], 'batch_size': [2], 'optimizer': [1], 'patience': [2]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 512, 'Dropout': 0.44452847169909016, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.3876340729876968, 'batch_size': 64, 'optimizer': 'adam', 'patience': 30}\n",
      "Trial 92 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [1], 'Dense_1': [4], 'Dropout': [0.2515087128251485], 'Dropout_1': [0], 'Dropout_2': [0.24441266214034157], 'batch_size': [3], 'optimizer': [1], 'patience': [0]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 64, 'Dense_1': 512, 'Dropout': 0.2515087128251485, 'Dropout_1': 'one_hidden', 'Dropout_2': 0.24441266214034157, 'batch_size': 128, 'optimizer': 'adam', 'patience': 10}\n",
      "Trial 93 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.08066792143582735], 'Dropout_1': [1], 'Dropout_2': [0.05213185479594606], 'batch_size': [0], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.08066792143582735, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.05213185479594606, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 94 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.07679164541472537], 'Dropout_1': [1], 'Dropout_2': [0.042478037139596234], 'batch_size': [0], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.07679164541472537, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.042478037139596234, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 95 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [0], 'Dense_1': [0], 'Dropout': [0.019351212076695254], 'Dropout_1': [1], 'Dropout_2': [0.1326656953336305], 'batch_size': [0], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 32, 'Dense_1': 32, 'Dropout': 0.019351212076695254, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.1326656953336305, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 96 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.21167710062451142], 'Dropout_1': [1], 'Dropout_2': [0.07278510236709616], 'batch_size': [0], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.21167710062451142, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.07278510236709616, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 97 vals: {'Activation': [0], 'Activation_1': [0], 'Dense': [3], 'Dense_1': [0], 'Dropout': [0.1135004852185294], 'Dropout_1': [1], 'Dropout_2': [0.029775449837181736], 'batch_size': [2], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'relu', 'Dense': 256, 'Dense_1': 32, 'Dropout': 0.1135004852185294, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.029775449837181736, 'batch_size': 64, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 98 vals: {'Activation': [0], 'Activation_1': [1], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.07778878843460363], 'Dropout_1': [1], 'Dropout_2': [0.1056766489933284], 'batch_size': [0], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'relu', 'Activation_1': 'sigmoid', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.07778878843460363, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.1056766489933284, 'batch_size': 16, 'optimizer': 'sgd', 'patience': 40}\n",
      "Trial 99 vals: {'Activation': [1], 'Activation_1': [0], 'Dense': [4], 'Dense_1': [0], 'Dropout': [0.14634062612169435], 'Dropout_1': [1], 'Dropout_2': [0.19952876837086736], 'batch_size': [3], 'optimizer': [3], 'patience': [3]}\n",
      "{'Activation': 'sigmoid', 'Activation_1': 'relu', 'Dense': 512, 'Dense_1': 32, 'Dropout': 0.14634062612169435, 'Dropout_1': 'two_hidden', 'Dropout_2': 0.19952876837086736, 'batch_size': 128, 'optimizer': 'sgd', 'patience': 40}\n"
     ]
    }
   ],
   "source": [
    "# ----------------To get parameter value of each trial---------------------\n",
    "for t, trial in enumerate(trials):\n",
    "    vals = trial.get('misc').get('vals')\n",
    "    print(\"Trial %s vals: %s\" % (t, vals))\n",
    "    tmp = {}\n",
    "    for k,v in list(vals.items()):\n",
    "        tmp[k] = v[0]\n",
    "    print(space_eval(space, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(index=range(len(Y_test)))\n",
    "predictions['actual'] = pd.DataFrame(Y_test)\n",
    "predictions['preds'] = pd.DataFrame(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2</td>\n",
       "      <td>8.882998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.095352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.751303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>30.948114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.2</td>\n",
       "      <td>23.557842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.5</td>\n",
       "      <td>24.404249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.2</td>\n",
       "      <td>28.266670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.9</td>\n",
       "      <td>20.497667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.5</td>\n",
       "      <td>19.672045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.2</td>\n",
       "      <td>20.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.6</td>\n",
       "      <td>18.962412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.5</td>\n",
       "      <td>16.573427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.8</td>\n",
       "      <td>15.149168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>42.056469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.8</td>\n",
       "      <td>20.806240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24.3</td>\n",
       "      <td>20.806726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24.2</td>\n",
       "      <td>25.715263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19.8</td>\n",
       "      <td>21.192602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.1</td>\n",
       "      <td>18.140078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22.7</td>\n",
       "      <td>28.423120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.762159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.2</td>\n",
       "      <td>11.952644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.400295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.5</td>\n",
       "      <td>13.662128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.9</td>\n",
       "      <td>17.840870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>23.0</td>\n",
       "      <td>20.818867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.5</td>\n",
       "      <td>31.046310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.1</td>\n",
       "      <td>28.096766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.5</td>\n",
       "      <td>11.107948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>22.0</td>\n",
       "      <td>20.977058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>19.6</td>\n",
       "      <td>25.625755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.920453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>26.4</td>\n",
       "      <td>24.917727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>18.9</td>\n",
       "      <td>19.613708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20.9</td>\n",
       "      <td>19.849052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>28.1</td>\n",
       "      <td>24.242519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>35.4</td>\n",
       "      <td>34.755207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10.2</td>\n",
       "      <td>10.500147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>24.3</td>\n",
       "      <td>21.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>43.1</td>\n",
       "      <td>36.899517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>17.6</td>\n",
       "      <td>14.208563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>15.4</td>\n",
       "      <td>14.296240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>16.2</td>\n",
       "      <td>16.096802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>27.1</td>\n",
       "      <td>18.301447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>21.4</td>\n",
       "      <td>24.474173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>21.5</td>\n",
       "      <td>20.095350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.919899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25.772562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>16.6</td>\n",
       "      <td>18.716633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.286312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>22.0</td>\n",
       "      <td>26.157448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>42.8</td>\n",
       "      <td>45.342838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>35.1</td>\n",
       "      <td>35.135468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>21.5</td>\n",
       "      <td>20.700787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>36.0</td>\n",
       "      <td>34.348110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.9</td>\n",
       "      <td>40.014153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24.1</td>\n",
       "      <td>26.484417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>50.0</td>\n",
       "      <td>44.670605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>26.7</td>\n",
       "      <td>31.987261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>25.0</td>\n",
       "      <td>20.043804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual      preds\n",
       "0       7.2   8.882998\n",
       "1      18.8  18.095352\n",
       "2      19.0  20.751303\n",
       "3      27.0  30.948114\n",
       "4      22.2  23.557842\n",
       "5      24.5  24.404249\n",
       "6      31.2  28.266670\n",
       "7      22.9  20.497667\n",
       "8      20.5  19.672045\n",
       "9      23.2  20.003736\n",
       "10     18.6  18.962412\n",
       "11     14.5  16.573427\n",
       "12     17.8  15.149168\n",
       "13     50.0  42.056469\n",
       "14     20.8  20.806240\n",
       "15     24.3  20.806726\n",
       "16     24.2  25.715263\n",
       "17     19.8  21.192602\n",
       "18     19.1  18.140078\n",
       "19     22.7  28.423120\n",
       "20     12.0  12.762159\n",
       "21     10.2  11.952644\n",
       "22     20.0  21.400295\n",
       "23     18.5  13.662128\n",
       "24     20.9  17.840870\n",
       "25     23.0  20.818867\n",
       "26     27.5  31.046310\n",
       "27     30.1  28.096766\n",
       "28      9.5  11.107948\n",
       "29     22.0  20.977058\n",
       "..      ...        ...\n",
       "72     19.6  25.625755\n",
       "73      7.0  14.920453\n",
       "74     26.4  24.917727\n",
       "75     18.9  19.613708\n",
       "76     20.9  19.849052\n",
       "77     28.1  24.242519\n",
       "78     35.4  34.755207\n",
       "79     10.2  10.500147\n",
       "80     24.3  21.813896\n",
       "81     43.1  36.899517\n",
       "82     17.6  14.208563\n",
       "83     15.4  14.296240\n",
       "84     16.2  16.096802\n",
       "85     27.1  18.301447\n",
       "86     21.4  24.474173\n",
       "87     21.5  20.095350\n",
       "88     22.4  22.919899\n",
       "89     25.0  25.772562\n",
       "90     16.6  18.716633\n",
       "91     18.6  20.286312\n",
       "92     22.0  26.157448\n",
       "93     42.8  45.342838\n",
       "94     35.1  35.135468\n",
       "95     21.5  20.700787\n",
       "96     36.0  34.348110\n",
       "97     21.9  40.014153\n",
       "98     24.1  26.484417\n",
       "99     50.0  44.670605\n",
       "100    26.7  31.987261\n",
       "101    25.0  20.043804\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Predicted')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAKYCAYAAAAyg4/gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZZIkSTlgKJMkScqB/wPWIE9r6bODsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa647124b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.scatter(predictions.actual,predictions.preds)\n",
    "fig.suptitle('Prediction Analysis', fontsize=20)\n",
    "ax.plot(ax.get_xlim(), ax.get_ylim(), ls=\"--\", c=\"r\")\n",
    "plt.xlabel('Actual', fontsize=14)\n",
    "plt.ylabel('Predicted', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
