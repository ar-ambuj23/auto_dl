{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fetch(csv_name):\n",
    "    \n",
    "    print(\"Reading the data...\")\n",
    "    df = pd.read_csv('datasets/{}.csv'.format(csv_name))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_cols(df):\n",
    "    \n",
    "    string_cols = list(df.select_dtypes(include=['object','category']).columns)\n",
    "    \n",
    "    return string_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_cols(df):\n",
    "    \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    num_cols = list(df.select_dtypes(include=numerics).columns)\n",
    "    \n",
    "    return num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bool_cols(df):\n",
    "    \n",
    "#     bool_cols = list(df.select_dtypes(include='bool').columns)\n",
    "    \n",
    "#     return bool_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df,label_col):\n",
    "\n",
    "    print(\"Pre-Processing the data...\")\n",
    "    # Remove y\n",
    "    y = df[label_col]\n",
    "    df = df.drop(label_col,axis=1)\n",
    "\n",
    "    string_cols = get_string_cols(df)\n",
    "    num_cols = get_num_cols(df)\n",
    "#     bool_cols = get_bool_cols(df)\n",
    "    \n",
    "    # Categorical Columns\n",
    "    substring = ':string'\n",
    "    num_cat_cols = []\n",
    "    for string in num_cols:\n",
    "        if(substring in string):\n",
    "            num_cat_cols.append(string)\n",
    "    #Convert all num_cat_cols to cat_cols\n",
    "    for col in num_cat_cols:\n",
    "        df[col] = df[col].astype('object')\n",
    "    categorical_cols = string_cols + num_cat_cols\n",
    "    \n",
    "    # Numerical Columns\n",
    "#     numerical_cols = list(set(num_cols) - set(num_cat_cols))\n",
    "    \n",
    "    # Pre Processing Categorical Columns\n",
    "    df = pd.get_dummies(df,columns=categorical_cols)\n",
    "    global training_dummy_columns\n",
    "    training_dummy_columns = df.columns\n",
    "    \n",
    "    # Pre Processing Numerical Columns\n",
    "    \n",
    "    # Remove :string from the df column names\n",
    "    df.columns = df.columns.str.replace(':string','')\n",
    "    \n",
    "    # Add back y\n",
    "    df[label_col] = y\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df,label_col,test_size=0.2):\n",
    "    \n",
    "    X = df.loc[:,df.columns != label_col]\n",
    "    y = df[label_col]\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_feat_selection(train_x,train_y,label_col,num_features):\n",
    "    \n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    print(\"Selecting the best features for training...\")\n",
    "    step = int(np.ceil(train_x.shape[1] / 100))\n",
    "#     print('Step:',step)\n",
    "\n",
    "    estimator = RandomForestRegressor(warm_start=True, random_state=42)\n",
    "    selector = RFE(estimator,step=step,n_features_to_select=num_features,verbose=0) \n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    print('No of selected features:',selector.n_features_)\n",
    "\n",
    "    selected_cols = []\n",
    "    for val,col in zip(selector.support_,train_x.columns):\n",
    "        if(val == True):\n",
    "            selected_cols.append(col)\n",
    "\n",
    "    return selected_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_space():\n",
    "    \n",
    "    space = {'num_layers': hp.choice('num_layers',['one_hidden', 'two_hidden']),\n",
    "\n",
    "                'units1': hp.choice('units1', [32, 64, 128, 256,512]),\n",
    "                'units2': hp.choice('units2', [32, 64, 128, 256,512]),\n",
    "\n",
    "                'dropout1': hp.uniform('dropout1', .25,.75),\n",
    "                'dropout2': hp.uniform('dropout2',  .25,.75),\n",
    "\n",
    "                'batch_size' : hp.choice('batch_size', [16,32,64,128]),\n",
    "\n",
    "                'nb_epochs' :  500,\n",
    "                'optimizer': hp.choice('optimizer',['rmsprop', 'adam', 'nadam','sgd']),\n",
    "                'activation': hp.choice('activation',['relu','sigmoid']),\n",
    "\n",
    "                'early_stop_rounds': hp.choice('early_stop_rounds',[10,20,30,40,50]),\n",
    "            }\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(csv_name,label_col,num_features):\n",
    "    \n",
    "    data = data_fetch(csv_name)\n",
    "    \n",
    "    pre_processed_data = pre_process(df=data,label_col=label_col)\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = split_train_test(df=pre_processed_data,label_col=label_col)\n",
    "    \n",
    "    best_features = rfe_feat_selection(train_x,train_y,label_col=label_col,num_features=num_features)\n",
    "    \n",
    "    best_features.append(label_col)\n",
    "    \n",
    "    feature_selected_data = pre_processed_data[best_features]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = split_train_test(df=feature_selected_data,label_col=label_col)\n",
    "    \n",
    "    return data, x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    \n",
    "    x_train_temp = x_train.copy()\n",
    "    x_test_temp = x_test.copy()\n",
    "    y_train_temp = y_train.copy()\n",
    "    y_test_temp = y_test.copy()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['units1'], input_shape=(x_train_temp.shape[1],)))\n",
    "    model.add(Activation(params['activation']))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "\n",
    "    # If we choose 'two_hidden', add an additional layer\n",
    "    if(params['num_layers'] == 'two_hidden'):\n",
    "        model.add(Dense(params['units2']))\n",
    "        model.add(Activation(params['activation']))\n",
    "        model.add(Dropout(params['dropout2']))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mse', metrics=['mae'],\n",
    "                  optimizer=params['optimizer'])\n",
    "    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=params['early_stop_rounds'])\n",
    "    history = History()\n",
    "    \n",
    "    model.fit(x_train_temp, y_train_temp,\n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=500,\n",
    "              callbacks=[early_stop, history],\n",
    "              verbose=0,\n",
    "              validation_split=0.2)\n",
    "    \n",
    "    [loss, mae] = model.evaluate(x_test_temp, y_test_temp, verbose=0)\n",
    "    \n",
    "    # In cases where the loss turns out to be nan (due to bad network architecture)\n",
    "    # An Assertion error is raised by hyperopt. Because of the nan value of loss.\n",
    "    # So, to avoid such a case, we update loss to infinity in that case.\n",
    "    if(np.isnan(mae)):\n",
    "        print(\"Testing set Mean Abs Error: NaN\")\n",
    "        return {'loss': np.inf, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "    print(\"Testing set Mean Abs Error: {:7.2f}\".format(mae))\n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(csv_name,label_col,num_features):\n",
    "    \n",
    "    global x_train,x_test,y_train,y_test\n",
    "    input_df, x_train, x_test, y_train, y_test = data(csv_name=csv_name,label_col=label_col,num_features=num_features)\n",
    "    \n",
    "    \n",
    "    trials=Trials()\n",
    "    space = get_search_space()\n",
    "    print(\"Moulding the network architecture specifically for your data...\")\n",
    "    print(\"Running evaluatins with various architectures and hyper-parameters...\")\n",
    "    best = fmin(create_model, space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "    best_model = trials.best_trial['result']['model']\n",
    "    \n",
    "#     print('\\nBest params are:\\n')\n",
    "#     print(best)\n",
    "#     print('\\nBest model:\\n')\n",
    "#     print(best_model.summary())\n",
    "    \n",
    "    \n",
    "    scaled_feature_df = pd.concat([x_train,x_test])\n",
    "    label_df = pd.concat([y_train,y_test])\n",
    "    \n",
    "    pred_df = make_predictions(model=best_model,df=scaled_feature_df)\n",
    "    \n",
    "    output_df = pd.merge(input_df,pred_df['predictions'].to_frame(),left_index=True,right_index=True)\n",
    "    \n",
    "    return best_model, output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model,df):\n",
    "    \n",
    "    # Prdeicting on whole df\n",
    "    \n",
    "    predictions = model.predict(df).flatten()\n",
    "    df['predictions'] = predictions\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(best_model,output_df):\n",
    "    \n",
    "    print(\"##################################################\")\n",
    "    print(\"Results:\")\n",
    "    print(\"Training Size: {} rows\".format(x_train.shape[0]))\n",
    "    print(\"Testing Size: {} rows\".format(x_test.shape[0]))\n",
    "    \n",
    "    # Evaluation on test data\n",
    "    loss,mae = best_model.evaluate(x_test,y_test,verbose=0)\n",
    "    \n",
    "    print(\"RMSE on the test data: \",(loss**0.5))\n",
    "    print(\"Percent error on the test data: \", (loss ** 0.5 / output_df.SalePrice.mean())*100, \"%\")\n",
    "    print(\"##################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model and update the config db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(best_model,output_df,training_dummy_columns):\n",
    "    \n",
    "    print(best_model)\n",
    "    print(output_df.shape)\n",
    "    print(training_dummy_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver(csv_name,label_col,num_features):\n",
    "    \n",
    "    best_model, output_df = get_best_model(csv_name=csv_name,label_col=label_col,num_features=num_features)\n",
    "    \n",
    "    display_results(best_model=best_model, output_df=output_df)\n",
    "    \n",
    "    # Save the model and update config db if user wants to save \n",
    "    save(best_model=best_model, output_df=output_df,training_dummy_columns=training_dummy_columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data...\n",
      "Pre-Processing the data...\n",
      "Selecting the best features for training...\n",
      "No of selected features: 10\n",
      "Moulding the network architecture specifically for your data...\n",
      "Running evaluatins with various architectures and hyper-parameters...\n",
      "Testing set Mean Abs Error: 178150.82\n",
      "Testing set Mean Abs Error: 56339.97\n",
      "Testing set Mean Abs Error: 30781.71\n",
      "Testing set Mean Abs Error: 165743.17\n",
      "Testing set Mean Abs Error: 28308.02\n",
      "Testing set Mean Abs Error: 54410.58\n",
      "Testing set Mean Abs Error: 29250.03\n",
      "Testing set Mean Abs Error: 177557.11\n",
      "Testing set Mean Abs Error: 179356.46\n",
      "\"Testing set Mean Abs Error: NaN\n",
      "##################################################\n",
      "Results:\n",
      "Training Size: 1160 rows\n",
      "Testing Size: 291 rows\n",
      "291/291 [==============================] - 0s 19us/step\n",
      "RMSE on the test data:  40501.29110427718\n",
      "Percent error on the test data:  22.422971605741882 %\n",
      "##################################################\n",
      "<keras.engine.sequential.Sequential object at 0x7fa1a2aaaf60>\n",
      "(1451, 77)\n",
      "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
      "       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       ...\n",
      "       'MSSubClass:string_60', 'MSSubClass:string_70', 'MSSubClass:string_75',\n",
      "       'MSSubClass:string_80', 'MSSubClass:string_85', 'MSSubClass:string_90',\n",
      "       'MSSubClass:string_120', 'MSSubClass:string_160',\n",
      "       'MSSubClass:string_180', 'MSSubClass:string_190'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    csv_name = 'train_no_null'\n",
    "    label_col = 'SalePrice'\n",
    "    num_features = 10\n",
    "    \n",
    "    driver(csv_name=csv_name,label_col=label_col,num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # No of epochs used\n",
    "# len(best_model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying graphical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# plt.scatter(output_df.SalePrice,output_df.predictions)\n",
    "# fig.suptitle('Prediction Analysis', fontsize=20)\n",
    "# ax.plot(ax.get_xlim(), ax.get_ylim(), ls=\"--\", c=\"r\")\n",
    "# plt.xlabel('Actual', fontsize=14)\n",
    "# plt.ylabel('Predicted', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
