{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import psutil\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lime_analysis_data/complete_data.pkl', 'rb') as handle:\n",
    "    complete_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lime_analysis_data/results.pkl', 'rb') as handle:\n",
    "    lime_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = complete_data['xtrain']\n",
    "x_test = complete_data['xtest']\n",
    "x_val = complete_data['xval']\n",
    "y_train = complete_data['ytrain']\n",
    "y_test = complete_data['ytest']\n",
    "y_val = complete_data['yval']\n",
    "# param_dict = complete_data['params_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df = lime_dict['intensity_df'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Intensity df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = intensity_df.iloc[0]\n",
    "intensity_df = intensity_df[1:]\n",
    "intensity_df.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df_trans = intensity_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df_trans['sum_of_intensities'] = intensity_df_trans.abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df_trans.sort_values(by=['sum_of_intensities'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of columns dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cols = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cols['drop_none'] = list(x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 0 intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df_trans_0 = intensity_df_trans.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df_trans_0 = intensity_df_trans_0.loc[(intensity_df_trans_0!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cols['drop_0_columns'] = list(intensity_df_trans_0.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop last n%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_df_trans_n = intensity_df_trans.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]:\n",
    "    list_of_cols['drop_{}_pct_columns'.format(n)] = list(intensity_df_trans_n.iloc[:int(np.ceil(intensity_df_trans_n.shape[0] * (1-(n/100)))),:].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def get_search_space():    \n",
    "    space = {'num_layers': hp.choice('num_layers',['one_hidden', 'two_hidden']),\n",
    "                'units1': hp.choice('units1', [32, 64, 128, 256,512]),\n",
    "                'units2': hp.choice('units2', [32, 64, 128, 256,512]),\n",
    "                'dropout1': hp.uniform('dropout1', .25,.75),\n",
    "                'dropout2': hp.uniform('dropout2',  .25,.75),\n",
    "                'batch_size' : hp.choice('batch_size', [16,32,64,128]),\n",
    "                'nb_epochs' :  500,\n",
    "                'optimizer': hp.choice('optimizer',['rmsprop', 'adam', 'nadam','sgd']),\n",
    "                'activation': hp.choice('activation',['relu','sigmoid']),\n",
    "                'early_stop_rounds': hp.choice('early_stop_rounds',[10,20,30,40,50]),\n",
    "            }\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params):    \n",
    "#     x_train_temp = x_train.copy()\n",
    "#     x_test_temp = x_test.copy()\n",
    "#     y_train_temp = y_train.copy()\n",
    "#     y_test_temp = y_test.copy()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['units1'], input_shape=(x_train_temp.shape[1],)))\n",
    "    model.add(Activation(params['activation']))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "    if(params['num_layers'] == 'two_hidden'):\n",
    "        model.add(Dense(params['units2']))\n",
    "        model.add(Activation(params['activation']))\n",
    "        model.add(Dropout(params['dropout2']))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(loss='mse', metrics=['mse'],\n",
    "                  optimizer=params['optimizer'])\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=params['early_stop_rounds'])\n",
    "    history = History()\n",
    "    model.fit(x_train_temp, y_train_temp,\n",
    "              batch_size=params['batch_size'],\n",
    "              epochs=500,\n",
    "              callbacks=[early_stop, history],\n",
    "              verbose=0,\n",
    "              validation_data=(x_valid_temp,y_valid_temp)) \n",
    "    [loss, mse] = model.evaluate(x_valid_temp,y_valid_temp, verbose=0)\n",
    "    global num\n",
    "    mem = psutil.virtual_memory()\n",
    "    if(np.isnan(mse)):\n",
    "        print(\"{}) Validation set root mean sq. error: NaN\".format(num),\"\\tAvailable Mem:\",(mem.available/1024)/1024,\"mb\")\n",
    "        num = num + 1\n",
    "        return {'loss': np.inf, 'status': STATUS_OK, 'model': model,'params':params}\n",
    "    print(\"{}) Validation set root mean sq. error: {:7.2f}\".format(num,mse**0.5),\"\\tAvailable Mem:\",(mem.available/1024)/1024,\"mb\")\n",
    "    num = num + 1\n",
    "    return {'loss': loss**0.5, 'status': STATUS_OK, 'model': model, 'params':params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(label_col):\n",
    "#     global x_train, x_test, x_valid, y_train, y_test, y_valid\n",
    "#     input_df, x_train, x_test, x_valid, y_train, y_test, y_valid = data(csv_name=csv_name,label_col=label_col,num_features=num_features)\n",
    "    trials=Trials()\n",
    "    space = get_search_space()\n",
    "    print(\"Selecting the best network architecture specifically for your data...\")\n",
    "    best = fmin(create_model, space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "    best_model = trials.best_trial['result']['model']\n",
    "#     scaled_feature_df = pd.concat([x_train,x_test])\n",
    "#     label_df = pd.concat([y_train,y_test])\n",
    "#     pred_df = make_predictions(model=best_model,df=scaled_feature_df)\n",
    "#     output_df = pd.merge(input_df,pred_df['predictions'].to_frame(),left_index=True,right_index=True)\n",
    "    return best_model, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 drop_none 396\n",
      "Selecting the best network architecture specifically for your data...\n",
      "1) Validation set root mean sq. error: 42634.62 \tAvailable Mem: 24241.828125 mb\n",
      "2) Validation set root mean sq. error: NaN \tAvailable Mem: 24231.6484375 mb\n",
      "3) Validation set root mean sq. error: NaN \tAvailable Mem: 24222.3515625 mb\n",
      "4) Validation set root mean sq. error: 42504.20 \tAvailable Mem: 24211.82421875 mb\n",
      "5) Validation set root mean sq. error: NaN \tAvailable Mem: 24205.16796875 mb\n",
      "6) Validation set root mean sq. error: NaN \tAvailable Mem: 24194.73828125 mb\n",
      "7) Validation set root mean sq. error: NaN \tAvailable Mem: 24187.8984375 mb\n",
      "8) Validation set root mean sq. error: 200034.77 \tAvailable Mem: 24178.15234375 mb\n",
      "9) Validation set root mean sq. error: 203549.09 \tAvailable Mem: 24167.8671875 mb\n",
      "10) Validation set root mean sq. error: 202024.36 \tAvailable Mem: 24158.73046875 mb\n",
      "11) Validation set root mean sq. error: 203512.22 \tAvailable Mem: 24150.18359375 mb\n",
      "12) Validation set root mean sq. error: 45336.10 \tAvailable Mem: 24137.2265625 mb\n",
      "13) Validation set root mean sq. error: 203229.21 \tAvailable Mem: 24124.953125 mb\n",
      "14) Validation set root mean sq. error: 42998.76 \tAvailable Mem: 24117.41796875 mb\n",
      "15) Validation set root mean sq. error: NaN \tAvailable Mem: 24106.24609375 mb\n",
      "16) Validation set root mean sq. error: 41836.36 \tAvailable Mem: 24098.4375 mb\n",
      "17) Validation set root mean sq. error: 44938.89 \tAvailable Mem: 24087.71484375 mb\n",
      "18) Validation set root mean sq. error: 201397.72 \tAvailable Mem: 24074.0625 mb\n",
      "19) Validation set root mean sq. error: 202040.62 \tAvailable Mem: 24063.99609375 mb\n",
      "20) Validation set root mean sq. error: 55788.92 \tAvailable Mem: 24053.91015625 mb\n",
      "21) Validation set root mean sq. error: 43192.70 \tAvailable Mem: 24043.0390625 mb\n",
      "22) Validation set root mean sq. error: 41973.77 \tAvailable Mem: 24031.25 mb\n",
      "23) Validation set root mean sq. error: 42358.58 \tAvailable Mem: 24022.8515625 mb\n",
      "24) Validation set root mean sq. error: 42239.42 \tAvailable Mem: 24011.61328125 mb\n",
      "25) Validation set root mean sq. error: 43838.06 \tAvailable Mem: 24000.8515625 mb\n",
      "26) Validation set root mean sq. error: 42276.09 \tAvailable Mem: 23992.08203125 mb\n",
      "27) Validation set root mean sq. error: 44688.89 \tAvailable Mem: 23985.5546875 mb\n",
      "28) Validation set root mean sq. error: 43817.23 \tAvailable Mem: 23973.88671875 mb\n",
      "29) Validation set root mean sq. error: 38292.64 \tAvailable Mem: 23963.5859375 mb\n",
      "30) Validation set root mean sq. error: 42920.80 \tAvailable Mem: 23951.7265625 mb\n",
      "31) Validation set root mean sq. error: 42190.97 \tAvailable Mem: 23939.97265625 mb\n",
      "32) Validation set root mean sq. error: 40757.27 \tAvailable Mem: 23933.515625 mb\n",
      "33) Validation set root mean sq. error: 42378.57 \tAvailable Mem: 23921.1171875 mb\n",
      "34) Validation set root mean sq. error: 42915.21 \tAvailable Mem: 23909.1953125 mb\n",
      "35) Validation set root mean sq. error: 41097.87 \tAvailable Mem: 23899.0 mb\n",
      "36) Validation set root mean sq. error: 41693.67 \tAvailable Mem: 23891.84765625 mb\n",
      "37) Validation set root mean sq. error: NaN \tAvailable Mem: 23882.80859375 mb\n",
      "38) Validation set root mean sq. error: 42912.92 \tAvailable Mem: 23875.1796875 mb\n",
      "39) Validation set root mean sq. error: NaN \tAvailable Mem: 23865.4375 mb\n",
      "40) Validation set root mean sq. error: 41501.12 \tAvailable Mem: 23855.359375 mb\n",
      "41) Validation set root mean sq. error: 202610.46 \tAvailable Mem: 23843.60546875 mb\n",
      "42) Validation set root mean sq. error: 52827.98 \tAvailable Mem: 23832.08203125 mb\n",
      "43) Validation set root mean sq. error: 42369.71 \tAvailable Mem: 23823.16015625 mb\n",
      "44) Validation set root mean sq. error: 83800.38 \tAvailable Mem: 23815.91015625 mb\n",
      "45) Validation set root mean sq. error: 38337.94 \tAvailable Mem: 23802.93359375 mb\n",
      "46) Validation set root mean sq. error: 39980.89 \tAvailable Mem: 23796.00390625 mb\n",
      "47) Validation set root mean sq. error: 82008.87 \tAvailable Mem: 23783.30859375 mb\n",
      "48) Validation set root mean sq. error: 42050.13 \tAvailable Mem: 23778.5234375 mb\n",
      "49) Validation set root mean sq. error: 43873.48 \tAvailable Mem: 23766.5390625 mb\n",
      "50) Validation set root mean sq. error: 203232.98 \tAvailable Mem: 23756.0 mb\n",
      "1 drop_0_columns 371\n",
      "Selecting the best network architecture specifically for your data...\n",
      "51) Validation set root mean sq. error: 68680.32 \tAvailable Mem: 23745.35546875 mb\n",
      "52) Validation set root mean sq. error: 53200.34 \tAvailable Mem: 23734.76953125 mb\n",
      "53) Validation set root mean sq. error: 46689.40 \tAvailable Mem: 23717.99609375 mb\n",
      "54) Validation set root mean sq. error: 42411.77 \tAvailable Mem: 23705.50390625 mb\n",
      "55) Validation set root mean sq. error: 80286.64 \tAvailable Mem: 23700.61328125 mb\n",
      "56) Validation set root mean sq. error: 202852.72 \tAvailable Mem: 23693.05859375 mb\n",
      "57) Validation set root mean sq. error: 43880.43 \tAvailable Mem: 23678.9296875 mb\n",
      "58) Validation set root mean sq. error: 42775.09 \tAvailable Mem: 23666.07421875 mb\n",
      "59) Validation set root mean sq. error: 42086.47 \tAvailable Mem: 23657.53125 mb\n",
      "60) Validation set root mean sq. error: 83285.28 \tAvailable Mem: 23648.60546875 mb\n",
      "61) Validation set root mean sq. error: 41987.29 \tAvailable Mem: 23641.296875 mb\n",
      "62) Validation set root mean sq. error: 43233.28 \tAvailable Mem: 23630.15234375 mb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "resultant_dict = {}\n",
    "num =1 \n",
    "for n,(key,cols) in enumerate(list_of_cols.items()):\n",
    "    print(n,key,len(cols))\n",
    "    global x_train_temp,y_train_temp,x_valid_temp,y_valid_temp, x_test_temp, y_test_temp\n",
    "    x_train_temp = x_train[cols].copy()\n",
    "    y_train_temp = y_train.copy()\n",
    "    x_valid_temp = x_val[cols].copy()\n",
    "    y_valid_temp = y_val.copy()\n",
    "    x_test_temp = x_test[cols].copy()\n",
    "    y_test_temp = y_test.copy()\n",
    "#     result_model = create_model(x_train_temp,y_train_temp,x_valid_temp,y_valid_temp,param_dict)\n",
    "    best_model, output_trials = get_best_model(label_col)\n",
    "    val_rmse = best_model.evaluate(x_valid_temp,y_valid_temp,verbose=0)[0] ** 0.5\n",
    "    test_rmse = best_model.evaluate(x_test_temp,y_test_temp,verbose=0)[0] ** 0.5\n",
    "    resultant_dict['{}'.format(key)] = [val_rmse,test_rmse]\n",
    "    result_lime_analysis_1_param_opt = pd.DataFrame(resultant_dict).T\n",
    "    result_lime_analysis_1_param_opt.columns = ['valid_rmse','test_rmse']\n",
    "    result_lime_analysis_1_param_opt.to_csv('lime_analysis_data/result_lime_analysis_1_param_opt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
