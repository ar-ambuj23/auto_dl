{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Keras libraries used in this example\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sys\n",
    "\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO # Python 2.x\n",
    "else:\n",
    "    from io import StringIO # Python 3.x\n",
    "    \n",
    "\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data is fetched from the url and saved in the hard disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- will be done in production environment ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciding Chunk Size on the basis of available RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- will be done in production environment --- <br>\n",
    "Assuming the chunk size to be 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data randomly into train and test for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following would be used in production script for all bash commands. <br>\n",
    "os.system('---command---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total rows in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23217\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l < data/large_house_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04307188697936857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the percentage of test data\n",
    "1000/23217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test_sample on the basis of pct_to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/large_house_data.csv | awk 'BEGIN {srand()} !/^$/ { if (rand() <= 0.043 || FNR==1) print $0}' > data/large_house_data_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the remaining train data except the test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "awk 'NR==FNR {exclude[$0];next} !($0 in exclude) || FNR==1' data/large_house_data_test.csv data/large_house_data.csv > data/large_house_data_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the test data and again saving it to the hard disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the testing data is already pre-processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE - Automated Feature Seclection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_feat_selection(train_x,train_y,label_col):\n",
    "    \n",
    "    testing_data = pd.read_csv('data/large_house_data_test.csv')\n",
    "    testing_data_X = testing_data.loc[:,testing_data.columns != label_col]\n",
    "    testing_data_y = testing_data[label_col]\n",
    "    \n",
    "    step = int(np.ceil(train_x.shape[1] / 100))\n",
    "    print('Step Value:',step)\n",
    "\n",
    "    estimator = RandomForestRegressor(warm_start=True, random_state=42,n_jobs=-1)\n",
    "\n",
    "    no_cols = train_x.shape[1]\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    for pct in range(10,100,10):\n",
    "        \n",
    "        n_features = int((pct * no_cols) / 100)\n",
    "        print('Fitting with {} features'.format(n_features))\n",
    "        selector = RFE(estimator,step=step,n_features_to_select=n_features,verbose=0)\n",
    "        selector = selector.fit(train_x, train_y)\n",
    "        predicted_Y = selector.predict(testing_data_X)\n",
    "        \n",
    "        error = mean_squared_error(testing_data_y,predicted_Y)\n",
    "        \n",
    "        selected_cols = []\n",
    "        for val,col in zip(selector.support_,train_x.columns):\n",
    "            if(val == True):\n",
    "                selected_cols.append(col)\n",
    "        \n",
    "        result_dict[pct] = error,selected_cols\n",
    "            \n",
    "    import operator\n",
    "    sorted_result_dict = sorted(result_dict.items(), key=operator.itemgetter(1))\n",
    "    \n",
    "    selected_cols = sorted_result_dict[0][1][1]\n",
    "    print('Best results with {} features for current chunk'.format(int((sorted_result_dict[0][0] * no_cols) / 100)))\n",
    "\n",
    "    return selected_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loding training data Chunk Wise and getting best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Chunk Number:  1\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 229 features for current chunk\n",
      "Current Chunk Number:  2\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 574 features for current chunk\n",
      "Current Chunk Number:  3\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 114 features for current chunk\n",
      "Current Chunk Number:  4\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 114 features for current chunk\n",
      "Current Chunk Number:  5\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 688 features for current chunk\n",
      "Current Chunk Number:  6\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 114 features for current chunk\n",
      "Current Chunk Number:  7\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 918 features for current chunk\n",
      "Current Chunk Number:  8\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 918 features for current chunk\n",
      "Current Chunk Number:  9\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 114 features for current chunk\n",
      "Current Chunk Number:  10\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 344 features for current chunk\n",
      "Current Chunk Number:  11\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 344 features for current chunk\n",
      "Current Chunk Number:  12\n",
      "Step Value: 12\n",
      "Fitting with 114 features\n",
      "Fitting with 229 features\n",
      "Fitting with 344 features\n",
      "Fitting with 459 features\n",
      "Fitting with 574 features\n",
      "Fitting with 688 features\n",
      "Fitting with 803 features\n",
      "Fitting with 918 features\n",
      "Fitting with 1033 features\n",
      "Best results with 344 features for current chunk\n"
     ]
    }
   ],
   "source": [
    "list_of_features = []\n",
    "label_col = 'SalePrice'\n",
    "\n",
    "for num,chunk in enumerate(pd.read_csv('data/large_house_data_train.csv',iterator=True,chunksize=1000)):\n",
    "    print('Current Chunk Number: ',num+1)\n",
    "    \n",
    "    X = chunk.loc[:,chunk.columns != label_col]\n",
    "    y = chunk[label_col]\n",
    "    \n",
    "    chunk_feature_list = rfe_feat_selection(X,y,label_col='SalePrice')\n",
    "    \n",
    "    list_of_features.append(chunk_feature_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
